[
  {
    "objectID": "special_conditions.html",
    "href": "special_conditions.html",
    "title": "4  Special Conditions",
    "section": "",
    "text": "Main plot is “irrigation” and split plot is “mix”.\n\nalfalfa_sp <- read.csv(\"data/alfalfa2021_data.csv\")\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\ncut: a cutting (harvest) of alfalfa within a single growing season. This is a temporal unit for repeated measures analysis. There were three cuttings in total for that year and field. The dates are not known, but we cannot assume they are evenly spaced apart.\nirrigation: irrigation treatment (“Full” or “Deficit”)\nplot: a unique number referring to each experimental unit\nblock: the blocking unit\nyield: response variable\nrow: plot position for row\ncol: plot positions for column or range\n\nhead(alfalfa_sp)\n\n    cut irrigation plot block     mix    yield row col\n1 First       Full 1101     1 50A+50O 221.0418   1   1\n2 First       Full 1102     1 75A+25O 288.7987   1   2\n3 First       Full 1103     1 50A+50F 466.7924   1   3\n4 First       Full 1104     1 75A+25M 556.9506   1   4\n5 First       Full 1105     1 50A+50M 422.9160   1   5\n6 First       Full 1106     1 75A+25F 289.8350   2   1\n\n\nTwo new variables created:\nrep: factor version of block (We should treat rep/block as a factor rather than an integer in modelling)\nCut: number version of cut where 1 is the first cutting. This is required by nlme::lme for specialized correlation structures.\n\nalfalfa_sp <- alfalfa_sp %>% \n  mutate(rep = as.factor(block)) %>% \n  mutate(Cut = case_when(\n    cut == \"First\" ~ 1L,\n    cut == \"Second\" ~ 2L,\n    cut == \"Third\" ~ 3L,\n    is.na(cut) ~ NA_integer_)) \n\nVisualise data\n\nlibrary(ggplot2); library(desplot)\n\nalfalfa_sp %>% filter(cut == \"First\") %>% \n  \nggplot(aes(x = col, y = row)) +\n  geom_raster(aes(fill = irrigation)) +\n  geom_tileborder(aes(group = 1, grp = rep), lwd = 1.5) + \n  theme_classic()\n\n\n\n\nModel statement\n\\[y_{ijk} = \\mu + \\alpha_i+\\beta_j + \\gamma_k + a_l + b_m + c_n + \\epsilon_{}\\] where\n\\(\\mu\\) = overall mean/intercept\n\\(\\alpha_i\\) = effect of the \\(i^{th}\\) irrigation treatment\n\\(\\beta_j\\) = effect of the \\(j^{th}\\) planting mix treatment \\(\\gamma_k\\) = effect of the \\(k^{th}\\) cutting [[need all those interactions]]\n\nlibrary(nlme)\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\nm1 <- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|rep/irrigation/plot,\n          data = alfalfa_sp)\n\nuse a special correlation structure for correlated error terms corCompSymm() is for compound symmetry. There are several other options in the nlm machinery (search “cor” for more options and details on the syntax). In general, repeated measures syntax follow this convention: form = ~ time|grouping. You can also use 1|group and the observation order for each group will be. The default starting value (value) is zero, and if fixed = FALSE (the current nlme default), this value will be allowed to change during the model fitting process.\n\ncorstr <- corCompSymm(value = 0.3, \n                      form = ~ cut|rep/irrigation/plot,\n                      fixed = FALSE)\n\nIt’s important that these two terms match after the “|” in the random and form arguments:\n\nm1 <- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|rep/irrigation/plot,\n          data = alfalfa_sp)\n\ncorstr <- corCompSymm(value = 0.3, \n                      form = ~ cut|rep/irrigation/plot,\n                      fixed = FALSE)\n\nUpdate the model:\n\nm2 <- update(m1, cor = corstr)\n\nThe usual next steps:\ncheck diagnostics\n\nplot(m2)\n\n\n\nqqnorm(m2, ~ resid(., type = \"p\"), abline = c(0, 1))\n\n\n\n\nLook at the variance components.\n\nVarCorr(m2)\n\n             Variance     StdDev    \nrep =        pdLogChol(1)           \n(Intercept)     83.17553    9.120062\nirrigation = pdLogChol(1)           \n(Intercept)    280.54818   16.749573\nplot =       pdLogChol(1)           \n(Intercept)    481.42852   21.941480\nResidual     16182.25878  127.209507\n\n\nRun ANOVA\n\nanova(m2)\n\n                   numDF denDF   F-value p-value\n(Intercept)            1   102 1432.6369  <.0001\nmix                    9   102   13.6932  <.0001\nirrigation             1     3    4.8770  0.1143\ncut                    2   102    6.0434  0.0033\nmix:irrigation         9   102    0.5256  0.8530\nmix:cut               18   102    0.8029  0.6927\nirrigation:cut         2   102   14.2649  <.0001\nmix:irrigation:cut    18   102    1.0226  0.4418\n\n\nalways check the degrees of freedom (denominator and numerator)!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mixed_models_guide",
    "section": "",
    "text": "This is a defaulf file accompanying a quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Each section contains the minimum to run a model, with more detail found at the later chapters. Unless I decide it makes more sense to include early materials.\nA Tidymodels framework is used whenever possible because that is a promising avenue for making the syntax easier to write across packages."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, mixed models are complicated."
  },
  {
    "objectID": "basic_models.html",
    "href": "basic_models.html",
    "title": "2  Randomized Complete Block Design",
    "section": "",
    "text": "This is a simple model that can serve as a good entrance point to mixed models. We will assume\nIt is very common design where experimental treatments are applied at random to experimental units within each block. The blocks are intended to control for a nuisance source of variation, such as over time, spatial variance, changes in equipment or operators, or myriad other causes.\n\n2.0.1 Background\nThe statistical model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\] Where:\n\\(\\mu\\) = overall experimental mean \\(\\alpha\\) = treatment effects (fixed) \\(\\beta\\) = block effects (random) \\(\\epsilon\\) = error terms\n\\[ \\epsilon} \\sim N(0, \\sigma)\\]\n\\[ \\beta \\sim N(0, \\sigma_b)\\]\nBoth the overall error and the block effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(sigma_B\\), respectively.\n\n\n\n\n\n\n‘IID’ assumption for error terms\n\n\n\nIn this model, the error terms, \\(\\epsilon\\) are assumed to be “IID”, that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\nThis guide will later address examples when this assumption is violated and how to handle it.\n\n\n\n\n2.0.2 Example Analysis\nFirst, load the libraries for analysis and estimation:\nNext, let’s load some data. It is located here if you want to download it yourself (recommended).\nThis data set is for a single wheat variety trial conducted in Aberdeen, Idaho in 2015. The trial includes 4 blocks and 42 different treatments (wheat varieties in this case). This experiment consists of a series of plots (the experimental unit) laid out in a rectangular grid in a farm field. The goal of this analysis is the estimate the yield and test weight of each variety and the determine the rankings of each variety with regard to yield.\n\nvar_trial <- read.csv(here::here(\"data\", \"aberdeen2015.csv\"))\n\n|—|————| |block | blocking unit | |range | column position for each plot | |row | row position for each plot | |variety | crop variety (the treatment) being evaluated | |stand_pct| percentage of the plot with actual plants growing in them | |days_to_heading_julian | Julian days (starting January 1st) until plot “headed” (first spike emerged)| |height | plant height at crop maturity | |lodging | percentage of plants in the plot that fell down and hence could not be harvested | |yield_bu_a | yield (bushels per acre) | |test weight | test weight (lbs per bushel of wheat) |\n: Table of variables in the data set {tbl-rcbd}\nThere are several variables present that are not useful for this analysis. The only thing we are concerned about is “block”, “variety”, “yield_bu_a”, and “test_weight”.\n\n2.0.2.1 Data integrity checks\nThe first thing is to make sure the data is what we expect. There are two steps:\n\nmake sure data are the expected data type\ncheck the extent of missing data\ninspect the independent variables and make sure the expected levels are present in the data\ninspect the dependent variable to ensure its distribution is following expectations\n\n\nstr(var_trial)\n\n'data.frame':   168 obs. of  10 variables:\n $ block                 : int  4 4 4 4 4 4 4 4 4 4 ...\n $ range                 : int  1 1 1 1 1 1 1 1 1 1 ...\n $ row                   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ variety               : chr  \"DAS004\" \"Kaseberg\" \"Bruneau\" \"OR2090473\" ...\n $ stand_pct             : int  100 98 96 100 98 100 100 100 99 100 ...\n $ days_to_heading_julian: int  149 146 149 146 146 151 145 145 146 146 ...\n $ height                : int  39 35 33 31 33 44 30 36 36 29 ...\n $ lodging               : int  0 0 0 0 0 0 0 0 0 0 ...\n $ yield_bu_a            : num  128 130 119 115 141 ...\n $ test_weight           : num  56.4 55 55.3 54.1 54.1 56.4 54.7 57.5 56.1 53.8 ...\n\n\nThese look okay except for block, which is currently coded as integer (numeric). We don’t want run a regression of block, where block 1 has twice the effect of block 2, and so on. So, converting it to a character will fix that. It can also be converted to a factor, but I find character easier to work with, and ultimately, equivalent to factor conversion\n\nvar_trial$block <- as.character(var_trial$block)\n\nNext, check the independent variables. Running a cross tabulations is often sufficient to ascertain this.\n\ntable(var_trial$variety, var_trial$block)\n\n                        \n                         1 2 3 4\n  06-03303B              1 1 1 1\n  Bobtail                1 1 1 1\n  Brundage               1 1 1 1\n  Bruneau                1 1 1 1\n  DAS003                 1 1 1 1\n  DAS004                 1 1 1 1\n  Eltan                  1 1 1 1\n  IDN-01-10704A          1 1 1 1\n  IDN-02-29001A          1 1 1 1\n  IDO1004                1 1 1 1\n  IDO1005                1 1 1 1\n  Jasper                 1 1 1 1\n  Kaseberg               1 1 1 1\n  LCS Artdeco            1 1 1 1\n  LCS Biancor            1 1 1 1\n  LCS Drive              1 1 1 1\n  LOR-833                1 1 1 1\n  LOR-913                1 1 1 1\n  LOR-978                1 1 1 1\n  Madsen                 1 1 1 1\n  Madsen / Eltan (50/50) 1 1 1 1\n  Mary                   1 1 1 1\n  Norwest Duet           1 1 1 1\n  Norwest Tandem         1 1 1 1\n  OR2080637              1 1 1 1\n  OR2080641              1 1 1 1\n  OR2090473              1 1 1 1\n  OR2100940              1 1 1 1\n  Rosalyn                1 1 1 1\n  Stephens               1 1 1 1\n  SY  Ovation            1 1 1 1\n  SY 107                 1 1 1 1\n  SY Assure              1 1 1 1\n  UI Castle CLP          1 1 1 1\n  UI Magic CLP           1 1 1 1\n  UI Palouse             1 1 1 1\n  UI Sparrow             1 1 1 1\n  UI-WSU Huffman         1 1 1 1\n  WB 456                 1 1 1 1\n  WB 528                 1 1 1 1\n  WB1376 CLP             1 1 1 1\n  WB1529                 1 1 1 1\n\n\nThere are 42 varieties and there appears to be no misspellings among them that might confuse R into thinking varieties are different when they are actually the same. R is sensitive to case and white space, which can make it easy to create near duplicate treatments, such as “eltan” and “Eltan” and “Eltan”. There is no evidence of that in this data set. Additionally, it is perfectly balanced, with exactly one observation per treatment per rep. Please note that this does not tell us anything about the extent of missing data.\nHere is a quick check I run to count the number of missing data in each column.\n\napply(var_trial, 2, function(x) sum(is.na(x)))\n\n                 block                  range                    row \n                     0                      0                      0 \n               variety              stand_pct days_to_heading_julian \n                     0                      0                      0 \n                height                lodging             yield_bu_a \n                     0                      0                      0 \n           test_weight \n                     0 \n\n\nAlas, no missing data!\nIf there were independent variables with a continuous distribution (a covariate), I would plot those data.\nLast, check the dependent variable. A histogram is often quite sufficient to accomplish this. This is designed to be a quick check, so no need to spend time making the plot look good.\n\nhist(var_trial$yield_bu_a)\n\n\n\n\nThe range is roughly falling into the range we expect. I know this from talking with the person who generated the data, not through my own intuition. I do not see any large spikes of points at a single value (indicating something odd), nor do I see any extreme values (low or high) that might indicate some larger problems. Data are not expected to be normally distributed at this point, so don’t bother running any Shapiro-Wilk tests. This is a check to ensure the the data are entered correctly and they appear valid. It requires a mixture of domain knoweldge and statistical training to know this, but over time, if you look at these plots with regularity, you will gain a feel for what your data should look like at this stage.\nThese are not complicated checks. They are designed to be done quickly and should be done for every analysis if you not previously already inspected the data as thus. I do this before every analysis and often discover surprising things! Best to discover these things early, since they are likely to impact the final analysis.\nThis data set is ready for analysis!\n\n\n\n2.0.3 Model Building\nRecall the model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\] For this model, \\(\\alpha_i\\) is the variety effect (fixed) and \\(\\beta_j\\) is the block effect (random).\nHere is that model translated into R syntax:\n\nmodel_rcbd <- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\n\nThe parentheses are used to indicate that ‘block’ is a random effect, and this particular notation (1|block) indicates that a ‘random intercept’ model is being fit. This is the most common approach. It means there is one overall effect fit for each block. I use the argument na.action = na.exclude as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.\n\n\n\n\n\n\nFormula notation\n\n\n\nFormula notation is often used in the R syntax for linear models. It looks like this: \\(Y ~ X\\), where Y is the dependent variable (the response) and X is/are the independent variable(s) (e.g. the experimental treatments).\n\nmy_formula <- formula(Y ~ treatment1 + treatment2)\nclass(my_formula)\n\n[1] \"formula\"\n\n\n\n\n\n\n2.0.4 Check Assumptions\nRemember those iid assumptions? Let’s make sure we actually met them.\nThere is a special plotting function written for lme4 object for checking the homoscedasticity (constant variance):\n\nplot(model_rcbd)\n\n\n\n\nWe are looking for a random and uniform distribution of points. This looks good!\nChecking normality requiring first extracting the model residuals with resid() and then generaing a qq-plot and line.\n\nqqnorm(resid(model_rcbd)); qqline(resid(model_rcbd))\n\n\n\n\nThis is reasonably good. Things do tend to fall apart at the tails.\nNext, extract estimates:\n\nrcbd_emm <- emmeans(model_rcbd, ~ variety)\nas.data.frame(rcbd_emm) %>% arrange(desc(emmean))\n\n variety                emmean   SE   df lower.CL upper.CL\n Rosalyn                   155 7.21 77.8    140.9      170\n IDO1005                   154 7.21 77.8    139.2      168\n OR2080641                 153 7.21 77.8    138.3      167\n Bobtail                   152 7.21 77.8    137.3      166\n UI Sparrow                152 7.21 77.8    137.2      166\n Kaseberg                  151 7.21 77.8    136.6      165\n IDN-01-10704A             149 7.21 77.8    134.6      163\n 06-03303B                 149 7.21 77.8    134.5      163\n WB1529                    148 7.21 77.8    133.9      163\n DAS003                    145 7.21 77.8    130.8      160\n IDN-02-29001A             145 7.21 77.8    130.2      159\n Bruneau                   144 7.21 77.8    129.6      158\n SY 107                    144 7.21 77.8    129.3      158\n WB 528                    143 7.21 77.8    128.6      157\n OR2080637                 142 7.21 77.8    127.4      156\n Jasper                    141 7.21 77.8    126.9      156\n UI Magic CLP              140 7.21 77.8    125.2      154\n Madsen                    139 7.21 77.8    124.9      154\n LCS Biancor               139 7.21 77.8    124.8      153\n SY  Ovation               139 7.21 77.8    124.3      153\n OR2090473                 138 7.21 77.8    123.5      152\n Madsen / Eltan (50/50)    137 7.21 77.8    122.6      151\n UI-WSU Huffman            135 7.21 77.8    121.1      150\n Mary                      135 7.21 77.8    120.5      149\n Norwest Tandem            134 7.21 77.8    120.0      149\n Brundage                  134 7.21 77.8    119.7      148\n IDO1004                   133 7.21 77.8    118.2      147\n DAS004                    132 7.21 77.8    117.9      147\n Norwest Duet              132 7.21 77.8    117.7      146\n Eltan                     131 7.21 77.8    117.1      146\n LCS Artdeco               131 7.21 77.8    116.5      145\n UI Palouse                130 7.21 77.8    116.1      145\n LOR-978                   130 7.21 77.8    116.1      145\n LCS Drive                 129 7.21 77.8    114.4      143\n Stephens                  127 7.21 77.8    112.8      142\n OR2100940                 126 7.21 77.8    111.8      141\n UI Castle CLP             126 7.21 77.8    111.2      140\n WB1376 CLP                124 7.21 77.8    109.3      138\n LOR-833                   123 7.21 77.8    108.4      137\n LOR-913                   119 7.21 77.8    104.4      133\n WB 456                    118 7.21 77.8    104.1      133\n SY Assure                 111 7.21 77.8     96.7      125\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\nThis table indicates the estimated marginal means (“emmean”, sometimes called “least squares means”), the standard error (“SE”) of those means, the degrees of freedom and the upper and lower bounds of the 95% confidence interval. As an additional step, the emmeans were sorted from largest to smallest.\nAt this point, the analysis goals have been met: we know the estimated means for each treatment and their rankings.\n\n2.0.4.1 Flotsam & Jetsam\nSometimes, researchers want to conduct an ANOVA or add the letters for indicating differences among treatments, even though we have reached the original goals of analysis. It is important to evaluate why you want to do these extra things, what extra information it will bring and what you plan to do with those results.\nRunning an ANOVA may increase or decrease confidence in the results, depending on what results. That is not at all what ANOVA is intended to do, nor is this what p-values can tell us!\nLabelling each treatment, especially when there are this many (42 in total), has its own perils. The biggest problem is that this creates a multiple testing problem: with 42 treatments, a total of 861 comparison are being run (=\\(42*(42-1)/2\\)), and then adjusted for multiple tests. With that many tests, a severe adjustment is likely and hence things that are different are not detected. With so many tests, it could be that there is an overall effect due to variety, but they all share the same letter!\nThe second problem is one of interpretation. Just because two treatments or varieties share a letter does not mean they are equivalent. It only means that they were not found to be different. A funny distinction, but alas. There is an entire branch of statistics, ‘equivalence testing’ devoted to just this topic - how to test if two things are actually the same. This involves the user declaring a maximum allowable numeric difference for a variable in order to determine if two items are statistically different or equivalent - something that these pairwise comparisons are not doing.\nIf you want to run ANOVA, it can be done quite easily:\n\nanova(model_rcbd)\n\nType III Analysis of Variance Table with Satterthwaite's method\n        Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \nvariety  18354  447.65    41   123  2.4528 8.017e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBut, please be thoughtful in your usage of it.\n\n\n\n\n\n\nna.action = na.exclude\n\n\n\nYou may have noticed the final argument for na.action in the model statement:\nmodel_rcbd <- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\nI use the argument na.action = na.exclude as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.\nSince there are no missing data, this step was not strictly necessary, but it’s a good habit to be in."
  }
]