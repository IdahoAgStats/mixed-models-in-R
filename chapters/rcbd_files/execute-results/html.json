{
  "hash": "a922dd87518499384810b3659cb07f34",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Randomized Complete Block Design\nreference-location: margin\n---\n\n\n\n\n\n\n\nThis is a simple model that can serve as a good entrance point to mixed models.\n\nRandomized complete block design (RCBD) is very common design where experimental treatments are applied at random to experimental units within each block. The block can represent a spatial or temporal unit or even different technicians taking data. The blocks are intended to control for a nuisance source of variation, such as over time, spatial variance, changes in equipment or operators, or myriad other causes. They are a random effect where the actual blocks used in the study are a random sample of a distribution of other blocks.\n\n## Background\n\nThe statistical model:\n\n$$y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}$$ Where:\n\n$\\mu$ = overall experimental mean $\\alpha$ = treatment effects (fixed) $\\beta$ = block effects (random) $\\epsilon$ = error terms\n\n$$ \\epsilon \\sim N(0, \\sigma)$$\n\n$$ \\beta \\sim N(0, \\sigma_b)$$\n\nBoth the overall error and the block effects are assumed to be normally distributed with a mean of zero and standard deviations of $\\sigma$ and $\\sigma_B$, respectively.\n\n::: callout-note\n## 'iid' assumption for error terms\n\nIn this model, the error terms, $\\epsilon$ are assumed to be \"iid\", that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\n\nThis guide will later address examples when this assumption is violated and how to handle it.\n:::\n\n## Example Analysis\n\nFirst, load the libraries for analysis and estimation:\n\n::: panel-tabset\n### lme4\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(performance)\n```\n:::\n\n\n\n\n\n### nlme\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nlme); library(performance); library(emmeans)\nlibrary(dplyr)\n```\n:::\n\n\n\n\n:::\n\n\nThis data set is for a single wheat variety trial conducted in Aberdeen, Idaho in 2015. The trial includes 4 blocks and 42 different treatments (wheat varieties in this case). This experiment consists of a series of plots (the experimental unit) laid out in a rectangular grid in a farm field. The goal of this analysis is the estimate the yield of each variety and the determine the rankings of each variety for the variable.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_trial <- read.csv(here::here(\"data\", \"aberdeen2015.csv\"))\n```\n:::\n\n\n\n\n\n|  |  |\n|-------------------|-----------------------------------------------------|\n| block | blocking unit |\n| range | column position for each plot |\n| row | row position for each plot |\n| variety | crop variety (the treatment) being evaluated |\n| stand_pct | percentage of the plot with actual plants growing in them |\n| days_to_heading_julian | Julian days (starting January 1st) until plot \"headed\" (first spike emerged) |\n| lodging | percentage of plants in the plot that fell down and hence could not be harvested |\n| yield_bu_a | yield (bushels per acre) |\n\n: Table of variables in the data set {tbl-rcbd}\n\nThere are several variables present that are not useful for this analysis. The only thing we are concerned about is **block**, **variety**, **yield_bu_a**, and **test_weight**.\n\n### Data integrity checks\n\nThe first thing is to make sure the data is what we expect.We will the steps explained in [**Chapter 4**](model-flow.qmd). Here are the steps to verify our data:\n\n- Check structure of the data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(var_trial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t168 obs. of  10 variables:\n $ block                 : int  4 4 4 4 4 4 4 4 4 4 ...\n $ range                 : int  1 1 1 1 1 1 1 1 1 1 ...\n $ row                   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ variety               : chr  \"DAS004\" \"Kaseberg\" \"Bruneau\" \"OR2090473\" ...\n $ stand_pct             : int  100 98 96 100 98 100 100 100 99 100 ...\n $ days_to_heading_julian: int  149 146 149 146 146 151 145 145 146 146 ...\n $ height                : int  39 35 33 31 33 44 30 36 36 29 ...\n $ lodging               : int  0 0 0 0 0 0 0 0 0 0 ...\n $ yield_bu_a            : num  128 130 119 115 141 ...\n $ test_weight           : num  56.4 55 55.3 54.1 54.1 56.4 54.7 57.5 56.1 53.8 ...\n```\n\n\n:::\n:::\n\n\n\n\n\nThese look okay except for block, which is currently coded as integer (numeric). We don't want run a regression of block, where block 2 has twice the effect of block 1, and so on. So, converting it to a character will fix that. It can also be converted to a factor, but character variables are a bit easier to work with, and ultimately, equivalent to factor conversion\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_trial$block <- as.character(var_trial$block)\n```\n:::\n\n\n\n\n\n- Inspect the independent variables\n\nNext, check the independent variables. Running a cross tabulations is often sufficient to ascertain this.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(var_trial$variety, var_trial$block)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        \n                         1 2 3 4\n  06-03303B              1 1 1 1\n  Bobtail                1 1 1 1\n  Brundage               1 1 1 1\n  Bruneau                1 1 1 1\n  DAS003                 1 1 1 1\n  DAS004                 1 1 1 1\n  Eltan                  1 1 1 1\n  IDN-01-10704A          1 1 1 1\n  IDN-02-29001A          1 1 1 1\n  IDO1004                1 1 1 1\n  IDO1005                1 1 1 1\n  Jasper                 1 1 1 1\n  Kaseberg               1 1 1 1\n  LCS Artdeco            1 1 1 1\n  LCS Biancor            1 1 1 1\n  LCS Drive              1 1 1 1\n  LOR-833                1 1 1 1\n  LOR-913                1 1 1 1\n  LOR-978                1 1 1 1\n  Madsen                 1 1 1 1\n  Madsen / Eltan (50/50) 1 1 1 1\n  Mary                   1 1 1 1\n  Norwest Duet           1 1 1 1\n  Norwest Tandem         1 1 1 1\n  OR2080637              1 1 1 1\n  OR2080641              1 1 1 1\n  OR2090473              1 1 1 1\n  OR2100940              1 1 1 1\n  Rosalyn                1 1 1 1\n  Stephens               1 1 1 1\n  SY  Ovation            1 1 1 1\n  SY 107                 1 1 1 1\n  SY Assure              1 1 1 1\n  UI-WSU Huffman         1 1 1 1\n  UI Castle CLP          1 1 1 1\n  UI Magic CLP           1 1 1 1\n  UI Palouse             1 1 1 1\n  UI Sparrow             1 1 1 1\n  WB 456                 1 1 1 1\n  WB 528                 1 1 1 1\n  WB1376 CLP             1 1 1 1\n  WB1529                 1 1 1 1\n```\n\n\n:::\n:::\n\n\n\n\n\nThere are 42 varieties and there appears to be no mis-spellings among them that might confuse R into thinking varieties are different when they are actually the same. R is sensitive to case and white space, which can make it easy to create near duplicate treatments, such as \"eltan\" and \"Eltan\". There is no evidence of that in this data set. Additionally, it is perfectly balanced, with exactly one observation per treatment per rep. Please note that this does not tell us anything about the extent of missing data.\n\n- Check the extent of missing data \n\nHere is a quick check to count the number of missing data in each column. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolSums(is.na(var_trial))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 block                  range                    row \n                     0                      0                      0 \n               variety              stand_pct days_to_heading_julian \n                     0                      0                      0 \n                height                lodging             yield_bu_a \n                     0                      0                      0 \n           test_weight \n                     0 \n```\n\n\n:::\n:::\n\n\n\n\n\nAlas, no missing data!\n\n- Inspect the dependent variable\n\nLast, check the dependent variable by creating a histogram.\n\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Histogram of the dependent variable.](rcbd_files/figure-html/fig-rcbd_hist-1.png){#fig-rcbd_hist width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(var_trial$yield_bu_a, main = \"\", xlab = \"yield\", col = \"turquoise\")\n```\n:::\n\n\n\n\n\nThe range is roughly falling into the range we expect. We (the authors) know this from talking with the person who generated the data, not through our own intuition. There are no large spikes of points at a single value (indicating something odd), nor are there any extreme values (low or high) that might indicate problems.\n\n\nThis data set is ready for analysis!\n\n### Model Building\n\n::: column-margin\nRecall the model:\n\n$$y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}$$\n\nFor this model, $\\alpha_i$ is the variety effect (fixed) and $\\beta_j$ is the block effect (random).\n:::\n\nHere is the R syntax for the RCBD statistical model:\n\n::: panel-tabset\n### lme4\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rcbd_lmer <- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\n```\n:::\n\n\n\n\n\n### nlme\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rcbd_lme <- lme(yield_bu_a ~ variety,\n                  random = ~ 1|block,\n                  data = var_trial, \n                  na.action = na.exclude)\n```\n:::\n\n\n\n\n:::\n\n\n\n### Check Model Assumptions\n\n::::: column-margin\n::: callout-note\nR syntax for checking model assumptions is the same for lme4 and nlme.\n:::\n:::::\n\nRemember those iid assumptions? Let's make sure we actually met them.\n\n#### Original Method {#old-iid-checks}\n\nWe will start inspecting the model assumptions by for checking the homoscedasticity (constant variance) first using a `plot()` function in base R.\n\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Plot of residuals versus fitted values](rcbd_files/figure-html/fig-rcbd_error-1-1.png){#fig-rcbd_error-1 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model_rcbd_lmer, resid(., scaled=TRUE) ~ fitted(.), \n     xlab = \"fitted values\", ylab = \"studentized residuals\")\n```\n:::\n\n\n\n\n\nWe have observed a random and uniform distribution of points. This looks good!\n\nAs explained in [**Chapter 4**](model-flow.qmd) we will first extract residuals using`resid()` and then generate a qq-plot and line.\n\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![QQ-plot of residuals](rcbd_files/figure-html/fig-rcbd_norm-1-1.png){#fig-rcbd_norm-1 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(resid(model_rcbd_lmer), main = NULL); qqline(resid(model_rcbd_lmer))\n```\n:::\n\n\n\n\n\nThis is reasonably good. Things do tend to fall apart at the tails a little, so this is not concerning.\n\n#### New Method {#new-iid-checks}\n\nHere, we will use the `check_model()` function from the **performance** package to look at the normality and linearity of the residuals. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(model_rcbd_lmer, check = c('normality', 'linearity'))\n```\n\n::: {.cell-output-display}\n![](rcbd_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Inference\n\n::::: callout-note\n::: column-margin\nR syntax for estimating model marginal means is the same for lme4 and nlme.\n:::\n:::::\n\nEstimates for each treatment level can be obtained with the **emmeans** package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcbd_emm <- emmeans(model_rcbd_lmer, ~ variety)\nas.data.frame(rcbd_emm) %>% arrange(desc(emmean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n variety                  emmean       SE    df  lower.CL upper.CL\n Rosalyn                155.2703 7.212203 77.85 140.91149 169.6292\n IDO1005                153.5919 7.212203 77.85 139.23310 167.9508\n OR2080641              152.6942 7.212203 77.85 138.33536 167.0530\n Bobtail                151.6403 7.212203 77.85 137.28149 165.9992\n UI Sparrow             151.6013 7.212203 77.85 137.24245 165.9601\n Kaseberg               150.9768 7.212203 77.85 136.61794 165.3356\n IDN-01-10704A          148.9861 7.212203 77.85 134.62729 163.3450\n 06-03303B              148.8300 7.212203 77.85 134.47116 163.1888\n WB1529                 148.2445 7.212203 77.85 133.88568 162.6034\n DAS003                 145.2000 7.212203 77.85 130.84116 159.5588\n IDN-02-29001A          144.5755 7.212203 77.85 130.21665 158.9343\n Bruneau                143.9900 7.212203 77.85 129.63116 158.3488\n SY 107                 143.6387 7.212203 77.85 129.27987 157.9975\n WB 528                 142.9752 7.212203 77.85 128.61633 157.3340\n OR2080637              141.7652 7.212203 77.85 127.40633 156.1240\n Jasper                 141.2968 7.212203 77.85 126.93794 155.6556\n UI Magic CLP           139.5403 7.212203 77.85 125.18149 153.8992\n Madsen                 139.2671 7.212203 77.85 124.90826 153.6259\n LCS Biancor            139.1110 7.212203 77.85 124.75213 153.4698\n SY  Ovation            138.6426 7.212203 77.85 124.28375 153.0014\n OR2090473              137.8229 7.212203 77.85 123.46407 152.1817\n Madsen / Eltan (50/50) 136.9642 7.212203 77.85 122.60536 151.3230\n UI-WSU Huffman         135.4810 7.212203 77.85 121.12213 149.8398\n Mary                   134.8564 7.212203 77.85 120.49762 149.2153\n Norwest Tandem         134.3490 7.212203 77.85 119.99020 148.7079\n Brundage               134.0758 7.212203 77.85 119.71697 148.4346\n IDO1004                132.5145 7.212203 77.85 118.15568 146.8733\n DAS004                 132.2413 7.212203 77.85 117.88245 146.6001\n Norwest Duet           132.0852 7.212203 77.85 117.72633 146.4440\n Eltan                  131.4606 7.212203 77.85 117.10181 145.8195\n LCS Artdeco            130.8361 7.212203 77.85 116.47729 145.1950\n UI Palouse             130.4848 7.212203 77.85 116.12600 144.8437\n LOR-978                130.4458 7.212203 77.85 116.08697 144.8046\n LCS Drive              128.7674 7.212203 77.85 114.40858 143.1262\n Stephens               127.1671 7.212203 77.85 112.80826 141.5259\n OR2100940              126.1523 7.212203 77.85 111.79342 140.5111\n UI Castle CLP          125.5277 7.212203 77.85 111.16891 139.8866\n WB1376 CLP             123.6932 7.212203 77.85 109.33439 138.0521\n LOR-833                122.7565 7.212203 77.85 108.39762 137.1153\n LOR-913                118.7752 7.212203 77.85 104.41633 133.1340\n WB 456                 118.4629 7.212203 77.85 104.10407 132.8217\n SY Assure              111.0468 7.212203 77.85  96.68794 125.4056\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\n\nThis table indicates the estimated marginal means (\"emmeans\", sometimes called \"least squares means\"), the standard error (\"SE\") of those means, the degrees of freedom and the upper and lower bounds of the 95% confidence interval. As an additional step, the emmeans were sorted from largest to smallest.\n\nAt this point, the analysis goals have been met: we know the estimated means for each treatment and their rankings.\n\nIf you want to run ANOVA, it can be done quite easily. By default, sequential (type I) sums of squares is used by **nlme**, but partial (type 3) sums of squares is also possible. Containment is the only degrees of freedom calculation method enabled in **nlme**. The lmer-extender package **lmerTest* implements type 3 tests and the Kenward-Rogers method of degrees of freedom approximation by default.^[The Type I method is called “sequential” sum of squares because it adds terms to the model one at a time; while type 3 (\"partial\") drops model terms one at a time. This can effect the results of an F-test and p-value, but only when a data set is unbalanced across treatments, either due to design or missing data points.]\n\n\nIn this example, there is only one fixed effect, so the sums of squares choice is immaterial. \n\n::: panel-tabset\n### lme4\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(model_rcbd_lmer, type = \"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nType I Analysis of Variance Table with Satterthwaite's method\n        Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \nvariety  18354  447.65    41   123  2.4528 8.017e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n### nlme\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(model_rcbd_lme, type = \"sequential\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            numDF denDF   F-value p-value\n(Intercept)     1   123 2514.1283  <.0001\nvariety        41   123    2.4528   1e-04\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n",
    "supporting": [
      "rcbd_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}