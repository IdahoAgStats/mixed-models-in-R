---
title: "Factorial Design"
---

## Background

Factorial design involves studying the impact of multiple factors simultaneously. Each factor can have multiple levels, and combinations of these levels form the experimental conditions. This design allows us to understand the main effects of individual factors and their interactions on the response variable. The statistical model for factorial design is:
$$y_{ij} = \mu +  \tau_i+ \beta_j + \epsilon_{ij}$$ Where:
$\mu$ = experiment mean, $\tau$ = effect of factor A, $\beta$ = effect of factor B, and $\tau\beta$ = interaction effect of factor A and B.

Assumptions of this model includes: independent and identically distributed error terms with a constant variance.


## Example Analysis
First step is to load the libraries required for the analysis:

::: panel-tabset
### lme4

```{r, message=FALSE, warning=FALSE}
library(lme4); library(lmerTest); library(emmeans)
library(dplyr); library(broom.mixed); library(performance)
```

### nlme

```{r, message=FALSE, warning=FALSE, eval=FALSE}
library(nlme); library(broom.mixed); library(emmeans)
library(dplyr)
```
:::
Next, we will load the data set named 'cochran.factorial' from the 'agridat' package. This data comprises a yield response of beans to different levels of manure (d), nitrogen (n), phosphorus The goal of this analysis is the estimate the effect on d, n, p, k, and their interactions on bean yield.

While importing the data, d, n, p, and k were converted into factor variables using the `mutate()` function.

```{r}
library(agridat)

data1 <- agridat::cochran.factorial %>% 
  mutate(d = as.factor(d),
         n = as.factor(n),
         p = as.factor(p),
         k = as.factor(k))
```
### Data Integrity Checks
Verify the class of variables, where rep, block, d, n, p, and k are supposed to be a factor/character and yield should be numeric/integer. 
```{r}
str(data1)
```
This looks good.

Next, inspect the independent variables and make sure the expected levels are present in the data.
```{r}
table(data1$d, data1$n, data1$p, data1$k)
```
The design looks well balanced.

Last step is to inspect the dependent variable to ensure its distribution is following expectations
```{r, echo=FALSE}
#| label: fig-factorial_hist
#| fig-cap: "Histogram of the dependent variable."
#| column: margin
par(mar=c(5.1, 5, 2.1, 2.1))
hist(data1$yield, main = "", xlab = "yield", cex.lab = 1.8, cex.axis = 1.5)
```
```{r, eval=FALSE}
hist(data1$yield)
```
The range is roughly falling into the expected range. I don't see any extreme values (high or low) which might indicate issues with data.

### Model fitting

Model fitting with R is exactly the same as shown in previous chapters: we need to include all effect, as well as the interaction, which is represented by using the colon indicator ‘:’. Therefore, model syntax is:

`yield ~ d + n + p + k + d:n + d:p + d:k + n:p + n:k + p:k + d:n:p:k`

which can be abbreviated as:

`yield ~ d*n*p*k`

::: panel-tabset
### lme4

```{r, warning=FALSE}
model1 <- lmer(yield ~ d*n*p*k + (1|block),
                   data = data1, 
                   na.action = na.exclude)
tidy(model1)
```
### nlme

```{r, warning=FALSE}
model1 <- lme(yield ~ d*n*p*k,
                  random = ~ 1|block,
                  data = data1, 
                  na.action = na.exclude)
tidy(model1)
```   
:::

::: column-margin
::: callout-note
Instead of `summary()` function, we used `tidy()` function from 'broom.mixed' package to get a short summary output of the model.
:::
:::
### Check Model Assumptions

```{r, fig.height=9, message=FALSE}
check_model(model1)
```
The linearity and homogeneity of variance plots show no trend. The normal Q-Q plots for the overall residuals and for the random effects all fall nearly on a straight line so we can be satisfied with that.
### Inference
We can get an ANOVA table for the linear mixed model using the function `anova()`, which works for both `lmer()` and `lme()` models..
```{r}
anova(model1)
```
Let’s find estimates for some of the factors such as n, p, and n:k interaction. We will try the random intercept model first.
```{r}
emmeans(model1, specs = ~ n)
emmeans(model1, specs = ~ p)
emmeans(model1, specs = ~ n:k)
```

2.  Unbalanced factorial design

### *Data integrity
