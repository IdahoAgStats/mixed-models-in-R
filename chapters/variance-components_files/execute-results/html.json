{
  "hash": "823e0cc5f4ea8877a74332dc3edc8293",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Variance & Variance Components\nexecute:\n  warning: false\n  message: false\n  echo: true\n  error: false\n---\n\n\n\n\n\n\n\n\nMixed, hierarchical or multilevel models provide the advantage of being able to estimate the variance of random variables and model correlations within the grouping structure of random variables. Instead of looking at a variable as a collection of specific levels to estimate, random effects view variables as being a random draw from a probability distribution. \n\nThe decision of how to designate a variable as random or fixed depends on (1) your experimental aims with regard to inference and (2) your data structure. ^[[This animation](http://mfviz.com/hierarchical-models/){.external target=\"_blank\"} show how accounting for grouping structure as random effects can impact the results of a linear model. ]\nThere is a philosophical consider and practical consideration. The philosophical approach is that random variable represents a small sample of a population you want to make inference on. The practical consideration is that when there are few sample levels, the random estimation procedure is not very reliable for those conditions. Ben Bolker has an [excellent summary](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random){.external target=\"_blank\"} that we strongly recommend that you read to learn more about this. Below is an excerpt from that on the consequences of too few levels to estimate a random effect: \n\n> Treating factors with small numbers of levels as random will in the best case lead to very small and/or imprecise estimates of random effects; in the worst case it will lead to various numerical difficulties such as lack of convergence, zero variance estimates, etc.. (A small simulation exercise shows that at least the estimates of the standard deviation are downwardly biased in this case; it’s not clear whether/how this bias would affect the point estimates of fixed effects or their estimated confidence intervals.) In the classical method-of-moments approach these problems may not arise (because the sums of squares are always well defined as long as there are at least two units), but the underlying problems of lack of power are there nevertheless.\n\n\n\n\n\n\n\n\n\n\n\n\n## Variance component estimation for 2 or more random effects\n\n### Multiple crossed variance components\n\nThis is a common scenario: an experiment is conducted and there are multiple grouping levels, none of which are nested within each other, but the observations have multiple group memberships. A common example is a multi-environmental trial where multiple crop genotypes are evaluated at multiple locations and years. We can consider genotypes, locations and years as random effects depending on our experimental aims. Very few R packages can handle crossed random effects, but **lme4** can! \n\nThe data used in this example is a collection of potato field trials conducted across 3 locations and 17 years. Each year, the same potato clones^[A clone is a genetically distinct potato genotype that is vegetatively propagated. It may be a released variety or an experimental breeding line] are evaluated across all 3 locations, but each year, different clones are evaluated. Some clones are evaluted for multiple years, and a small number are evaluted each year. These potato clones were evaluated for the length-to-width ratio (LxW). We want to know how much location, year and clone contribute to this trait.  \n\n\n|       |                               |\n|-------|-------------------------------|\n| year   | year of trial, 16 levels    |\n| state   | location of trial, 3 levels   |\n| clone   | potato genotype |\n| LxW | length-to-width ratio     |\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npotato <- read.csv(here::here(\"data\", \"potato_tuber_size.csv\"))\n```\n:::\n\n\n\n\n\nNumber of observations for each location and year: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naddmargins(table(potato$year, potato$state))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n         ID   OR   WA  Sum\n  2005   30   30   30   90\n  2006   30   30   30   90\n  2007   29   29   29   87\n  2008   25   25   25   75\n  2009   16   17   17   50\n  2010   28   28   28   84\n  2011   18   24   26   68\n  2012   30   32   32   94\n  2013   24   25   25   74\n  2014   33   33   33   99\n  2015   29   31   31   91\n  2016   25   25   25   75\n  2017   18   21   22   61\n  2018   25   25   25   75\n  2019   22   23   23   68\n  2020   23   24   24   71\n  Sum   405  422  425 1252\n```\n\n\n:::\n:::\n\n\n\n\n\nTotal number of clones evaluated: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(unique(potato$clone))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 181\n```\n\n\n:::\n:::\n\n\n\n\n\nTotal counts for how often invividual clones were evaluated:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npotato |> count(clone, name = \"Frequency of Evaluation\") |> count(`Frequency of Evaluation`, name = \"No. of Clones\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Frequency of Evaluation No. of Clones\n1                        2             4\n2                        3            92\n3                        4             1\n4                        6            30\n5                        8             2\n6                        9            20\n7                       10             1\n8                       11             2\n9                       12            11\n10                      13             1\n11                      14             4\n12                      15             8\n13                      16             1\n14                      17             1\n15                      18             1\n16                      91             1\n17                      93             1\n```\n\n\n:::\n:::\n\n\n\n\n\nThe dependent variable, LxW or length-to-width ratio, distribution had a slight left skew, so the the inverse of this trait was modelled. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(1/potato$LxW, ylab=NULL, xlab = NULL,  main = NA, breaks = 20)\n```\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Distribution of Potato Clone Length-to-Width Ratio](variance-components_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n\n#### Model fitting\n\nFor this analysis, location (\"state\") is a fixed effect because it only has 3 levels, and the researchers are only interested in understanding clone performance in those locations (Idaho, Oregon and Washington). The remaining effects are random because (1) they represent a sample of the full population that inference is desired for, and (2) each has a sufficient number of levels to make estimation feasible. \n\nThe statistical model:\n\n$$ y_{ijkl} = \\mu + \\alpha_i + b_j + (\\alpha\\beta)_{ij} + \\gamma_k + \\epsilon_{ijkl}$$\n\n$\\mu$ = model intercept\n\n$\\alpha_i$ = fixed effect of state (3 levels)\n\n$\\beta_j$ = random effect of year (16 levels)\n\n$(\\alpha\\beta)_{ij}$ = random effect of state-by-year interaction (48 levels)\n\n$\\gamma_k$ = random effect of clone (181 levels)\n\n$\\epsilon_{ijkl}$ = error term \n\nThe error terms and all random effects are normally distributed with a mean of zero and a given variance for each term:\n\n$$ \\epsilon \\sim \\mathcal{N}(0, \\sigma^2) $$\n\n$$ \\beta \\sim \\mathcal{N}(0, \\sigma^2_b) $$\n$$ (\\alpha\\beta) \\sim \\mathcal{N}(0, \\sigma^2_a) $$\n\n$$ \\gamma \\sim \\mathcal{N}(0, \\sigma^2_g) $$\n\n\nThe **lme4** syntax:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npotato_m1 <- lmer((1/LxW) ~ state + (1|year) + (1|state:year) + (1|clone),\n                  data = potato)\n```\n:::\n\n\n\n\n\nModel assumption evaluation: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_model(potato_m1, check = c('qq', 'linearity', 'reqq'), detrend=FALSE, alpha = 0)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n#### Inference on random effects\n\nMarginal means of fixed effects can be visualized as demonstrated in previous chapters (e.g. . \n\nThe variance components for each random effect can be extracted most easily using the `tidy()` function from **broom.mixed**. We can also a bit of extra code to calculate the percent of variance explained by each component. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_comps <- tidy(potato_m1, \"ran_pars\", scales = \"vcov\") |> \n  dplyr::select(group, variance = \"estimate\") |> \n  mutate(`percent variance` = round(variance/sum(variance) * 100, 1))\n\nvar_comps\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  group      variance `percent variance`\n  <chr>         <dbl>              <dbl>\n1 clone      0.00344                61.6\n2 state:year 0.000468                8.4\n3 year       0.000301                5.4\n4 Residual   0.00138                24.6\n```\n\n\n:::\n:::\n\n\n\n\n\nThis is a naive method to estimate relative variance components; in particular, heritablity estimates should also take into account the number of locations and year. \n\n::: note-information, collapse=false\n## log likelihood ratio tests\nANOVA as classically defined (F-tests contrasting the between group and within group variation) is not an option for evaluating random effects. There are several ways to test if random effects are impactful on the model overall. One of the most reliable and popular methods is the log likelihood ratio test. In brief, a reduced model is refit from a full specified model omitting a random variable. The log likelihood from the two models (the fully specified and reduced models) are compared, and a p-value is computed for that difference given the change in number of parameters estimated. The null hypothesis is that the models are equivalent and the alternative hypothesis is that the models are not equivalent. Hence, low p-values provide evidence that the omitted factor is impactful on the dependent variable of interest. \n\n:::\n\nThe function `ranova()` in **lmerTest** conducts log-likelihood ratio tests for all random effects in a model.^[It is also possible to conduct likelihood tests manually by constructing reduced models and comparing it to the fully specificed (or more specified) model. In such cases, the fixed effects need to be identical between models, and they need to be fit using maximimun likelihood instead of REML.] \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranova(potato_m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA-like table for random-effects: Single term deletions\n\nModel:\n(1/LxW) ~ state + (1 | year) + (1 | state:year) + (1 | clone)\n                 npar logLik     AIC     LRT Df Pr(>Chisq)    \n<none>              7 2041.9 -4069.7                          \n(1 | year)          6 2039.3 -4066.7    5.07  1    0.02436 *  \n(1 | state:year)    6 1953.7 -3895.4  176.34  1    < 2e-16 ***\n(1 | clone)         6 1477.3 -2942.7 1129.03  1    < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n \nIt is possible to make inferences on specific levels of random effects. This take a different analytical approach than fixed effects and has a different term, predictions, or more specifically Best Linear Unbiased Predictions, commonly called \"BLUPs\" (rhymes with \"cups\"). The estimated marginal means from fixed effects are technically BLUEs, or Best Linear Unbiased Estimates. By their nature, BLUPs \"shrink\" the estimates towards zero, reducing their overall spread compared to fixed effects. [VSNi](https://vsni.co.uk/blogs/BLUPS_BLUES_breeding_values/){.external target=\"_blank\"} has a short summary on BLUPs and BLUEs. \n\nRecall that random effects are distributed with a mean of zero and a standard deviation, $\\sigma_x$ that is estimated in the model fitting procedure. We can add the overall model intercept to all BLUPs in order to shift them to a scale that may be more intuitive for some. Since this constant (the model intercept) was added to all BLUPs, the overall relationship between the them (in this example, potato clones) is unchanged. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the model intercept\nintercept = fixef(potato_m1)[1]\n\n# all random effects from the model\nrandom_effects <- REextract(potato_m1)\n\n# filter to clone BLUPs and add the intercept\nclone_re <- filter(random_effects, groupFctr == \"clone\") |> \n  rename(clone = groupID, BLUP = \"(Intercept)\", SE = \"(Intercept)_se\") |> \n  mutate(blup_adj = BLUP + intercept)\n```\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Histogram of Clone BLUPs](variance-components_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\nBelow are the BLUPs (in red) and standard errors for each clone, arranged from lowest to highest length-to-width ratio. The horizontal gray dotted line indicates the average clone effect. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(clone_re, aes(x = reorder(clone, blup_adj), y = blup_adj)) +\n  geom_hline(yintercept = intercept, color = \"gray\", linetype = 2) + \n  geom_linerange(aes(ymax = blup_adj + SE, ymin = blup_adj - SE)) +\n    geom_point(size = 0.7, col = \"violetred1\") + \n  theme_classic(base_size = 14) +\n  ggtitle(\"length-to-width ratio\") + \n  ylab(\"BLUP + intercept\") + \n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(), \n        axis.title.x = element_blank())\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n### Nested variance components\n\nIt is possible to have a nested data set: learners in a classroom and classrooms in institutions, cows in dairies and dairies in counties or other regional indicators. These end up being truly hierarchical models, where we expect that there is some covariance between observations at the different levels. Cows in the same dairy are likely to be more correlated with each other than cows from another dairy. But how correlated? And how much does each grouping level influence the variation of whatever dependent variable is being studied. \n\nThis example is looking at pay at institutions of higher education in Washington. All annual earnings less than $25,000 were excluded from the data set, and only earners with a minimum of four years of data were included. Although this is public information, all individual names were anonymized.^[This data set ([source](https://govsalaries.com/state/WA)) was incompletely curated and hence no substantive conclusions should be drawn from this particular analysis. This example is for teaching and demonstration purposes only.]\n\nFor this example analysis, our interest is in understanding how much salarie vary within and across Washington State higher educational institutions. In particulr, to what extent did year, the institution itself and the individual employee contribute to salary changes over time. This is an example where we will use random slopes to examine how an individual's salary changed over time. The data set:\n\n|            |                                     |\n|------------|-------------------------------------|\n| agency   | educational institution, 36 levels    |\n| id   |  anonymized employee within each agency, 46,164 levels   |\n| salary  |                          annual salary, continuous |\n| year |     year of salary, set to {0, 1,...4} for {2019, 2020,.. 2023 }    |\n\n\nThis is a rather large data set (218,040 rows), and it requires quite a bit of computing power to analyze. Hence, the analysis was done locally, and the data set and model object were saved as a .RData file. Now let's load this object into an R session. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(here::here(\"data/salary_modeldata.RData\"))\n```\n:::\n\n\n\n\n\nThere is a large number of individuals in this data set. \n\nTotal individuals: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwa_salary |> distinct(agency, id) |> summarise(N = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n      N\n  <int>\n1 46164\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe number of employees per institution ranged dramatically from 107 to 26,568 employees. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwa_salary |> group_by(agency) |> distinct(id) |> \n  summarise(N = n()) |> ungroup() |> arrange(N) |> print(n = 36)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 36 × 2\n   agency                                  N\n   <chr>                               <int>\n 1 Grays Harbor College                  107\n 2 Big Bend Community College            116\n 3 Cascadia Community College            132\n 4 Peninsula Community College           145\n 5 Bellingham Technical College          163\n 6 Bates Technical College               196\n 7 Centralia College                     202\n 8 Wenatchee Valley College              209\n 9 Renton Technical College              214\n10 Lake Washington Technical College     223\n11 Clover Park Technical College         240\n12 Whatcom Community College             243\n13 Skagit Valley College                 249\n14 Walla Walla Community College         254\n15 Lower Columbia Community College      278\n16 South Puget Sound Community College   301\n17 Yakima Valley College                 306\n18 Olympic College                       332\n19 Shoreline Community College           337\n20 Columbia Basin Community College      345\n21 Everett Community College             391\n22 Tacoma Community College              424\n23 The Evergreen State College           447\n24 Green River Community College         460\n25 Highline Community College            474\n26 Pierce Community College              501\n27 Edmonds Community College             525\n28 Clark College                         539\n29 Bellevue Community College            645\n30 Spokane Community College             886\n31 Eastern Washington University         981\n32 Seattle Community College            1098\n33 Central Washington University        1174\n34 Western Washington University        1691\n35 Washington State University          4768\n36 University of Washington            26568\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n### Model fitting\n\nSalary is very skewed, where the 70% of salaries are less than $100,000, but there are a few very high salaries, up to a maximum value of \\$3.1 million. In this analysis, the data are log transformed for a log-linear model. This is a special case of generalized linear mixed model (GLMM); log-linear model follow the assumption of normally-distributed residuals terms when the dependent variable is log-transformed. The salaries are observed to increase a small amount each year. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(log(wa_salary$salary), ylab=NULL, xlab = NULL, main = \"Washington Higher Ed Salaries\")\n```\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Histogram of Log of Washington Higher Ed Salaries](variance-components_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(log(salary) ~ year, data = wa_salary, ylab=NULL, xlab = NULL, main = \"Salaries by Year\")\n```\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Boxpplot of Log Salaries by Year](variance-components_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThe analysis is derived from this model where random intercepts and slopes were fit for institution and individuals nested within institution.\n\n$$  Y_{ijkl} = (\\beta_0 + r1_j) + (\\beta_1 + r2_j)X_{ij} + \\epsilon_{ijkl}$$\n\n$$Y_{ijkl} = \\mu + \\alpha_i + \\beta_j  + \\gamma_k + \\delta_jX_{ij} + \\zeta_kX_{ik} + \\epsilon_{ijkl}$$\n$\\mu$ = model intercept\n\n$\\alpha_i$ = fixed effect of year (5 levels, treated as categorical)\n\n$\\beta_j$ = random intercept of institution (36 levels)\n\n$\\gamma_k$ = random intercept of individual nested within institution (46164 total levels) \n\n$\\delta_j$ = random slope of change over years for each institution\n\n$\\zeta_k$ = random slope of change over years for each individual\n\n$\\epsilon_{ijkl}$ = error term \n\n\n**R LMM Syntax**\n\nRun the model: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lmer(log(salary) ~ factor(year) + (year|agency/id), \n           data = wa_salary, REML = FALSE)\n```\n:::\n\n\n\n\n\nDue to the size of the data set, we cannot display the residual plot because it takes too long to render. \n\n\n\n\n\n\n\n\n\n\n\nObtain the BLUPs: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_effects <- REextract(m1)\n```\n:::\n\n\n\n\n\nSave all object to file for later usage: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave(m1, wa_salary, random_effects, file = here::here(\"data\", \"salary_modeldata.RData\"))\n```\n:::\n\n\n\n\n\n### Inference\n\n##### 1. Variance Components\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVarCorr(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Groups    Name        Std.Dev. Corr  \n id:agency (Intercept) 0.473969       \n           year        0.079368 -0.368\n agency    (Intercept) 0.087550       \n           year        0.016624 -0.674\n Residual              0.158676       \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_comps_salary <- tidy(m1, \"ran_pars\", scales = \"vcov\") |> \n  filter(grepl(\"^var.*\", term)) |> \n  dplyr::select(group, term, variance = \"estimate\") |> \n  mutate(`percent variance` = round(variance/sum(variance) * 100, 1))\n\nvar_comps_salary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  group     term             variance `percent variance`\n  <chr>     <chr>               <dbl>              <dbl>\n1 id:agency var__(Intercept) 0.225                  85.1\n2 id:agency var__year        0.00630                 2.4\n3 agency    var__(Intercept) 0.00767                 2.9\n4 agency    var__year        0.000276                0.1\n5 Residual  var__Observation 0.0252                  9.5\n```\n\n\n:::\n:::\n\n\n\n\n\n#### 2. Examine BLUPs\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# the model intercept\nintercept = fixef(m1)[1]\n\n# all random effects from the model\nrandom_effects <- REextract(m1)\n```\n:::\n\n\n\n\n\n#### 3. Visualize Random Effects \n*(intercepts and slopes)*\n\n* Filter BLUPs to a single factor, \"agency\" (i.e. institute of higher education). \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagency_re <- filter(random_effects, groupFctr == \"agency\") |> \n  rename(Institution = groupID, BLUP = \"(Intercept)\", SE = \"(Intercept)_se\") |> \n  mutate(blup_adj = BLUP + intercept) |> \n  mutate(`salary slope` = ifelse(year > 0, \"+\", \"-\"))\n```\n:::\n\n\n\n\n\n* Plot Salaries by Institution:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(agency_re, aes(x = reorder(Institution, blup_adj), y = blup_adj)) +\n  geom_hline(yintercept = intercept, color = \"gray\", linetype = 2) + \n  geom_linerange(aes(ymax = blup_adj + SE, ymin = blup_adj - SE)) +\n    geom_point(size = 3, col = \"violetred\", shape = 18, alpha = 0.6) + \n  labs(title = \"Institutional Salaries, 2019 - 2024\", subtitle = \"Log of Salaries\") + \n  ylab(\"BLUP + mean and standard error\") + \n  theme_classic(base_size = 14) +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(), \n        axis.title.x = element_blank())\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\n\n* Plot Salary Changes by Institution:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(agency_re) +  # need sequence -0.4 to 0.4\n  geom_abline(aes(slope = year, intercept = blup_adj, col = `salary slope`), alpha = 0.7, linewidth = 0.75) +\n  geom_hline(yintercept = intercept, color = \"black\", linetype = 2) + \n  labs(title = \"Changes in Institutional Salaries, 2019 - 2024\", subtitle = \"Log of Salaries\") + \n  xlim(c(0, 4)) +\n  ylim(c(10.75, 11.3)) + \n  scale_color_manual(values = c(\"springgreen3\", \"violetred\")) +\n  #ylim(c(-0.25, 0.3)) +\n  ylab(\"log salary\") + xlab(\"year\") + \n  theme_bw(base_size = 14) +\n  theme(legend.position = c(0.98, 0.98),\n        legend.justification = c(1,1),\n        legend.background = element_rect(color = \"gray60\", fill = rgb(1, 1, 1, alpha = 0.8)),\n        legend.key = element_rect(fill = \"transparent\"))\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n\n* Examine Relationship Between Employee Salary and Changes in Salary:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperson_re <- filter(random_effects, groupFctr == \"id:agency\") |> \n  rename(employee = groupID, BLUP = \"(Intercept)\", SE = \"(Intercept)_se\") |> \n  mutate(blup_adj = BLUP + intercept) |> \n  mutate(`salary slope` = ifelse(year > 0, \"+\", \"-\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(person_re, aes(x = BLUP, y = year)) +\n  geom_point(alpha = 0.4, color = \"royalblue\") +\n  geom_hline(yintercept = 0, col = \"black\", linetype = 2) +\n  geom_vline(xintercept = 0, col = \"black\", linetype = 2) +\n  labs(title = \"Changes in Employee Salaries, 2019 - 2024\", subtitle = \"(Log of Salaries)\") +\n  xlab(\"random intercept (BLUP) for Employee Salary\") +\n  ylab(\"random slope for Employee salary increase\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis plot illustrates the negative correlation between employee salary and employee salary change indicated by the `VarCorr(m1)` output. \n\nThere are other functions in [**merTools**](https://CRAN.R-project.org/package=merTools){.external target=\"_blank\"} to explore random effects and variances from an `lme4` analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Variance estimation under heteroscedasticity\n\n> In the \"general\" linear model days, when a premium was placed on the i.i.d. error paradigm, if we did reject $H_0$, it would set off a minor crisis in the form of a hunt for a variance stabilizing transformation. In contemporary modeling, we simply proceed with inference on estimable functions using the equal variance model. \n\n\n-- Walt Stroup, Marina Ptukhiuna and Julie Garai (2024), *Generalized Linear Mixed Models*, 2nd Ed, Section 7.2.3.1\n\nIn previous sections, we have assumed the error terms or residuals were \"i.i.d.\", that is \"independently and identically distributed. This means they were shared the same distribution (identical) and were uncorrelated (independent). Longitudinal studies, that is, those with repeated measures, do have correlated residuals, so we relax the independence assumption and model those correlations. However, residuals can be unexpectedly related to the their observations, particular treatments or the order data was gathered from the experimental units (among other causes). As mentioned in the previous quote, we now have tools for handling this rather than trying to transform the data. Below are examples on how to model heteroscedasticity. \n\n### Case 1: Unequal variance due to a factor\n\nThis data set is a set of canola variety trials conducted within a single year across  multiple locations. The trials consist of 38 canola varieties that were evaluated at 9 locations using a RCB design. The goal is to estimate varietal performance at each location as precisely as possible.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_ex1 <- read.csv(here::here(\"data\", \"MET_trial_variance.csv\")) |> \n  mutate(block = as.character(block)) |> \n  tidyr::drop_na()\n```\n:::\n\n\n\n\n\nExploratory data visualizations indicate that the dependent variable, seed yield, varied greatly overall and certain locations had smaller variance compared to others. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-41-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(var_ex1$yield, main=NA)\nboxplot(yield ~ site, data = var_ex1)\n```\n:::\n\n\n\n\n\nThe study is not fully crossed; all sites did not include all varieties, although there is substantial overlap. As a result, only variety and the site-by-variety interaction are included in the statistical model. \n\nWhile it may be possible to implement heterogenous error structures with **lme4**, it requires a good working knowledge of that R package.  is requires extensive comfort programming in **lme4**. However, the package **nlme** contains relatively straightforward implementations that are illustrated below.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_a <- lme(yield ~ site:variety + variety, \n                random = ~ 1 |site/block, \n                na.action = na.exclude, \n                data = var_ex1)\n```\n:::\n\n\n\n\n\nThe residual plot indicates some association between the residuals and fitted values, violating the i.i.d. model assumption.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(m1_a)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can add a term to model the variance by site.\n\n$$Var(\\epsilon_{ij}) = \\sigma^2 \\delta^2_{s_{ij}} $$\nDetails on the implementation can be found in [@nlme_book].\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_b <- update(m1_a, weights = varIdent(form = ~1|site))\n```\n:::\n\n\n\n\n\nThe function `varIdent()` is used to set the stratifying variable at which to estimate variance. Like many functions in R, there are additional arguments to consider for more complex scenarios (type `?varIdent` in an R console to check). \n\n::: {.note}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_b <- update(m1_a, weights = varIdent(form = ~1|site))\n```\n:::\n\n\n\n\n\nis equivalent to\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_b <- lme(yield ~ site:variety + variety, \n                random = ~ 1 |site/block,\n                weights = varIdent(form = ~1|site), \n                na.action = na.exclude, \n                data = var_ex1)\n```\n:::\n\n\n\n\n\n:::\n\nThe residual plot is now much cleaner. The result is a better-fitting model and with that, better inference for variety at the site level. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(m1_b)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n\n```{.r .cell-code}\nanova(m1_a, m1_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Model  df      AIC      BIC    logLik   Test  L.Ratio p-value\nm1_a     1 345 14826.99 16524.62 -7068.493                        \nm1_b     2 353 14499.68 16236.68 -6896.840 1 vs 2 343.3059  <.0001\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_c <- lmer(yield ~ site:variety + variety + (1|site/block),\n                #weights = varIdent(form = ~1|site), \n                na.action = na.exclude, \n                data = var_ex1)\n```\n:::\n\n\n\n\n\n\n### Case 2: Variance is related to the fitted values\n\nBelow is the infamous 'horn' pattern in the residuals-vs-fitted values plot. This analysis is from a canola variety trial of 38 cultivars conducted at single location for one field season. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_ex2 <- read.csv(here::here(\"data\", \"single_trial_variance.csv\")) |> \n  dplyr::mutate(block = as.character(block))\n```\n:::\n\n\n\n\n\nA histogram does indicate there is anything unusual about the dependent variable (seed yield), except that is varies quite a bit, ranging from 24 to nearly 950 units.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(var_ex2$yield, main = NA)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n:::\n\n\n\n\n\nSince this experiment has a single fixed effect and is arranged using a RCBD, the model is same as described in [the RCBD chapter](rcbd.qmd).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2_a <- lme(yield ~ variety, \n               random = ~ 1 |block, \n               na.action = na.exclude, \n               data = var_ex2)\n```\n:::\n\n\n\n\n\nAn inspection of the residual plot indicates a clear mean-variance relationship. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(m2_a)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-54-1.png){width=672}\n:::\n:::\n\n\n\n\nThis mean-variance relationship can be mitigated by modelling the variance directly as a function of any covariate in the model using a power function. \n\n\n$$ Var(\\epsilon_{ij}) = \\sigma^2|\\nu_{ij}|^{2\\delta}$$\n\nWe can accomplish this using the **nlme** function `varPower()`. This function can take other covariates, but when there is no argument provided, it defaults to using the fitted values. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2_b <- update(m2_a, weights = varPower())\n```\n:::\n\n\n\n\n\nThe model fit is substantially improved according to visual inspection of the residuals and the results of a likelihood ratio test. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(m2_b)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-56-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(m2_a, m2_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nm2_a     1 40 1545.596 1655.044 -732.7978                        \nm2_b     2 41 1519.199 1631.383 -718.5996 1 vs 2 28.39636  <.0001\n```\n\n\n:::\n:::\n\n\n\n\n\nThere are many other ways of using these functions for modeling heteroscedasticity. For example, `varIdent()` can include a covariate, and `varPower()` can include a stratifying variable. All or some of the parameters can be fixed at set values. It's worth reading the documentation to understand what is possible.  \n\n### Case 3: Variance is related to a factor under other complex circumstances\n\nRecall the [repeated measures/split-split plot example](repeated-measures.qmd#ssp-rm) that indicated some evidence of heteroscedasticity.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Boxplot of P concentration by stage](variance-components_files/figure-html/fig-split-split-plot_boxplot-1.png){#fig-split-split-plot_boxplot width=672}\n:::\n:::\n\n\n\n\n\n\nWe can model the variance as a function of time point by using the `varIdent()` function shown earlier. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1_b <- update(fit1, weights = varIdent(form = ~1|time))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1_b)\n```\n\n::: {.cell-output-display}\n![](variance-components_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\n\n\n\n\nA comparison of models indicates that 'fit1_b` (with heteroscedascity modelled) is a better fit.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit1, fit1_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nfit1       1 66 2511.987 2722.722 -1189.993                        \nfit1_b     2 68 2508.314 2725.435 -1186.157 1 vs 2 7.672945  0.0216\n```\n\n\n:::\n:::\n\n\n\n\n\nThis change impacts the standard errors: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages({\n  em1 <- as.data.frame(emmeans(fit1, ~ time)) |> mutate(model = \"equal variance\")\n  em2 <- as.data.frame(emmeans(fit1_b, ~ time)) |> mutate(model = \"unequal variance\")\n})\n\nbind_rows(em1, em2) |> dplyr::select(model, time, emmean, SE, df) |> arrange(time, model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             model time    emmean       SE df\n1   equal variance  PT1 3095.5645 47.21842  3\n2 unequal variance  PT1 3095.5645 39.92148  3\n3   equal variance  PT2 2269.5734 47.21842  3\n4 unequal variance  PT2 2269.5734 39.48225  3\n5   equal variance  PT3  197.6457 47.21842  3\n6 unequal variance  PT3  197.6457 37.57384  3\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Coefficient of Variation\n\nThe coefficient of variation can be manually calculated as thus:\n\n$$ \\frac {\\sigma}{\\mu} * 100 $$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_ave <- mean(var_ex1$yield, na.rm = TRUE)\nm1_cv = sigma(m1_b)/m1_ave*100\nround(m1_cv, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 23.3\n```\n\n\n:::\n:::\n\n\n\n\n\nHowever, in cases of unequal variance, the overall error term can be larger than expected under homoscedasticity (with `varIdent()`) or much much smaller (e.g. with `varPower()`). Interpret the coefficient of variation from mixed models with caution. \n\n\n",
    "supporting": [
      "variance-components_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}