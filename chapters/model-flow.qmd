---
title: "Model Preparation and Flow"
---

This chapter provides a brief introduction to the steps involved in data analysis using linear mixed models and some thoughts on data quality and data interpretation. 

add this to callout - tip: The steps explained below were applied to all the chapters. 

Analyzing data using linear mixed models involves several key steps, from data preparation to model interpretation. Here’s a structured approach:

## Define the Research Question 

It's important to know what is your question that you want to answer with your research data. For example, we want to analyze the impact of 3 nitrogen treatments on crop yield. 
This step involves identifying the dependent variable (response variable), determine the fixed and random effects in the experiment design. 

## Data integrity checks 

The first thing is to make sure the data is what we expect. Here are the steps to verify our data:

1.  Check structure of the data 

In this step, we need to make sure data are the expected data type e.g. replication/block are generally in the numeric format. But, for analysis the blocks/replications needs to be in a 'character' or 'factor' format. 
The response variable has be in the 'numeric' format. Sometimes the class of response variable appears to be a character, it's important 

You can use the base code `str()` in R to look at the class of each variable in the data set. 
```{r, eval=FALSE}
str(data)
```


The code chunk below can be used to change the class of variable from numeric to character/factor or vice-versa.
Here the example code below shows the conversion of rep from numeric to factor class and conversion of yield from character to numeric class.
```{r, eval = FALSE}
data$rep <- as.factor(data$rep)
data$yield <- as.numeric(data$yield)
```

::: column-margin
factor v character
integer v numeric
:::


3.  Inspect the independent variables

Running a cross tabulations across treatments and replications is generally enough to make sure the expected levels are present in the data.

```{r, eval=FALSE}
table(data$trt, data$rep)
```

The output from this code will give you the number of observations in each replication for a given treatment. You are supposed to have equal number of observations across treatments. Unbalanced independent variables can affect the fitting, interpretation and performance of mixed model which can result in biased estimates for fixed effects. 

3.  Check the extent of missing data

It's important to check the extent of missing values in the data. 

```{r, eval=FALSE}
colSums(is.na(data))
```

This will give you a number of missing values in each variable. It's an easy identification to 

This is not needed for the data sets in this tutorial that have already been comprehensively examined, but it is helpful to check that the extent of missing values displayed in an R session is what you expect.


Having extreme values in the data can lead to biased estimates, model convergence issues, and incorrect variance estimates. Properly handling missing data through imputation ensures more reliable results.  


If there were independent variables with a continuous distribution (a covariate), plot those data.


4.  Inspect the dependent variable 

Last, check the dependent variable to ensure its distribution is following expectations. A histogram is often quite sufficient to accomplish this. This is designed to be a quick check, so no need to spend time making the plot look good.

The code below does not test for the normality of the response variable. Here we are creating a histogram to look at count of a given values of the response variable. 

The target of this step is to verify the distribution of the variable and to make sure there are no anomalies in the data such as zero-inflation, right or left skewness, or any extreme high/low observations. 

```{r, eval=FALSE}
hist(data$response)
```

Data are not expected to be normally distributed at this point, so don't bother running any Shapiro-Wilk tests. This histogram is a check to ensure that the data are entered correctly and they appear valid. It requires a mixture of domain knowledge and statistical training to know this, but over time, if you look at these plots with regularity, you will gain a feel for what your data should look like at this stage.

These are not complicated checks. They are designed to be done quickly and should be done for **every analysis** if you have not previously inspected your data as thus. We do this before every analysis and often discover surprising things! Best to discover these things early, since they are likely to impact the final analysis.


the structure of data variables, 


- check balance of independent variables 

The purpose of this step is to verify that all treatments have equal number of reps/ observations at each treatment level.





check distribution of the response variable

## Model building - Formula syntax and expectations

In this tutorial, we will demonstrate the methodology to fit linear mixed model using **lme4** and **nlme** package.

The parentheses are used to indicate a random effect, and this particular notation `(1|block)` indicates that a 'random intercept' model is being fit. This is the most common approach. It means there is one overall effect fit for each block. Here, note that random effects are specified differently in the `lmer()` and `nlme()` models. 

The code below shows the R syntax mixed model with one fixed and one random effect:

::: panel-tabset
### lme4

```{r, eval=FALSE}
model_lmer <- lmer(response ~ fixed + (1|random),
                   data = data1, 
                   na.action = na.exclude)
```

### nlme

```{r, eval=FALSE}
model_lme <- lme(response ~ fixed,
                  random = ~ 1|random,
                  data = data1, 
                  na.action = na.exclude)
```
:::

::: callout-note
## `na.action = na.exclude`

You may have noticed the final argument for `na.action` in the model statement:

```         
model_rcbd_lmer <- lmer(yield_bu_a ~ variety + (1|block),
                   data = var_trial, 
                   na.action = na.exclude)
```

The argument `na.action = na.exclude` provides instructions for how to handle missing data. `na.exclude` removes the missing data points before proceeding with the analysis. When any obervation-levels model outputs is generated (e.g. predictions, residuals), they are padded in the appropriate place to account for missing data. This is handy because it makes it easier to add those results to the original data set if so desired.

Even when there are no missing data and this step is not necessary, it's a good habit to be in.
:::



We use the argument `na.action = na.exclude` as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.

## Model Assumptions

Check assumptions:

Residuals should be normally distributed (Q-Q plot).

Check homoscedasticity (residuals vs. fitted values plot).

we are looking for a constant variance and normality of residuals.
Checking normality requiring first extracting the model residuals and then generating a qq-plot and qq-line.
we can do all at one using one function `check_model()`.


Residual normality: Check using Q-Q plots.

Homoscedasticity: Plot residuals vs. fitted values.

Influential points: Use Cook’s distance or leverage analysis.

Random effect distribution: Examine estimated BLUPs.

## Inference


The biggest advantage of mixed models is their incredible flexibility. They handle clustered individuals as well as repeated measures (even in the same model). They handle [crossed](https://www.theanalysisfactor.com/multilevel-models-with-crossed-random-effects/) as well as nested random factors.

The biggest disadvantage of mixed models, at least for someone new to them, is their incredible flexibility. It’s easy to mis-specify a mixed model, and this is a place where a little knowledge is definitely dangerous.

::: callout-warning
## Model inference
Please remember that conclusions cannot be drawn from the model that doesn't meet linear mixed model assumptions. 
:::
