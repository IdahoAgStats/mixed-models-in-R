# Latin Square Design

```{r, include=FALSE, echo=FALSE}
source(here::here("settings.r"))

par(mar=c(5.1, 6, 4.1, 2.1))
```

## Background

In the Latin Square design, two blocking factors are laid out across the row and the column of the square. This allows blocking across rows and columns to reduce even more experimental variability in the trial. The requirement of Latin square design is that all 't' treatments appears only once in each row and column and number of replications is equal to number of treatments.

Advantages of Latin square design are:

1.  The design is particularly appropriate for comparing *t* treatment means in the presence of two sources of extraneous variation, each measured at *t* levels.

2.  Easy to analyze.

Disadvantages:

1. A Latin square can be constructed for any value of *t*, however, it is best suited for comparing *t* treatments when 5≤ *t*≤ 10.

2. Additional sources of variability reduces efficiency and tend to inflate the error term which makes it more difficult to detect differences among the treatments.

3. There must be no interaction of rows and columns with treatment effect. 

Statistical model for a response in Latin square design is:

$Y_{ijk} = \mu + \alpha_i + \beta_j +  \gamma_k + \epsilon_{ijk}$

where, $\mu$ is the experiment mean, $\alpha_i$ represents treatment effect, $\beta$ and $\gamma$ are the row- and column specific effects.

Assumptions of this design includes normality and independent distribution of error ($\epsilon_{ijk}$) terms. And there is no interaction between two blocking (rows & columns) factors and treatments.

## Example Analysis

Let's start the analysis first by loading the required libraries:

::: panel-tabset
### lme4
```{r, message=FALSE, warning=FALSE}
library(lme4); library(lmerTest); library(emmeans); library(performance)
library(dplyr); library(broom.mixed)
```

### nlme
```{r, message=FALSE, warning=FALSE}
library(nlme); library(broom.mixed); library(emmeans); library(performance)
library(dplyr)
```
:::

The data used in this example is from the **agridat** package (data set "goulden.latin"). In this experiment, 5 treatments (A = Dusted before rains. B = Dusted after rains. C = Dusted once each week. D = Drifting, once each week. E = Not dusted) were tested to control stem rust in wheat.

```{r, eval=FALSE, echo=FALSE}
#save data from the package
latin_square <- agridat::goulden.latin
write.csv(latin_square, here::here("data", "goulden_latin.csv"), row.names = FALSE)
```


```{r}
dat <- read.csv(here::here("data", "goulden_latin.csv"))
```

|       |                               |
|-------|-------------------------------|
| trt   | treatment factor, 5 levels    |
| row   | row position for each plot    |
| col   | column position for each plot |
| yield | wheat yield                   |

: Table of variables in the data set {tbl-latin}

### Data integrity checks

- Check structure of the data

First, let's verify the class of variables in the data set using `str()` function in base R

```{r}
str(dat)
```
Here yield and trt are classified as numeric and factor variables, respectively, as needed. But we need to change 'row' and 'col' from integer to factor/character.

```{r}
dat1 <- dat |> 
        mutate(row = as.factor(row),
               col = as.factor(col))
```

- Inspect the independent variables

Next, to verify if the data meets the assumption of the Latin square design let's plot the field layout for this experiment.

```{r, echo=FALSE, warning=FALSE}
desplot::desplot(data = dat1, flip = TRUE,
        form = trt ~ col + row,         
        text = trt, cex = 0.7, shorten = "no", 
        out1 = trt,                          
       # out2 = block,  
        main = "Alpha Lattice Design", show.key =F) 
```

This looks great! Here we can see that there are equal number (5) of treatments, rows, and columns. Treatments were randomized in such a way that one treatment doesn't appear more than once in each row and column.

- Check the extent of missing data

Next step is to check if there are any missing values in response variable.

```{r}
colSums(is.na(dat))
```

No missing values detected in this data set.

- Inspect the dependent variable

Before fitting the model, let's create a histogram of response variable to see if there are extreme values.

```{r, echo=FALSE}
#| label: lattice_design
#| fig-cap: "Histogram of the dependent variable."
#| column: margin
par(mar=c(5.1, 5, 2.1, 2.1))
hist(dat1$yield, main = "", xlab = "yield", col = base_plot_color)
```

```{r, eval=FALSE}
hist(dat1$yield, main = "", xlab = "yield")
```

### Model fitting

Here we will fit a model to evaluate the impact of fungicide treatments on wheat yield with trt as a fixed effect and row & col as a random effect.

::: panel-tabset
### lme4

```{r}
m1_a <- lmer(yield ~ trt + (1|row) + (1|col),
           data = dat1,
           na.action = na.exclude)
summary(m1_a) 
```

### nlme

```{r}
m1_b <- lme(yield ~ trt,
          random =list(~1|row, ~1|col),
          data = dat, 
          na.action = na.exclude)

summary(m1_b)
```
:::

### Check Model Assumptions

This step involves inspection of the model residuals by using `check_model()` function from the **performance** package.

:::: panel-tabset
#### lme4

```{r, fig.height=3}
check_model(m1_a, check = c("linearity", "normality"))
```

#### nlme

::: {.column-body layout-ncol="2"}
```{r, echo=FALSE, eval=FALSE}
par(mar=c(5.1, 5, 2.1, 2.1))
plot(residuals(m1_b), xlab = "fitted values", ylab = "residuals",
     cex.lab = 1.8, cex.axis = 1.5); abline(0,0)
```

```{r, echo=FALSE, eval=FALSE}
par(mar=c(5.1, 5, 2.1, 2.1))
qqvals <- qqnorm(residuals(m1_b), plot.it=FALSE)
qqplot(qqvals$x, qqvals$y, xlab = "Theoretical Quantiles", ylab = "Sample Quantiles", cex.lab = 1.7, cex.axis = 1.5); qqline(residuals(m1_b))
```
:::

```{r, fig.height=3}
check_model(m1_b, check = c("linearity", "normality"))
```
::::

These visuals imply that assumptions of linear model have been met.

### Inference

We can now proceed to the variance partioning. In this case, we will use `anova()` with `type = 1` or `type = "sequential"` for lmer() and lme() models, respectively.

::: panel-tabset
#### lme4

```{r}
anova(m1_a, type = "1")
```

#### nlme

```{r}
anova(m1_b, type = "sequential")
```
:::

Both models have detected a significant treatment effect. Here we observed a significant impact on fungicide treatment on crop yield. Let's have a look at the estimated marginal means of wheat yield with each treatment using `emmeans()` function.

::: panel-tabset
#### lme4

```{r, fig.height=3}
emmeans(m1_a, ~ trt)
```

#### nlme

```{r, fig.height=3}
emmeans(m1_b, ~ trt)
```
:::

We see that wheat yield was higher with 'C' fungicide treatment compared to other fungicides applied in this study. Which implies that 'C' fungicide was more efficient in controlling the stem rust in wheat.
