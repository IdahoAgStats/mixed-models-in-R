---
title: Variance & Variance Components
execute: 
  eval: true
---

Mixed, hierarchical or multilevel models provide the advantage of being able to estimate the variance of random variables and model correlations within the grouping structure of random variables. Instead of looking at a variable as a collection of specific levels to estimate, random effects view variables as being a random draw from a probability distribution. 

The decision of how to designate a variable as random or fixed depends on (1) your experimental aims with regard to inference and (2) your data structure. 

[This animation](http://mfviz.com/hierarchical-models/){.external target="_blank"} show how accounting for grouping structure as random effects can impact the results of a linear model. 



```{r, include=FALSE}
library(dplyr)
library(lme4); library(nlme)
library(lmerTest); library(merTools)
library(emmeans); library(performance)
library(broom.mixed)
library(ggplot2)
```

## Variance component estimation for 2+ random effects

## Multiple crossed variance components

```{r}
potato <- read.csv(here::here("data", "potato_tuber_size.csv"))
```

Number of observations for each location and year: 
```{r}
table(potato$year, potato$state)
```

Total clones evaluated: 
```{r}
length(unique(potato$clone))
```

How often clones were evaluated:
```{r}
potato |> count(clone, name = "n_clone") |> count(n_clone)
```

Distribution of the dependent variable, LxW or length-to-width ratio:
```{r}
hist(potato$LxW)

boxplot(LxW ~ state, data = potato)
```


```{r}
potato_m1 <- lmer(LxW ~ 1 + (1|year) + (1|state) + (1|state:year) + (1|clone),
                  data = potato)
```

```{r}
var_comps <- tidy(potato_m1, "ran_pars", scales = "vcov") |> 
  dplyr::select(group, variance = "estimate") |> 
  mutate(percentage = round(variance/sum(variance) * 100, 1))

var_comps
```

```{r}
ranova(potato_m1)
```
```{r}
intercept = fixef(potato_m1)[1]
random_effects <- REextract(potato_m1)
```

```{r}
clone_re <- filter(random_effects, groupFctr == "clone") |> 
  rename(clone = groupID, BLUP = "(Intercept)", SE = "(Intercept)_se") |> 
  mutate(blup_adj = BLUP + intercept)
```

Recall that random effects are distributed with a mean of zero and a standard deviation, $\sigma_{clone}$ that is estimated in the model fitting procedure. We can add the overall model intercept to all BLUPs in order to put it on a scale that may be more intuitive for some. Since this consant (the model intercept) was added to all BLUPs, the overall relationship between the clones is unchanged. 

```{r}
#| fig-cap: "Histogram of Clone BLUPs"
#| column: margin
hist(clone_re$BLUP, ylab=NULL, xlab = NULL, main = "Clone Random Effects", col = "turquoise")
```

Below are the BLUPs (in red) and standard errors for each clone, arranged from lowest to highest length-to-width ratio. The horizontal gray dotted line indicates the average clone effect. 

```{r}
ggplot(clone_re, aes(x = reorder(clone, blup_adj), y = blup_adj)) +
  geom_hline(yintercept = intercept, color = "gray", linetype = 2) + 
  geom_linerange(aes(ymax = blup_adj + SE, ymin = blup_adj - SE)) +
    geom_point(size = 0.7, col = "red3") + 
  theme_classic(base_size = 14) +
  ggtitle("length-to-width ratio") + 
  ylab("BLUP + intercept") + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(), 
        axis.title.x = element_blank())
```



```{r, eval = FALSE, echo=FALSE}
new_data <- data.frame(clone = unique(potato$clone))
new_data$clone_blups <- predict(potato_m1, newdata = new_data, re.form = ~ (1|clone))

PI <- predictInterval(merMod = potato_m1, 
                        level = 0.95, n.sims = 1000,
                        stat = "median", type="linear.prediction",
                        include.resid.var = FALSE) |> 
  bind_cols(potato)
```


```{r, echo=FALSE, include=FALSE}
rm(list = ls())
gc()
```

## Nested variance components

It is possible to have a nested data set: learners in a classroom and classrooms in institutions, cows in dairies and dairies in counties or other regional indicators. These end up being truly hierarchical models, where we expect that there is some covariance between observations at the different levels. Cows in the same dairy are likely to be more correlated with each other than cows from another dairy. But how correlated? And how much does each grouping level influence the variation of whatever dependent variable is being studied. 

This example is looking at pay at institutions of higher education in Washington. All annual earnings less than $25,000 were excluded from the data set, and only earners with a minimum of four years of data were included. Although this is public information, all individual names were anonymized. ^1

::: column-margin
^1 This data set ([source](https://govsalaries.com/state/WA)) was incompletely curated and hence no substantive conclusions should be drawn from this particular analysis. This example is for teaching and demonstration purposes only. :::

For this data set, we are concerned with what is contributing to employee salaries over time - to what extent did year, the institution itself and the individual employee contribute to salary changes over time. 
This is a rather large data set, and it requires quite a bit of computing power to analyze. Hence, the analysis was done locally. The data set and and the model object were saved as a .RData file for easy loading into this session.

```{r, eval=FALSE}
load("data/salary_models.RData")
```


The analysis is from this model:
```{r, eval=FALSE}
m2 <- lmer(log(salary) ~ factor(year) + (year0|agency/id), 
           data = salary_final, REML = FALSE)
```




## Variance estimation under heteroscedasticity

> In the "general" linear model days, when a premium was placed on the i.i.d. error paradigm, if we did reject $H_0$, it would set off a minor crisis in the form of a hunt for a variance stabilizing transformation. In contemporary modeling, we simply proceed with inference on estimable functions using the equal variance model. 
> 
> -- Walt Stroup, Marina Ptukhiuna and Julie Garai (2024), *Generalized Linear Mixed Models*, $2^{nd}$ Ed, Section 7.2.3.1

In previous sections, we have assumed the error terms or residuals were "i.i.d.", that is "independently and identically distributed. This means they were shared the same distribution (identical) and were uncorrelated (independent). Longitudinal studies, that is, those with repeated measures, do have correlated residuals, so we relax the independence assumption and model those correlations. However, residuals can be unexpectedly related to the their observations, particular treatments or the order data was gathered from the experimental units (among other causes). As mentioned in the previous quote, we now have tools for handling this rather than trying to transform the data. Below are examples on how to model heteroscedasticity. 

### Case 1: unequal variance due to a factor

This data set is from a set of canola variety trials conducted in a single year across  multiple locations. The trials included 38 varieties that were evaluated at 9 locations using a RCBD design. 

```{r}
var_ex1 <- read.csv(here::here("data", "MET_trial_variance.csv")) |> 
  mutate(block = as.character(block)) |> 
  tidyr::drop_na()
```

Exploratory data visualizations indicate that the dependent variable, seed yield, varied greatly overall and certain locations had smaller variance compared to others. 
```{r}
hist(var_ex1$yield)
boxplot(yield ~ site, data = var_ex1)
```
The study is not fully crossed; all sites did not include all varieties, although there is substantial overlap. As a result, only variety and the site-by-variety interaction are included in the statistical model. 

```{r}
m1_a <- lme(yield ~ site:variety + variety, 
                random = ~ 1 |site/block, 
                na.action = na.exclude, 
                data = var_ex1)

```

The residual plot indicates some association between the residuals and fitted values. 
```{r}
plot(m1_a)
```
We can add a term to model the variance by site.

$$Var(\epsilon_{ij}) = \sigma^2 \delta^2_{s_{ij}} $$
Details on the implementation can be found in [@nlme_book].

```{r}
m1_b <- update(m1_a, weights = varIdent(form = ~1|site))
```

The function `varIdent()` is used to set the stratifying variable at which to estimate variance. Like many functions in R, there are additional arguments to consider for more complex scenarios (type `?varIdent` in an R console to check). 

::: {.note}


```{r eval=FALSE}
m1_b <- update(m1_a, weights = varIdent(form = ~1|site))
```

is equivalent to

```{r eval=FALSE}
m1_b <- lme(yield ~ site:variety + variety, 
                random = ~ 1 |site/block,
                weights = varIdent(form = ~1|site), 
                na.action = na.exclude, 
                data = var_ex1)
```

:::

The residual plot is now much cleaner. The result is a better-fitting model and with that, better inference for variety at the site level. 

```{r}
plot(m1_b)
anova(m1_a, m1_b)
```


### Case 2: Variance is related to the fitted values

This is the infamous 'horn' pattern in the residuals-vs-fitted values plot. This is another canola trial using 38 varieties conducted at a single year and single location. 

```{r}
var_ex2 <- read.csv(here::here("data", "single_trial_variance.csv")) |> 
  dplyr::mutate(block = as.character(block))
```

A histogram does indicate there is anything unusual about the dependent variabe (seed yield), except that is varies quite a bit, ranging from 24 to nearly 950 units.
```{r}
hist(var_ex2$yield)
```

Since this experiment has a single fixed effect and is arranged using a RCBD, the model is same as described in [the RCBD chapter](rcbd.qmd).

```{r}
m2_a <- lme(yield ~ variety, 
               random = ~ 1 |block, 
               na.action = na.exclude, 
               data = var_ex2)
```

An inspection of the residual plot indicates a clear mean-variance relationship. 
```{r}
plot(m2_a)
```
This mean-variance relationship can be mitigated by modelling the variance directly as a function of any covariate in the model using a power function. 


$$ Var(\epsilon_{ij}) = \sigma^2|\nu_{ij}|^{2\delta}$$

We can accomplish this using the **nlme** function `varPower()`. This function can take other covariates, but when there is no argument provided, it defaults to using the fitted values. 

```{r}
m2_b <- update(m2_a, weights = varPower())
```

The model fit is substantially improved according to visual inspection of the residuals and the results of a likelihood ratio test. 

```{r}
plot(m2_b)
```
```{r}
anova(m2_a, m2_b)
```

There are many other ways of using these functions for modeling heteroscedasticity. For example, `varIdent()` can include a covariate, and `varPower()` can include a stratifying variable. All or some of the parameters can be fixed at set values. It's worth reading the documentation to understand what is possible.  

### Case 3: Variance is related to a factor under other complex circumstances

Recall the [repeated measures/split-split plot example](repeated-measures.qmd). There was some evidence of 

```{r, echo=FALSE}
load(here::here("data/phos_fit1.RData"))
phos1 <- getData(fit1)
corr_str1 = corCompSymm(form = ~ time1|rep/Ptrt/Inoc/plot, value = 0.2, fixed = FALSE)
```

```{r}
check_model(fit1, check = c('qq', 'linearity'), detrend=FALSE)
```

```{r, echo=FALSE}
#| label: fig-split-split-plot_boxplot
#| fig-cap: "Boxplot of P concentration by stage"
#| column: margin
par(mar=c(5.1, 5, 2.1, 2.1))
boxplot(P_leaf ~ time, data = phos1)
```

We can model the variance as a function of time point by using the `varIdent()` function shown earlier. 

```{r}
fit1_b <- update(fit1, weights = varIdent(form = ~1|time))
```

```{r, fig.height=3}
#| warning: false
#| message: false
check_model(fit1_b, check = c('qq', 'linearity'), line_size = 0, detrend=FALSE)
```

A comparison of models indicates that 'fit1_b` (with heteroscedascity modelled) is a better fit.

```{r}
anova(fit1, fit1_b)
```
The main impact of this change are the standard error for time:

```{r}
emmeans(fit1, ~ time)
emmeans(fit1_b, ~ time)
```


#### Inference

```{r}
#| warning: false
#| message: false
anova(fit1, type = "marginal")
```


```{r}
emmeans(fit1_b, ~ Inoc|Cv)
emmeans(fit1_b, ~ time|Cv)
```



## Coefficient of Variation

The coefficient of variation can be manually calculated as thus:

$$ \frac {\sigma}{\mu} * 100 $$

```{r}
m1_ave <- mean(var_ex1$yield, na.rm = TRUE)
m1_cv = sigma(m1_b)/m1_ave*100
round(m1_cv, 1)
```

However, in cases of unequal variance, the overall error term can be larger than expected under homoscedasticity (with `varIdent()`) or much much smaller (e.g. with `varPower()`). Interpret the coefficient of variation from mixed models with caution. 


