## Repeated measures mixed models

In the previous chapters we covered how to run linear mixed models for different experiment designs. All of the examples in those chapters were independent measure designs, where each subject was assigned to a different treatment. Now we will move on to experiment with repeated measures random effects.

Studies that involve repeated observations of the exact same experimental units require a repeated measures component to properly model correlations across time with the experiment unit. This is common in any perennial crop that is evaluated across years, hay crops subject to repeat cuttings, and many other circumstances. In these models, the 'iid' assumption (idependently and identically distributed) is being violated, so we need to introduce specialized covariance structures that can account for these correlations between error terms.

***ADD STATISTICAL Model here***

\*\*add table for R codes for different covariance structures\*\*

There are several types of covariance structures:

| Structure name    | nlme          | Assumption                                                  |
|------------------------|------------------------|------------------------|
| AR1               | corAR1()      |                                                             |
| Compound symmetry | corCompSymm() | Correlation is equal for all time gaps between observations |
| Unstructures      | CorSymm()     | Correlations are different for the various time gaps        |

The repeated measures syntax in ***nlme*** follow this convention: `form = ~ time|grouping`. You can also use `1|group` and the observation order for each group will be. The default starting value (`value`) is zero, and if `fixed = FALSE` (the current nlme default), this value will be allowed to change during the model fitting process.

There are several other options in the **nlm** machinery (search "cor" for more options and details on the syntax).

Fitting models with correlated observations requires new libraries including mmrm and nlme. lmer allows random effects only.

### Talk about different covariance structures and provide reference for details

Packages required for this tutorial:

```{r}
#| message: false
#| warning: false
library(dplyr) 
library(nlme)
library(mmrm)
library(emmeans)
library(performance)
```

1.  **Repeated Measures RCBD**

The example shown below contains data from a sorghum trial laid out as a randomized complete block design (5 blocks) with variety (4 varieties) treatment effect. The response variable 'y' is the leaf area index assessed in five consecutive weeks on each plot.

We need to have time as numeric and factor variable. In the model, to assess the week effect, week was used as a factor (factweek). For the correlation matrix, week needs to be numeric (week).

```{r}
dat <- agriTutorial::sorghum %>%   
  mutate(week = as.numeric(factweek),
         block = as.character(varblock)) 

str(dat)

```

```{r}
cs1 <- corAR1(form = ~ week|block/factplot,  value = 0.2, fixed = FALSE)
cs2 <- corCompSymm(form = ~ week|block/factplot,  value = 0.2, fixed = FALSE)



lm1 <- lme(y ~ variety + factweek + variety:factweek, random = ~1|block/factplot,
              data = dat,
              na.action = na.exclude)


lm2 <- update(lm1, corr = cs1)
lm3 <- update(lm1, corr= cs2)

# Compare models with different correlation structure using anova()
anova(lm1, lm2, lm3)
```

We can compare the performance of these models (lm1, lm2, lm3) either by using `anova()` or by `compare_performance()` function from the 'performance' library.

```{r}
anova(lm1, lm2, lm3)
## or
result <- compare_performance(lm1, lm2, lm3)
print_md(result)

##model with AR1 correaltion matrix is better
```

## Model Diagnostcis

```{r}
check_model(lm2)
```

## Post-Hoc Analysis

```{r}
anova(lm2)
```

## Emmeans

```{r}

mean_1 <- emmeans(lm2, ~ variety)
mean_1
pairs(mean_1)

mean_2 <- emmeans(lm2, ~ variety:factweek)
mean_2

```

2.  **Split plot repeated measures**
    -   **using mmrm() from mmrm package:**

The example shown below contains yield data in a split-plot design. In this data set, we have:

Variety: 2 levels

Fertilizer: 3 levels

Replications: 4

The yield data was collected repeatedly from the same Reps over 5 'Sample_times'.

This can be analyze either using `nlme` or `mmrm`.

```{r}
library(readr)
Yield <- read_csv(here::here("data/Yield.csv"))
head(Yield)
str(Yield)
```

## Model fit

**using lme() from nlme package.**

To fit model, we first need to convert Variety, Fertilizer, and Sample_time as factors. In addition, we need to create a new variable named 'plot' with a unique value for each plot. The plot will be used as a subject with repeated measures. The subject variable can be factor or numeric but the time (it could be year, or sample_time) has to be a factor.

```{r}
Yield$Variety <- factor(Yield$Variety) 
Yield$Fertilizer <- factor(Yield$Fertilizer) 
Yield$Sample_time1 <- factor(Yield$Sample_time) 
Yield$Rep <- factor(Yield$Rep)  

table(Yield$Fertilizer, Yield$Variety) 

##creating a plot variable 
Yield$plot <- factor(paste(Yield$Rep, Yield$Fertilizer, Yield$Variety, sep='-')) 
Yield$Rep2 <- factor(paste(Yield$Rep, Yield$Variety, sep='-')) 
table(Yield$plot) 
```

## Model fit

```{r}

corr_str1 = corAR1(form = ~ Sample_time|Rep/Variety/plot, value = 0.2, fixed = FALSE)
corr_str2 = corCompSymm(form = ~ Sample_time|Rep/Variety/plot, fixed = FALSE)


# establish model
mod <- lme(Yield ~ Sample_time1*Variety*Fertilizer,
                random = ~ 1|Rep/Variety/plot,
                data = Yield, na.action= na.exclude)

##update model with correlation matrix
mod1 <- update(mod, corr= corr_str1)
mod2 <- update(mod, corr= corr_str2)

##compare different correlation matrices

anova(mod, mod1, mod2)

```

A model with AR1 is better than compared to the model with compound symmetry structure.

### Model diagnostics

```{r}
check_model(mod1)
```

Post-Hoc analysis

```{r}
anova(mod1)
```

```{r}
emm <- emmeans(mod1,~ Fertilizer)
pairs(emm)
```

##### Fitting Model using `mmrm()` from the mmrm package:

```{r}
fit1 <- mmrm(
  formula = Yield ~ Sample_time1*Variety*Fertilizer +  ar1(Sample_time1|Rep/plot),
  data = Yield)


summary(fit1)

```

Model Diagnostics

```{r}
##check_model(asp.fit) ## performance package doesn't work with mmrm class.
plot(residuals(fit1)) 
qqnorm(residuals(fit1)); qqline(residuals(fit1))
```

Anova

```{r}
# type III tests 
car::Anova(fit1)
```

Post-Hoc comparison

```{r}
# cell means 
asp.emm <- emmeans(fit1, c('Variety','Fertilizer')) 
pairs(asp.emm) 
```

3.  **Split-split plot repeated measures**

```{r}
agridat::caribbean.maize
```

```{r}
library(agridat)
data("durban.splitplot")
data("brandle.rape")

data1 <- brandle.rape
table(data1$gen, data1$loc)
```

```{r}
data("hunter.corn")
data2 <- hunter.corn

table(data2$nitro, data2$loc, data2$year)
```

4.  **Factorial design repeated measures**

https://search.r-project.org/CRAN/refmans/agridat/html/gregory.cotton.html

The biggest advantage of mixed models is their incredible flexibility. They handle clustered individuals as well as repeated measures (even in the same model). They handle [crossed random factors](https://www.theanalysisfactor.com/multilevel-models-with-crossed-random-effects/) as well as nested

The biggest disadvantage of mixed models, at least for someone new to them, is their incredible flexibility. It’s easy to mis-specify a mixed model, and this is a place where a little knowledge is definitely dangerous.
