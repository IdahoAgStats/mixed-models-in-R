[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Field Guide to the R Mixed Model Wilderness",
    "section": "",
    "text": "Preface\n“Path in the Wilderness” by Erich Taeubel, Jr.\nRunning mixed models in R is no easy task. There are dozens of packages supporting these aims, each with varying functionality, syntax, and conventions. The linear mixed model ecosystem in R consists of over 80 libraries that either construct and solve mixed model equations or helper packages the process the results from mixed model analysis. These libraries provide a patchwork of overlapping and unique functionality regarding the fundamental structure of mixed models: allowable distributions, nested and crossed random effects, heterogeneous error structures and other facets. No single library has all possible functionality enabled.\nThis patchwork of packages makes it very challenging for statisticians to conduct mixed model analysis and to teach others how to run mixed models in R. The purpose of this guide to to provide some recipes for handling common analytical scenario’s that require mixed models. As a field guide, it is intended to be succinct, and help researchers meet their analytic goals.\nIn general, the content from this website may not be copied or reproduced. However, the example code and required data sets to run the code are MIT licensed. These can be accessed on GitHub.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Field Guide to the R Mixed Model Wilderness",
    "section": "Recent Updates",
    "text": "Recent Updates\nThis is a work-in-progress and will be updated over time.\n\nRCBD lesson has been completed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Terms\nPlease read this section and refer back to if when you forget what these terms mean.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#terms",
    "href": "chapters/intro.html#terms",
    "title": "1  Introduction",
    "section": "",
    "text": "Table 1.1: Terms definitions\n\n\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nRandom effect\nAn independent variable where the levels being estimated compose a random sample from a population whose variance will be estimated\n\n\nFixed effect\nAn independent variable with specific, predefined levels to estimate\n\n\nExperimental unit\nThe smallest unit being used for analysis. This could be an animal, a field plot, a person, a meat or muscle sample. The unit may be assessed multitple times or through multiple point in time. When the analysis is all said and done, the predictions occur at this level.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#packages",
    "href": "chapters/intro.html#packages",
    "title": "1  Introduction",
    "section": "1.2 Packages",
    "text": "1.2 Packages\n\n1.2.1 Table of required packages for modelling\n\n\n\nTable 1.2: Table of required packages\n\n\n\n\n\n\n\n\n\nPackage\nFunction\n\n\n\n\nlme4\nmain package for linear mixed models\n\n\nlmerTest\nfor computing p-values when using lme4\n\n\nnlme\nmain package for linear mixed models\n\n\nemmeans\nfor estimating fixed effects, their confidence intervals and conducting contrasts\n\n\nbroom.mixed\npackage for presenting the model summary output into a tidy workflow.\n\n\nDHARMa\nfor evaluating residuals (error terms) in generalized linear models\n\n\nperformance\nFor creating diagnostic plots or to compute fit measures\n\n\n\n\n\n\n\n\n1.2.2 Optional packages\n\n\n\nTable 1.3: Table of optional packages\n\n\n\n\n\nPackage Name\nFunction\n\n\nhere\nFor setting work directory\n\n\nggplot\nplotting\n\n\ndesplot\nplotting\n\n\nagridat\nto download example dataset\n\n\nagricolae\nto download example dataset\n\n\n\n\n\n\nThis entire guide will use the here package for loading data. If you can load your data fine without ths package, please carry on. {here} is certainly not required for running mixed models.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/analysis-tips.html",
    "href": "chapters/analysis-tips.html",
    "title": "2  Tips on Analysis",
    "section": "",
    "text": "Below are some things I frequently say to researchers.\n\n2.0.1 Think About Your Analytical Goals\nThroughout this guide, we have tried to explicitly state the goals of each analysis. This helps inform us on how to approach the analysis of an experiment. It can be difficult, especially for new scientists-in-training (i.e. graduate students), to understand what it is they want to estimate. You may have been handed a data set you had no role in generating and told to “analyze this” with no additional context. Or perhaps you may have conducted a large study that has some overall goals that are lofty, yet vague.\nIt can helpful to think about the exact results you are hoping to get. What does this look like exactly? Do you want to estimate the changes in plant diversity as the result of a herbicide spraying program? Do you want to find out if a fertilizer treatment changed protein content in a crop and by how much? Do you want to know about changes in human diet due to an intervention? What are quantifiable difference that you and/or experts in your domain would find meaningful?\nConsider what the results would look like for (1) the best case scenario when your wildest dreams come true, and (2) null results, when you find out that your treatment or invention had no effect. It’s very helpful to understand and recognize both situations.\nBy “consider”, we mean: imagine the final plot or table, or summary sentence you want to present, either in a peer-reviewed manuscript, or some output for stakeholders. From this, you work backwards to determine the analytical approach needed to arrive at that final output. Or you may determine that your data are unsuitable to generate the desired output, in which case, it’s best to determine that as soon as possible.\nBy “consider”, we also mean: imagine exactly what the spreadsheet of results would say - what columns are present and what data are in the cells. If you are planning an experiment, this can help ensure you plan it properly to actually test whatever it is you want to evaluate. If the experiment is done, this enables you to evaluate if you have the information present to test your hypothesis.\nBy taking the time to reflect on what it is you exactly want to analyse, this can save time and prevent you from doing unneeded analyses that don’t serve this final goal. There is rarely (never?) one way to analyse an experiment or a data set, so use your limited time wisely and focus on what matters.\n\n\n2.0.2 Data Cleaning is Time Consuming\n\n\n\n\n\n\n\n\n\nFigure 2.1: How you will spend your time\n\n\n\n\nThis has and will continue to occupy the majority of researcher’s time when conducting an analysis. Truly, we a5re sorry for this. But, please know it is not you, it is the nature of data. Please plan for and prepare yourself mentally to spend time cleaning and preparing your data for analysis.1 This will take way longer than the actual analysis! It is needed to ensure you can actually get correct results in an analysis, and hence data cleaning is worth the time it requires.\n1 For an excellent set of basic instructions on data preparation, please see: Broman, K. W., & Woo, K. H. (2018). Data Organization in Spreadsheets. The American Statistician, 72(1), 2–10. https://doi.org/10.1080/00031305.2017.1375989\n\n2.0.3 Interpret ANOVA and P-values with Caution\nSometimes, researchers want to conduct an ANOVA even though we have reached the original goals of analysis. It is important to evaluate why you want to do these extra things, what extra information it will bring and what you plan to do with those results.\nRunning an ANOVA may increase or decrease confidence in the results, depending on what results. That is not at all what ANOVA is intended to do, nor is this what p-values can tell us!\n\nInformally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.\n---American Statistical Association\n\nThe great majority of researched are deeply interested in p-values. This is not a bad thing per se, but sometimes the focus is so strong it comes at the expense of other valuable pieces of information, like treatment estimates! Russ Leanth, author of the emmeans package refers to this practice as “star gazing”.\nThe American Statistics Association recommends that “Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.”2 That article also explains what p-values are telling us and how to avoid committing analytical errors and/or misinterpreting p-values. If you have time to read the full article, it will benefit your research!\n2 Wasserstein, R. L., & Lazar, N. A. (2016). The ASA Statement on p-Values: Context, Process, and Purpose. The American Statistician, 70(2), 129–133. https://doi.org/10.1080/00031305.2016.1154108The main problematic behavior I see is researchers using p-values as the sole criteria on whether to present results: “We wanted to test if x, y and z had an effect. We ran some model and found that that only x had a significant effect, and those results indicate…” (while results with a p-value &gt; 0.05 are ignored).\nA better option would be to discuss the the results of the analysis and how they addressed the research questions: how did the dependent variable change (or not change) as a result of the treatments/interventions/independent variables? What are the parameters or treatment predictions and what do they tell us with regard to the research goals? And to bolster those estimates, what are the confidence intervals on those estimates? What are the p-values for the statistical tests? P-values can support the results and conclusions, but the main results desired by a researcher are usually the estimates themselves - so lead with that!\nTo learn more about common pitfalls in interpreting p-values, check out our blog post on the subject and/or this paper3 on the subject.\n3 Greenland S, Senn SJ, Rothman KJ, Carlin JB, Poole C, Goodman SN, Altman DG. (2016) Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. Eur J Epidemiol. 31(4):337-50. doi: 10.1007/s10654-016-0149-3. https://doi.org/10.1007/s10654-016-0149-3\n\n2.0.4 Comments on Hypothesis Testing and Usage of Treatment Letters\nOften, I see researchers use compact letter display (e.g. “A”, “B”, “C”, ….) for indicating differences among treatments. This makes for concise presentation of results in tables and figures, but it can both kill statistical power and misses nuance in the results.\n\n\n\nImage from a paper published in 2024. Although this was a fully crossed factorial experiment, compact letter display was implemented across all treatment combinations, resulting in some nonsensical comparisons among some informative contrasts.\nImplementing compact letter display can kill statistical power because it requires that all pairwise comparison being made. Doing this, especially when there are many treatment levels, has its perils. The biggest problem is that this creates a multiple testing problem. The RCBD example in this guide has 42 treatments, resulting in a total of 861 comparisons (\\(=42*(42-1)/2\\)), that are then adjusted for multiple tests. With that many tests, a severe adjustment is likely and hence things that are different are not detected. With so many tests, it could be that there is an overall effect due to treatment, but they all share the same letter! Additionally, it could be that not every pairwise combination is of any interest or relevance to the study.\nThe second problem is one of interpretation. Just because two treatments or varieties share a letter does not mean they are equivalent. It only means that they were not found to be different. A funny distinction, but alas. There is an entire branch of statistics, ‘equivalence testing’ devoted to just this topic - how to test if two things are actually the same. This involves the user declaring a maximum allowable numeric difference for a variable in order to determine if two items are statistically different or equivalent - something that these pairwise comparisons are not doing.\nOften, researchers have embedded additional structure in the treatments that is not fully reflected in the statistical model. For example, perhaps a study is looking at five different intercropping mixtures, two that incorporate a legume and 3 that do not. Conducting all pairwise comparisons with miss estimating the difference due to including a legume in an intercropping mix and not incorporating one. Soil fertility and other agronomic studies often have complex treatment structure. When it is not practical or financially feasible to have a full factorial experiment, embedding different treatment combinations in the main factor of analysis can accomplish this. This is a good study design approach, and we have statistical tools to analyze it.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Tips on Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/background.html",
    "href": "chapters/background.html",
    "title": "3  Mixed model theory and background",
    "section": "",
    "text": "3.1 Model\nRecall simple linear regression with intercept (β0) and slope (β1) effect for subject i. The (β0) and (β1) are chosen in a way so that the residual sum of squares is as small as possible.\n\\[  Y = \\beta_0 + \\beta_1(X) + \\epsilon \\]\nIf we consider this model in a mixed model framework, β0 and β1 are considered fixed effects (also known as the population-averaged values) and bi is a random effect for subject i. The random effect can be thought of as each subject’s deviation from the fixed intercept parameter. The key assumption about bi is that it is independent, identically and normally distributed with a mean of zero and associated variance. Random effects are especially useful when we have (1) lots of levels (e.g., many species or blocks), (2) relatively little data on each level (although we need multiple samples from most of the levels), and (3) uneven sampling across levels.\nFor example, if we let the intercept be a random effect, it takes the form:\n\\[  Y = \\beta_0 + b_i + \\beta_1(X) + \\epsilon \\]\nIn this model, predictions would vary depending on each subject’s random intercept term, but slopes would be the same.\nIn second case, we can have a fixed intercept and a random slope. The model will be:\n\\[  Y = \\beta_0 + (\\beta_1 + b_i)(X) + \\epsilon\\]\nIn this model, the bi is a random effect for subject i applied to the slope. Predictions would vary with random slope term, but the intercept will be the same:\nThird case would be the mixed model with random slope and intercept:\n\\[  Y = (\\beta_0 + ai) + (\\beta_1 + b_i)(X) + \\epsilon\\]\nIn this model, ai and bi are random effects for subject i applied to the intercept and slope, respectively. Predictions would vary depending on each subject’s slope and intercept terms:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#model",
    "href": "chapters/background.html#model",
    "title": "3  Mixed model theory and background",
    "section": "",
    "text": "Example mixed model with random intercepts but identical slopes.\n\n\n\n\n\n\n\n\n\n\nMixed model with random slopes but identical intercepts.\n\n\n\n\n\n\n\n\n\n\nMixed Model with random intercept and slope",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#formula-notation",
    "href": "chapters/background.html#formula-notation",
    "title": "3  Mixed model theory and background",
    "section": "3.2 R Formula Syntax for Random and Fixed Effects",
    "text": "3.2 R Formula Syntax for Random and Fixed Effects\nFormula notation is often used in the R syntax for linear models. It looks like this: \\(Y ~ X\\), where Y is the dependent variable (the response) and X is/are the independent variable(s) (e.g. the experimental treatments).\n\nmy_formula &lt;- formula(Y ~ treatment1 + treatment2)\nclass(my_formula)\n\n[1] \"formula\"\n\n\nThe package ‘lmer’ has some additional conventions regarding the formula. Random effects are put in parentheses and a 1| is used to denote random intercepts (rather than random slopes). The table below provides several examples of random effects in mixed models. The names of grouping factors are denoted g, g1, and g2, and covariate as x.\n\n\n\n\n\n\n\n\nFormula\nAlternative\nMeaning\n\n\n\n\n(1 | g)\n1 + (1 | g)\nRandom intercept with a fixed mean\n\n\n(1 | g1/g2)\n(1 | g1) + (1 | g1:g2)\nIntercept varying among g1 and g2 within g1.\n\n\n(1 | g1) + (1 | g2)\n1 + (1 | g1) + (1| g2)\nIntercept varying among g1 and g2.\n\n\nx + (x | g)\n1 + x + (1 + x | g)\nCorrelated random intercept and slope\n\n\nx + (x || g)\n1 + x + (1 | g) + (0 + x | g)\nUncorrelated random intercept and slope.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html",
    "href": "chapters/rcbd.html",
    "title": "4  Randomized Complete Block Design",
    "section": "",
    "text": "4.1 Background\nThe statistical model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\] Where:\n\\(\\mu\\) = overall experimental mean \\(\\alpha\\) = treatment effects (fixed) \\(\\beta\\) = block effects (random) \\(\\epsilon\\) = error terms\n\\[ \\epsilon \\sim N(0, \\sigma)\\]\n\\[ \\beta \\sim N(0, \\sigma_b)\\]\nBoth the overall error and the block effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(sigma_B\\), respectively.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html#background",
    "href": "chapters/rcbd.html#background",
    "title": "4  Randomized Complete Block Design",
    "section": "",
    "text": "‘iid’ assumption for error terms\n\n\n\nIn this model, the error terms, \\(\\epsilon\\) are assumed to be “iid”, that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\nThis guide will later address examples when this assumption is violated and how to handle it.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html#example-analysis",
    "href": "chapters/rcbd.html#example-analysis",
    "title": "4  Randomized Complete Block Design",
    "section": "4.2 Example Analysis",
    "text": "4.2 Example Analysis\nFirst, load the libraries for analysis and estimation:\n\nlme4nlme\n\n\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(performance)\n\n\n\n\nlibrary(nlme); library(performance); library(emmeans)\nlibrary(dplyr)\n\n\n\n\nNext, let’s load some data. It is located here if you want to download it yourself (recommended).\nThis data set is for a single wheat variety trial conducted in Aberdeen, Idaho in 2015. The trial includes 4 blocks and 42 different treatments (wheat varieties in this case). This experiment consists of a series of plots (the experimental unit) laid out in a rectangular grid in a farm field. The goal of this analysis is the estimate the yield and test weight of each variety and the determine the rankings of each variety with regard to yield.\n\nvar_trial &lt;- read.csv(here::here(\"data\", \"aberdeen2015.csv\"))\n\n\nTable of variables in the data set\n\n\n\n\n\n\nblock\nblocking unit\n\n\nrange\ncolumn position for each plot\n\n\nrow\nrow position for each plot\n\n\nvariety\ncrop variety (the treatment) being evaluated\n\n\nstand_pct\npercentage of the plot with actual plants growing in them\n\n\ndays_to_heading_julian\nJulian days (starting January 1st) until plot “headed” (first spike emerged)\n\n\nlodging\npercentage of plants in the plot that fell down and hence could not be harvested\n\n\nyield_bu_a\nyield (bushels per acre)\n\n\n\nThere are several variables present that are not useful for this analysis. The only thing we are concerned about is block, variety, yield_bu_a, and test_weight.\n\n4.2.1 Data integrity checks\nThe first thing is to make sure the data is what we expect. There are two steps:\n\nmake sure data are the expected data type\ncheck the extent of missing data\ninspect the independent variables and make sure the expected levels are present in the data\ninspect the dependent variable to ensure its distribution is following expectations\n\n\nstr(var_trial)\n\n'data.frame':   168 obs. of  10 variables:\n $ block                 : int  4 4 4 4 4 4 4 4 4 4 ...\n $ range                 : int  1 1 1 1 1 1 1 1 1 1 ...\n $ row                   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ variety               : chr  \"DAS004\" \"Kaseberg\" \"Bruneau\" \"OR2090473\" ...\n $ stand_pct             : int  100 98 96 100 98 100 100 100 99 100 ...\n $ days_to_heading_julian: int  149 146 149 146 146 151 145 145 146 146 ...\n $ height                : int  39 35 33 31 33 44 30 36 36 29 ...\n $ lodging               : int  0 0 0 0 0 0 0 0 0 0 ...\n $ yield_bu_a            : num  128 130 119 115 141 ...\n $ test_weight           : num  56.4 55 55.3 54.1 54.1 56.4 54.7 57.5 56.1 53.8 ...\n\n\nThese look okay except for block, which is currently coded as integer (numeric). We don’t want run a regression of block, where block 1 has twice the effect of block 2, and so on. So, converting it to a character will fix that. It can also be converted to a factor, but I find character easier to work with, and ultimately, equivalent to factor conversion\n\nvar_trial$block &lt;- as.character(var_trial$block)\n\nNext, check the independent variables. Running a cross tabulations is often sufficient to ascertain this.\n\ntable(var_trial$variety, var_trial$block)\n\n                        \n                         1 2 3 4\n  06-03303B              1 1 1 1\n  Bobtail                1 1 1 1\n  Brundage               1 1 1 1\n  Bruneau                1 1 1 1\n  DAS003                 1 1 1 1\n  DAS004                 1 1 1 1\n  Eltan                  1 1 1 1\n  IDN-01-10704A          1 1 1 1\n  IDN-02-29001A          1 1 1 1\n  IDO1004                1 1 1 1\n  IDO1005                1 1 1 1\n  Jasper                 1 1 1 1\n  Kaseberg               1 1 1 1\n  LCS Artdeco            1 1 1 1\n  LCS Biancor            1 1 1 1\n  LCS Drive              1 1 1 1\n  LOR-833                1 1 1 1\n  LOR-913                1 1 1 1\n  LOR-978                1 1 1 1\n  Madsen                 1 1 1 1\n  Madsen / Eltan (50/50) 1 1 1 1\n  Mary                   1 1 1 1\n  Norwest Duet           1 1 1 1\n  Norwest Tandem         1 1 1 1\n  OR2080637              1 1 1 1\n  OR2080641              1 1 1 1\n  OR2090473              1 1 1 1\n  OR2100940              1 1 1 1\n  Rosalyn                1 1 1 1\n  Stephens               1 1 1 1\n  SY  Ovation            1 1 1 1\n  SY 107                 1 1 1 1\n  SY Assure              1 1 1 1\n  UI Castle CLP          1 1 1 1\n  UI Magic CLP           1 1 1 1\n  UI Palouse             1 1 1 1\n  UI Sparrow             1 1 1 1\n  UI-WSU Huffman         1 1 1 1\n  WB 456                 1 1 1 1\n  WB 528                 1 1 1 1\n  WB1376 CLP             1 1 1 1\n  WB1529                 1 1 1 1\n\n\nThere are 42 varieties and there appears to be no misspellings among them that might confuse R into thinking varieties are different when they are actually the same. R is sensitive to case and white space, which can make it easy to create near duplicate treatments, such as “eltan” and “Eltan” and “Eltan”. There is no evidence of that in this data set. Additionally, it is perfectly balanced, with exactly one observation per treatment per rep. Please note that this does not tell us anything about the extent of missing data.\n\n\n\n\n\n\nMissing Data\n\n\n\nHere is a quick check to count the number of missing data in each column. This is not neededfor the data sets in this tutorial that have already been comprehensively examined, but it is helpful to check that the level of missingness displayed in an R session is what you expect.\n\napply(var_trial, 2, function(x) sum(is.na(x)))\n\n                 block                  range                    row \n                     0                      0                      0 \n               variety              stand_pct days_to_heading_julian \n                     0                      0                      0 \n                height                lodging             yield_bu_a \n                     0                      0                      0 \n           test_weight \n                     0 \n\n\nAlas, no missing data!\n\n\nIf there were independent variables with a continuous distribution (a covariate), I would plot those data.\nLast, check the dependent variable. A histogram is often quite sufficient to accomplish this. This is designed to be a quick check, so no need to spend time making the plot look good.\n\n\n\n\n\n\n\n\n\nFigure 4.1: Histogram of the dependent variable.\n\n\n\n\n\nhist(var_trial$yield_bu_a, main = \"\", xlab = \"yield\")\n\nThe range is roughly falling into the range we expect. I know this from talking with the person who generated the data, not through my own intuition. I do not see any large spikes of points at a single value (indicating something odd), nor do I see any extreme values (low or high) that might indicate some larger problems.\nData are not expected to be normally distributed at this point, so don’t bother running any Shapiro-Wilk tests. This histogram is a check to ensure the the data are entered correctly and they appear valid. It requires a mixture of domain knowledge and statistical training to know this, but over time, if you look at these plots with regularity, you will gain a feel for what your data should look like at this stage.\nThese are not complicated checks. They are designed to be done quickly and should be done for every analysis if you not previously already inspected the data as thus. We do this before every analysis and often discover surprising things! Best to discover these things early, since they are likely to impact the final analysis.\nThis data set is ready for analysis!\n\n\n4.2.2 Model Building\n\n\nRecall the model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\]\nFor this model, \\(\\alpha_i\\) is the variety effect (fixed) and \\(\\beta_j\\) is the block effect (random).\nHere is the R syntax for the RCBD statistical model:\n\nlme4nlme\n\n\n\nmodel_rcbd_lmer &lt;- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\n\n\n\n\nmodel_rcbd_lme &lt;- lme(yield_bu_a ~ variety,\n                  random = ~ 1|block,\n                  data = var_trial, \n                  na.action = na.exclude)\n\n\n\n\nThe parentheses are used to indicate that ‘block’ is a random effect, and this particular notation (1|block) indicates that a ‘random intercept’ model is being fit. This is the most common approach. It means there is one overall effect fit for each block. I use the argument na.action = na.exclude as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.\n\n\n4.2.3 Check Model Assumptions\n\n\nR syntax for checking model assumptions is the same for lme4 and nlme.\nRemember those iid assumptions? Let’s make sure we actually met them.\n\n4.2.3.1 Old Way\nThere are special plotting function written for lme4 and nlme objects (ie.plot(lmer_object)) for checking the homoscedasticity (constant variance).\n\n\n\n\n\n\n\n\n\nFigure 4.2: Plot of residuals versus fitted values\n\n\n\n\n\nplot(model_rcbd_lmer, resid(., scaled=TRUE) ~ fitted(.), \n     xlab = \"fitted values\", ylab = \"studentized residuals\")\n\nWe are looking for a random and uniform distribution of points. This looks good!\nChecking normality requiring first extracting the model residuals with resid() and then generating a qq-plot and line.\n\n\n\n\n\n\n\n\n\nFigure 4.3: QQ-plot of residuals\n\n\n\n\n\nqqnorm(resid(model_rcbd_lmer), main = NULL); qqline(resid(model_rcbd_lmer))\n\nThis is reasonably good. Things do tend to fall apart at the tails.\n\n\n4.2.3.2 New Way\nNowadays, we can take advantage of the performance package, which provides a comprehensive suite of diagnostic plots.\n\n\nPlease look for check_model() in help tab to find what other checks you can perform using this function. If you would like to check all assumptions you can use check = “all”.\n\ncheck_model(model_rcbd_lmer, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\n4.2.4 Inference\n\n\nR syntax for esimating model marginal means is the same for lme4 and nlme.\nEstimates for each treatment level can be obtained with the ‘emmeans’ package.\n\nrcbd_emm &lt;- emmeans(model_rcbd_lmer, ~ variety)\nas.data.frame(rcbd_emm) %&gt;% arrange(desc(emmean))\n\n variety                  emmean       SE    df  lower.CL upper.CL\n Rosalyn                155.2703 7.212203 77.85 140.91149 169.6292\n IDO1005                153.5919 7.212203 77.85 139.23310 167.9508\n OR2080641              152.6942 7.212203 77.85 138.33536 167.0530\n Bobtail                151.6403 7.212203 77.85 137.28149 165.9992\n UI Sparrow             151.6013 7.212203 77.85 137.24245 165.9601\n Kaseberg               150.9768 7.212203 77.85 136.61794 165.3356\n IDN-01-10704A          148.9861 7.212203 77.85 134.62729 163.3450\n 06-03303B              148.8300 7.212203 77.85 134.47116 163.1888\n WB1529                 148.2445 7.212203 77.85 133.88568 162.6034\n DAS003                 145.2000 7.212203 77.85 130.84116 159.5588\n IDN-02-29001A          144.5755 7.212203 77.85 130.21665 158.9343\n Bruneau                143.9900 7.212203 77.85 129.63116 158.3488\n SY 107                 143.6387 7.212203 77.85 129.27987 157.9975\n WB 528                 142.9752 7.212203 77.85 128.61633 157.3340\n OR2080637              141.7652 7.212203 77.85 127.40633 156.1240\n Jasper                 141.2968 7.212203 77.85 126.93794 155.6556\n UI Magic CLP           139.5403 7.212203 77.85 125.18149 153.8992\n Madsen                 139.2671 7.212203 77.85 124.90826 153.6259\n LCS Biancor            139.1110 7.212203 77.85 124.75213 153.4698\n SY  Ovation            138.6426 7.212203 77.85 124.28375 153.0014\n OR2090473              137.8229 7.212203 77.85 123.46407 152.1817\n Madsen / Eltan (50/50) 136.9642 7.212203 77.85 122.60536 151.3230\n UI-WSU Huffman         135.4810 7.212203 77.85 121.12213 149.8398\n Mary                   134.8564 7.212203 77.85 120.49762 149.2153\n Norwest Tandem         134.3490 7.212203 77.85 119.99020 148.7079\n Brundage               134.0758 7.212203 77.85 119.71697 148.4346\n IDO1004                132.5145 7.212203 77.85 118.15568 146.8733\n DAS004                 132.2413 7.212203 77.85 117.88245 146.6001\n Norwest Duet           132.0852 7.212203 77.85 117.72633 146.4440\n Eltan                  131.4606 7.212203 77.85 117.10181 145.8195\n LCS Artdeco            130.8361 7.212203 77.85 116.47729 145.1950\n UI Palouse             130.4848 7.212203 77.85 116.12600 144.8437\n LOR-978                130.4458 7.212203 77.85 116.08697 144.8046\n LCS Drive              128.7674 7.212203 77.85 114.40858 143.1262\n Stephens               127.1671 7.212203 77.85 112.80826 141.5259\n OR2100940              126.1523 7.212203 77.85 111.79342 140.5111\n UI Castle CLP          125.5277 7.212203 77.85 111.16891 139.8866\n WB1376 CLP             123.6932 7.212203 77.85 109.33439 138.0521\n LOR-833                122.7565 7.212203 77.85 108.39762 137.1153\n LOR-913                118.7752 7.212203 77.85 104.41633 133.1340\n WB 456                 118.4629 7.212203 77.85 104.10407 132.8217\n SY Assure              111.0468 7.212203 77.85  96.68794 125.4056\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\nThis table indicates the estimated marginal means (“emmeans”, sometimes called “least squares means”), the standard error (“SE”) of those means, the degrees of freedom and the upper and lower bounds of the 95% confidence interval. As an additional step, the emmeans were sorted from largest to smallest.\nAt this point, the analysis goals have been met: we know the estimated means for each treatment and their rankings.\nIf you want to run ANOVA, it can be done quite easily. By default, the Kenward-Rogers method of degrees of freedom approximation is used.\n\n\nThe Type I method is sometimes referred to as the “sequential” sum of squares, because it involves a process of adding terms to the model one at a time. Type I sum of squares is the default hypothesis testing method used by the anova() function.\n\nlme4nlme\n\n\n\nanova(model_rcbd_lmer, type = \"1\")\n\nType I Analysis of Variance Table with Satterthwaite's method\n        Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nvariety  18354  447.65    41   123  2.4528 8.017e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model_rcbd_lme, type = \"sequential\")\n\n            numDF denDF   F-value p-value\n(Intercept)     1   123 2514.1283  &lt;.0001\nvariety        41   123    2.4528   1e-04\n\n\n\n\n\n\n\n\n\n\n\nna.action = na.exclude\n\n\n\nYou may have noticed the final argument for na.action in the model statement:\nmodel_rcbd_lmer &lt;- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\nThe argument na.action = na.exclude provides instructions for how to handle missing data. na.exclude removes the missing data points before proceeding with the analysis. When any obervation-levels model outputs is generated (e.g. predictions, residuals), they are padded in the appropriate place to account for missing data. This is handy because it makes it easier to add those results to the original data set if so desired.\nSince there are no missing data, this step was not strictly necessary, but it’s a good habit to be in.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html",
    "href": "chapters/split-plot-design.html",
    "title": "5  Split Plot Design",
    "section": "",
    "text": "5.1 Details for Split Plot Designs\nThe statistical model structure this design:\n\\[y_{ijk} = \\mu + \\alpha_i + \\beta_k + (\\alpha_j\\beta_k) + \\epsilon_{ij} + \\delta_{ijk} \\] Where:\n\\(\\mu\\)= overall experimental mean, \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\tau\\) = interaction between factors A and B, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\\[ \\epsilon \\sim N(0, \\sigma_\\epsilon)\\]\n\\[\\ \\delta  \\sim N(0, \\sigma_\\delta)\\]\nBoth the error and the rep effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma_\\epsilon\\) and \\(\\sigma_\\delta\\), respectively.\nThis is also referred as “Split-Block RCB” design. The statistical model structure for split plot design:\n\\[y_{ijk} = \\mu + \\rho_j +  \\alpha_i + \\beta_k + (\\alpha_i\\beta_k) + \\epsilon_{ij} + \\delta_{ijk}\\] Where:\n\\(\\mu\\) = overall experimental mean, \\(\\rho\\) = block effect (random), \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\beta\\) = interaction between factors A and B, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\\[ \\epsilon \\sim N(0, \\sigma_\\epsilon)\\]\n\\[\\ \\delta  \\sim N(0, \\sigma_\\delta)\\]\nBoth the overall error and the rep effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(\\sigma_\\delta\\), respectively.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html#details-for-split-plot-designs",
    "href": "chapters/split-plot-design.html#details-for-split-plot-designs",
    "title": "5  Split Plot Design",
    "section": "",
    "text": "Whole Plot Randomized as a completely randomized design\n\n\n\n\n\n\n\n\nWhole Plot Randomized as an RCBD\n\n\n\n\n\n\n\n\n\n\n\n\n\n‘iid’ assumption for error terms\n\n\n\nIn these model, the error terms, \\(\\epsilon\\) are assumed to be “iid”, that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\n\n\n\n\n\nSplit Plot CRD Design\n\n\n\n\n\nSplit Plot RCBD Design",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html#analysis-examples",
    "href": "chapters/split-plot-design.html#analysis-examples",
    "title": "5  Split Plot Design",
    "section": "5.2 Analysis Examples",
    "text": "5.2 Analysis Examples\nLoad required libraries\n\nlme4nlme\n\n\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(performance); library(ggplot2)\nlibrary(broom.mixed)\n\n\n\n\nlibrary(nlme); library(performance); library(emmeans)\nlibrary(dplyr); library(ggplot2); library(broom.mixed)\n\n\n\n\n\n5.2.1 Example model for CRD Split Plot Designs\nLet’s import height data. It is located here if you want to download it yourself (recommended).\nThe data (Height data) for this example involves a CRD split plot designed experiment. Treatments are 4 Timings (times) and 8 managements (manage). The whole plots are times and management represents subplot and 3 replications.\n\nheight_data &lt;- readxl::read_excel(here::here(\"data\", \"height_data.xlsx\"))\n\n\nTable of variables in the oat data set\n\n\nrep\nreplication unit\n\n\ntime\nMain plot with 4 levels\n\n\nManage\nSplit-plot with 8 levels\n\n\nsample\ntwo sampling units per each rep\n\n\nheight\nyield (lbs per acre)\n\n\n\n\n5.2.1.1 Data integrity checks\n\nRun a cross tabulation using table() to check the arrangement of whole-plots and sub-plots.\n\n\ntable(height_data$time, height_data$manage)\n\n    \n     M1 M2 M3 M4 M5 M6 M7 M8\n  T1  6  6  6  6  6  6  6  6\n  T2  6  6  6  6  6  6  6  6\n  T3  6  6  6  6  6  6  6  6\n  T4  6  6  6  6  6  6  6  6\n\n\nThe levels of whole plots and subplots are balanced.\n\nLook at structure of the data using str(), this will help in identifying class of the variable. In this data set, class of the whole-plot, sub-plot, and block should be factor/character and response variable (height) should be numeric.\n\n\nstr(height_data)\n\ntibble [192 × 5] (S3: tbl_df/tbl/data.frame)\n $ time  : chr [1:192] \"T1\" \"T1\" \"T1\" \"T1\" ...\n $ manage: chr [1:192] \"M1\" \"M2\" \"M3\" \"M4\" ...\n $ rep   : chr [1:192] \"R1\" \"R1\" \"R1\" \"R1\" ...\n $ sample: chr [1:192] \"S1\" \"S1\" \"S1\" \"S1\" ...\n $ height: num [1:192] 104.5 92.3 96.8 94.7 105.7 ...\n\n\nThe ‘time’, ‘manage’, and ‘rep’ are character and variable height is numeric. The structure of the data is in format as needed. - Check the number of missing values in each column.\n\napply(height_data, 2, function(x) sum(is.na(x)))\n\n  time manage    rep sample height \n     0      0      0      0      0 \n\n\n\nExploratory boxplot to look at the height observations at different times with variable managements.\n\n\nggplot(data = height_data, aes(y = height, x = time)) +\n  geom_boxplot(aes(fill = manage), alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n5.2.1.2 Model building\n\n\nRecall the model:\n\\[y_{ijk} = \\mu + \\gamma_i +  \\alpha_j + \\beta_k + (\\alpha_j\\beta_k) + \\epsilon_{ijk}\\]\nFor this model, \\(\\gamma\\) = block/rep effect (random), \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\beta\\) = interaction between factors A and B (fixed).\nIn order to test the main effects of the treatments as well as the interaction between two factors, we can specify that in model as: time + manage + time:manage or time*manage.\nWhen dealing with split plot design across reps or blocks, the random effects needs to be nested hierarchically, from largest unit to smallest. For example, in this example the random effects will be designated as (1 | rep/time). This implies that random intercepts vary with rep and time within rep.\n\nlme4nlme\n\n\n\nmodel_lmer &lt;- lmer(height ~ time*manage + (1|rep/time), data = height_data)\ntidy(model_lmer)\n\n# A tibble: 35 × 8\n   effect group term        estimate std.error statistic     df    p.value\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 fixed  &lt;NA&gt;  (Intercept)   108.        3.19    33.9     4.38 0.00000181\n 2 fixed  &lt;NA&gt;  timeT2          3.18      2.63     1.21  104.   0.229     \n 3 fixed  &lt;NA&gt;  timeT3         -2.25      2.63    -0.855 104.   0.394     \n 4 fixed  &lt;NA&gt;  timeT4          1.28      2.63     0.488 104.   0.627     \n 5 fixed  &lt;NA&gt;  manageM2       -4.45      2.55    -1.74  152.   0.0832    \n 6 fixed  &lt;NA&gt;  manageM3       -5.30      2.55    -2.08  152.   0.0395    \n 7 fixed  &lt;NA&gt;  manageM4       -6.18      2.55    -2.42  152.   0.0166    \n 8 fixed  &lt;NA&gt;  manageM5       -5.02      2.55    -1.97  152.   0.0511    \n 9 fixed  &lt;NA&gt;  manageM6       -3.42      2.55    -1.34  152.   0.183     \n10 fixed  &lt;NA&gt;  manageM7       -9.75      2.55    -3.82  152.   0.000193  \n# ℹ 25 more rows\n\n\n\n\n\nmodel_lme &lt;-lme(height ~ time*manage,\n             random = ~ 1|rep/time, data = height_data)\n\ntidy(model_lme)\n\nWarning in tidy.lme(model_lme): ran_pars not yet implemented for multiple\nlevels of nesting\n\n\n# A tibble: 32 × 7\n   effect term        estimate std.error    df statistic  p.value\n   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  (Intercept)   108.        3.19   152    33.9   9.59e-73\n 2 fixed  timeT2          3.18      2.63     6     1.21  2.72e- 1\n 3 fixed  timeT3         -2.25      2.63     6    -0.855 4.25e- 1\n 4 fixed  timeT4          1.28      2.63     6     0.488 6.43e- 1\n 5 fixed  manageM2       -4.45      2.55   152    -1.74  8.32e- 2\n 6 fixed  manageM3       -5.30      2.55   152    -2.08  3.95e- 2\n 7 fixed  manageM4       -6.18      2.55   152    -2.42  1.66e- 2\n 8 fixed  manageM5       -5.02      2.55   152    -1.97  5.11e- 2\n 9 fixed  manageM6       -3.42      2.55   152    -1.34  1.83e- 1\n10 fixed  manageM7       -9.75      2.55   152    -3.82  1.93e- 4\n# ℹ 22 more rows\n\n\n\n\n\n\n\n5.2.1.3 Check Model Assumptions\nBefore interpreting the model we should investigate the assumptions of the model to ensure any conclusions we draw are valid. There are assumptions that we can check are 1. Homogeneity (equal variance) 2. normality of residuals 3. values with high leverage.\nWe will use check_model() function from ‘performance’ package. The plots generated using this code gives a visual check of various assumptions including normality of residuals, normality of random effects, heteroscedasticity, homogeneity of variance, and multicollinearity.\n\nlme4nlme\n\n\n\ncheck_model(model_lmer, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model_lme, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\nIn this case the residuals fit the assumptions of the model well.\n\n\n5.2.1.4 Inference\nThe anova() function prints the the rows of analysis of variance table for whole-plot, sub-plot, and their interactions. We observed a significant effect of manage factor only.\n\nlme4nlme\n\n\n\ncar::Anova(model_lmer, type = 'III', test.statistics = \"F\")\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: height\n                Chisq Df Pr(&gt;Chisq)    \n(Intercept) 1148.5658  1    &lt; 2e-16 ***\ntime           4.5139  3    0.21105    \nmanage        15.9090  7    0.02596 *  \ntime:manage   24.3349 21    0.27711    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model_lme, type = \"marginal\")\n\n            numDF denDF   F-value p-value\n(Intercept)     1   152 1148.6202  &lt;.0001\ntime            3     6    1.5046  0.3061\nmanage          7   152    2.2727  0.0315\ntime:manage    21   152    1.1588  0.2955\n\n\n\n\n\nWe can further compute estimated marginal means for each fixed effect and interaction effect can be obtained using emmeans().\n\nlme4nlme\n\n\n\nm1 &lt;- emmeans(model_lmer, ~ time)\n\nNOTE: Results may be misleading due to involvement in interactions\n\nm1\n\n time emmean  SE   df lower.CL upper.CL\n T1      103 2.7 2.27     92.8      114\n T2      106 2.7 2.27     95.5      116\n T3      100 2.7 2.27     89.8      111\n T4      104 2.7 2.27     94.0      115\n\nResults are averaged over the levels of: manage \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n\nm2 &lt;- emmeans(model_lme, ~ time)\n\nNOTE: Results may be misleading due to involvement in interactions\n\nm2\n\n time emmean  SE df lower.CL upper.CL\n T1      103 2.7  2     91.6      115\n T2      106 2.7  2     94.2      118\n T3      100 2.7  2     88.6      112\n T4      104 2.7  2     92.8      116\n\nResults are averaged over the levels of: manage \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\nFurther, a pairwise comparison or contrasts can be analyzed using estimated means. In this model, ‘time’ factor has 4 levels. We can use pairs() function to evaluate pairwise comparison among different ‘time’ levels.\nHere’s a example using pairs() function to compare difference in height among different time points.\n\nlme4nlme\n\n\n\npairs(m1)\n\n contrast estimate   SE df t.ratio p.value\n T1 - T2     -2.68 1.11  6  -2.426  0.1719\n T1 - T3      2.95 1.11  6   2.665  0.1287\n T1 - T4     -1.21 1.11  6  -1.091  0.7072\n T2 - T3      5.63 1.11  6   5.091  0.0089\n T2 - T4      1.48 1.11  6   1.334  0.5767\n T3 - T4     -4.15 1.11  6  -3.756  0.0358\n\nResults are averaged over the levels of: manage \nDegrees-of-freedom method: kenward-roger \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\n\n\n\npairs(m2)\n\n contrast estimate   SE df t.ratio p.value\n T1 - T2     -2.68 1.11  6  -2.426  0.1719\n T1 - T3      2.95 1.11  6   2.665  0.1287\n T1 - T4     -1.21 1.11  6  -1.091  0.7072\n T2 - T3      5.63 1.11  6   5.091  0.0089\n T2 - T4      1.48 1.11  6   1.334  0.5767\n T3 - T4     -4.15 1.11  6  -3.756  0.0358\n\nResults are averaged over the levels of: manage \nDegrees-of-freedom method: containment \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\n\n\n\n\n\n\n\n\n\npairs()\n\n\n\nThe default p-value adjustment in pairs() function is “tukey”, other options include “holm”, “hochberg”, “BH”, “BY”, and “none”. In addition, it’s okay to use this function when independent variable has few factors (2-4). For variable with multiple levels, it’s better to use custom contrasts. For more information on custom contrasts please check this link.\n\n\n\n\n\n5.2.2 Example model for RCBD Split Plot Designs\nThe oats data used in this example is from the MASS package. The design is RCBD split plot with 6 blocks, 3 main plots and 4 subplots. The primary outcome variable was oat yield.\n\nTable of variables in the oat data set\n\n\nblock\nblocking unit\n\n\nVariety (V)\nMain plot with 3 levels\n\n\nNitrogen (N)\nSplit-plot with 4 levels\n\n\nyield (Y)\nyield (lbs per acre)\n\n\n\nThe objective of this analysis is to study the impact of different varieties and nitrogen application rates on oat yields.\nTo fully examine the yield of oats due to varieties and nutrient levels in a split plots. We will need to statistically analyse and compare the effects of varieties (main plot), nutrient levels (subplot), their interaction.\n\nlibrary(MASS)\ndata(\"oats\")\nhead(oats,5)\n\n  B           V      N   Y\n1 I     Victory 0.0cwt 111\n2 I     Victory 0.2cwt 130\n3 I     Victory 0.4cwt 157\n4 I     Victory 0.6cwt 174\n5 I Golden.rain 0.0cwt 117\n\n\n\n5.2.2.1 Data integrity checks\nLet’s look at the structure of the data. The “B”, “V”, and “N” needs to be ‘factor’ and “Y” should be numeric.\n\nstr(oats)\n\n'data.frame':   72 obs. of  4 variables:\n $ B: Factor w/ 6 levels \"I\",\"II\",\"III\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ V: Factor w/ 3 levels \"Golden.rain\",..: 3 3 3 3 1 1 1 1 2 2 ...\n $ N: Factor w/ 4 levels \"0.0cwt\",\"0.2cwt\",..: 1 2 3 4 1 2 3 4 1 2 ...\n $ Y: int  111 130 157 174 117 114 161 141 105 140 ...\n\n\nNext, run the table() command to verify the levels of main-plots and sub-plots.\n\ntable(oats$V, oats$N)\n\n             \n              0.0cwt 0.2cwt 0.4cwt 0.6cwt\n  Golden.rain      6      6      6      6\n  Marvellous       6      6      6      6\n  Victory          6      6      6      6\n\n\n\n\n5.2.2.2 Model Building the Model\nWe are evaluating the effect of V, N and their interaction on yield. The 1|B/V implies that random intercepts vary with block and V within each block.\n\n\nRecall the model:\n\\[y_{ijk} = \\mu + \\rho_j +  \\alpha_i + \\beta_k + (\\alpha_i\\beta_k) + \\epsilon_{ij} + \\delta_{ijk}\\] Where:\n\\(\\mu\\) = overall experimental mean, \\(\\rho\\) = block effect (random), \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\beta\\) = interaction between factors A and B, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\nlme4nlme\n\n\n\nmodel2_lmer &lt;- lmer(Y ~  V + N + V:N + (1|B/V), \n                   data = oats, \n                   na.action = na.exclude)\ntidy(model2_lmer)\n\n# A tibble: 15 × 8\n   effect   group    term            estimate std.error statistic    df  p.value\n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed    &lt;NA&gt;     (Intercept)       80.0        9.11    8.78    16.1  1.55e-7\n 2 fixed    &lt;NA&gt;     VMarvellous        6.67       9.72    0.686   30.2  4.98e-1\n 3 fixed    &lt;NA&gt;     VVictory          -8.50       9.72   -0.875   30.2  3.89e-1\n 4 fixed    &lt;NA&gt;     N0.2cwt           18.5        7.68    2.41    45.0  2.02e-2\n 5 fixed    &lt;NA&gt;     N0.4cwt           34.7        7.68    4.51    45.0  4.58e-5\n 6 fixed    &lt;NA&gt;     N0.6cwt           44.8        7.68    5.84    45.0  5.48e-7\n 7 fixed    &lt;NA&gt;     VMarvellous:N0…    3.33      10.9     0.307   45.0  7.60e-1\n 8 fixed    &lt;NA&gt;     VVictory:N0.2c…   -0.333     10.9    -0.0307  45.0  9.76e-1\n 9 fixed    &lt;NA&gt;     VMarvellous:N0…   -4.17      10.9    -0.383   45.0  7.03e-1\n10 fixed    &lt;NA&gt;     VVictory:N0.4c…    4.67      10.9     0.430   45.0  6.70e-1\n11 fixed    &lt;NA&gt;     VMarvellous:N0…   -4.67      10.9    -0.430   45.0  6.70e-1\n12 fixed    &lt;NA&gt;     VVictory:N0.6c…    2.17      10.9     0.199   45.0  8.43e-1\n13 ran_pars V:B      sd__(Intercept)   10.3       NA      NA       NA   NA      \n14 ran_pars B        sd__(Intercept)   14.6       NA      NA       NA   NA      \n15 ran_pars Residual sd__Observation   13.3       NA      NA       NA   NA      \n\n\n\n\n\nmodel2_lme &lt;- lme(Y ~  V + N + V:N ,\n                  random = ~1|B/V,\n                  data = oats, \n                  na.action = na.exclude)\ntidy(model2_lme)\n\nWarning in tidy.lme(model2_lme): ran_pars not yet implemented for multiple\nlevels of nesting\n\n\n# A tibble: 12 × 7\n   effect term                estimate std.error    df statistic  p.value\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  (Intercept)           80          9.11    45    8.78   2.56e-11\n 2 fixed  VMarvellous            6.67       9.72    10    0.686  5.08e- 1\n 3 fixed  VVictory              -8.50       9.72    10   -0.875  4.02e- 1\n 4 fixed  N0.2cwt               18.5        7.68    45    2.41   2.02e- 2\n 5 fixed  N0.4cwt               34.7        7.68    45    4.51   4.58e- 5\n 6 fixed  N0.6cwt               44.8        7.68    45    5.84   5.48e- 7\n 7 fixed  VMarvellous:N0.2cwt    3.33      10.9     45    0.307  7.60e- 1\n 8 fixed  VVictory:N0.2cwt      -0.333     10.9     45   -0.0307 9.76e- 1\n 9 fixed  VMarvellous:N0.4cwt   -4.17      10.9     45   -0.383  7.03e- 1\n10 fixed  VVictory:N0.4cwt       4.67      10.9     45    0.430  6.70e- 1\n11 fixed  VMarvellous:N0.6cwt   -4.67      10.9     45   -0.430  6.70e- 1\n12 fixed  VVictory:N0.6cwt       2.17      10.9     45    0.199  8.43e- 1\n\n\n\n\n\n\n\n5.2.2.3 Check Model Assumptions\nAs shown in example 1, We need to verify the normality of residuals and homogeneous variance. Here we are using the check_model() function from the performance package.\n\nlme4nlme\n\n\n\ncheck_model(model2_lmer, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model2_lme, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.2.4 Inference\nWe can evaluate the model for the analysis of variance, for V, N and their interaction effect.\n\nlme4nlme\n\n\n\ncar::Anova(model2_lmer, type = \"III\", test.statistics = \"F\")\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: Y\n              Chisq Df Pr(&gt;Chisq)    \n(Intercept) 77.1664  1  &lt; 2.2e-16 ***\nV            2.4491  2     0.2939    \nN           39.0683  3  1.679e-08 ***\nV:N          1.8169  6     0.9357    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model2_lme, type = \"marginal\")\n\n            numDF denDF  F-value p-value\n(Intercept)     1    45 77.16729  &lt;.0001\nV               2    10  1.22454  0.3344\nN               3    45 13.02273  &lt;.0001\nV:N             6    45  0.30282  0.9322\n\n\n\n\n\nNext, we can estimate marginal means for V, N, or their interaction (V*N) effect.\n\nlme4nlme\n\n\n\nemm1 &lt;- emmeans(model2_lmer, ~ V *N) \nemm1\n\n V           N      emmean   SE   df lower.CL upper.CL\n Golden.rain 0.0cwt   80.0 9.11 16.1     60.7     99.3\n Marvellous  0.0cwt   86.7 9.11 16.1     67.4    106.0\n Victory     0.0cwt   71.5 9.11 16.1     52.2     90.8\n Golden.rain 0.2cwt   98.5 9.11 16.1     79.2    117.8\n Marvellous  0.2cwt  108.5 9.11 16.1     89.2    127.8\n Victory     0.2cwt   89.7 9.11 16.1     70.4    109.0\n Golden.rain 0.4cwt  114.7 9.11 16.1     95.4    134.0\n Marvellous  0.4cwt  117.2 9.11 16.1     97.9    136.5\n Victory     0.4cwt  110.8 9.11 16.1     91.5    130.1\n Golden.rain 0.6cwt  124.8 9.11 16.1    105.5    144.1\n Marvellous  0.6cwt  126.8 9.11 16.1    107.5    146.1\n Victory     0.6cwt  118.5 9.11 16.1     99.2    137.8\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n\nemm1 &lt;- emmeans(model2_lme, ~ V *N) \nemm1\n\n V           N      emmean   SE df lower.CL upper.CL\n Golden.rain 0.0cwt   80.0 9.11  5     56.6    103.4\n Marvellous  0.0cwt   86.7 9.11  5     63.3    110.1\n Victory     0.0cwt   71.5 9.11  5     48.1     94.9\n Golden.rain 0.2cwt   98.5 9.11  5     75.1    121.9\n Marvellous  0.2cwt  108.5 9.11  5     85.1    131.9\n Victory     0.2cwt   89.7 9.11  5     66.3    113.1\n Golden.rain 0.4cwt  114.7 9.11  5     91.3    138.1\n Marvellous  0.4cwt  117.2 9.11  5     93.8    140.6\n Victory     0.4cwt  110.8 9.11  5     87.4    134.2\n Golden.rain 0.6cwt  124.8 9.11  5    101.4    148.2\n Marvellous  0.6cwt  126.8 9.11  5    103.4    150.2\n Victory     0.6cwt  118.5 9.11  5     95.1    141.9\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\nIn the next chapter we will continue with extension of split plot design called split-split plot design.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-split-plot.html",
    "href": "chapters/split-split-plot.html",
    "title": "6  Split-Split Plot Design",
    "section": "",
    "text": "6.1 Details for split-split plot designs\nThe statistical model structure this design:\n\\[y_{ijk} = \\mu + \\rho_j +  \\alpha_i + \\beta_k + (\\alpha_i\\beta_k) + \\tau_n + (\\alpha_i\\tau_n) + (\\tau_n\\beta_k) + (\\alpha_i\\beta_k\\tau_n) + \\epsilon_{ijk} + \\delta_{ijkn}\\] Where:\n\\(\\mu\\)= overall experimental mean, \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\tau\\) = main effect of sub-subplot, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\\[ \\epsilon \\sim N(0, \\sigma_\\epsilon)\\]\n\\[\\ \\delta  \\sim N(0, \\sigma_\\delta)\\]\nThe assumptions of the model includes normal distribution of both the error and the rep effects with a mean of zero and standard deviations of \\(\\sigma_\\epsilon\\) and \\(\\sigma_\\delta\\), respectively.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Split-Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-split-plot.html#example-analysis",
    "href": "chapters/split-split-plot.html#example-analysis",
    "title": "6  Split-Split Plot Design",
    "section": "6.2 Example Analysis",
    "text": "6.2 Example Analysis\n\nlme4nlme\n\n\n\nlibrary(dplyr)\nlibrary(lme4); library(lmerTest); library(broom.mixed)\nlibrary(emmeans); library(performance)\n\n\n\n\nlibrary(dplyr)\nlibrary(nlme); library(emmeans)\nlibrary(broom.mixed); library(performance)\n\n\n\n\nIn this example, we have a rice yield data from ‘agricolae’ package. This consists of of 3 different rice varieties grown under 3 management practices and 5 Nitrogen levels in the split-split design. Here, we are using rice yield data from the (agricolae) package.\n\nrice &lt;- read.csv(here::here(\"data\", \"rice_ssp.csv\"))\n\n\nTable of variables in the rice data set\n\n\n\n\n\n\nblock\nblocking unit\n\n\nnitrogen\ndifferent nitrogen fertilizer rates as main plot with 5 levels\n\n\nmanagement\nmanagement practices as subplot with 3 levels\n\n\nvariety\ncrop variety being a sub-subplot with 3 levels\n\n\nyield\nyield (bushels per acre)\n\n\n\n\n6.2.1 Data integrity checks\nLook at the structure of the data, class of block, nitrogen, management and variety should be a character/factor and yield should be numeric.\n\nstr(rice)\n\n'data.frame':   135 obs. of  6 variables:\n $ X         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ block     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ nitrogen  : int  0 0 0 50 50 50 80 80 80 110 ...\n $ management: chr  \"m1\" \"m2\" \"m3\" \"m1\" ...\n $ variety   : int  1 1 1 1 1 1 1 1 1 1 ...\n $ yield     : num  3.32 3.77 4.66 3.19 3.62 ...\n\n\nConvert block, nitrogen, variety, and management to characters.\n\nrice$block &lt;- as.character(rice$block)\nrice$nitrogen &lt;- as.character(rice$nitrogen)\nrice$management &lt;- as.character(rice$management)\nrice$variety &lt;- as.character(rice$variety)\n\nNext, run a cross tabulations to check balance of observations across independent variables:\n\ntable(rice$variety, rice$nitrogen, rice$management)\n\n, ,  = m1\n\n   \n    0 110 140 50 80\n  1 3   3   3  3  3\n  2 3   3   3  3  3\n  3 3   3   3  3  3\n\n, ,  = m2\n\n   \n    0 110 140 50 80\n  1 3   3   3  3  3\n  2 3   3   3  3  3\n  3 3   3   3  3  3\n\n, ,  = m3\n\n   \n    0 110 140 50 80\n  1 3   3   3  3  3\n  2 3   3   3  3  3\n  3 3   3   3  3  3\n\n\nIt looks perfectly balanced, with exactly 3 observation per treatment group.\nLast, check the distribution of the dependent variable by plotting a histogram using hist().\n\nhist(rice$yield)\n\n\n\n\n\n\n\n\n\n\nFigure 6.1: Histogram of the dependent variable.\n\n\n\n\n\n\n6.2.2 Model Building\nThe variance analysis of a split-split plot design is divided into three parts: the main-plot, subplot and sub-subplot analysis. We can use the nesting notation in the random part because nitrogen and management are nested in blocks. We can do blocks as fixed or random.\n\nlme4nlme\n\n\n\nmodel_lmer &lt;- lmer(yield ~ nitrogen * management * variety +\n                     (1 | block / nitrogen / management),\n                   data = rice,\n                   na.action = na.exclude)\n\nboundary (singular) fit: see help('isSingular')\n\ntidy(model_lmer)\n\n# A tibble: 49 × 8\n   effect group term                 estimate std.error statistic    df  p.value\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  &lt;NA&gt;  (Intercept)             3.90      0.386    10.1    89.7 1.79e-16\n 2 fixed  &lt;NA&gt;  nitrogen110             0.753     0.545     1.38   89.7 1.71e- 1\n 3 fixed  &lt;NA&gt;  nitrogen140             0.165     0.545     0.302  89.7 7.63e- 1\n 4 fixed  &lt;NA&gt;  nitrogen50              0.335     0.545     0.614  89.7 5.41e- 1\n 5 fixed  &lt;NA&gt;  nitrogen80              1.33      0.545     2.44   89.7 1.68e- 2\n 6 fixed  &lt;NA&gt;  managementm2            0.420     0.540     0.779  80.0 4.38e- 1\n 7 fixed  &lt;NA&gt;  managementm3            1.43      0.540     2.65   80.0 9.82e- 3\n 8 fixed  &lt;NA&gt;  variety2                1.45      0.540     2.68   80.0 8.83e- 3\n 9 fixed  &lt;NA&gt;  variety3                1.48      0.540     2.74   80.0 7.49e- 3\n10 fixed  &lt;NA&gt;  nitrogen110:managem…    0.377     0.763     0.493  80.0 6.23e- 1\n# ℹ 39 more rows\n\n\n\n\n\nmodel_lme &lt;- lme(yield ~ nitrogen*management*variety,\n                  random = ~ 1|block/nitrogen/management,\n                  data = rice, \n                  na.action = na.exclude)\ntidy(model_lme)\n\nWarning in tidy.lme(model_lme): ran_pars not yet implemented for multiple\nlevels of nesting\n\n\n# A tibble: 45 × 7\n   effect term                     estimate std.error    df statistic  p.value\n   &lt;chr&gt;  &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  (Intercept)                 3.90      0.386    60    10.1   1.43e-14\n 2 fixed  nitrogen110                 0.753     0.545     8     1.38  2.05e- 1\n 3 fixed  nitrogen140                 0.165     0.545     8     0.302 7.70e- 1\n 4 fixed  nitrogen50                  0.335     0.545     8     0.614 5.56e- 1\n 5 fixed  nitrogen80                  1.33      0.545     8     2.44  4.08e- 2\n 6 fixed  managementm2                0.420     0.540    20     0.779 4.45e- 1\n 7 fixed  managementm3                1.43      0.540    20     2.65  1.55e- 2\n 8 fixed  variety2                    1.45      0.540    60     2.68  9.38e- 3\n 9 fixed  variety3                    1.48      0.540    60     2.74  7.99e- 3\n10 fixed  nitrogen110:managementm2    0.377     0.763    20     0.493 6.27e- 1\n# ℹ 35 more rows\n\n\n\n\n\n\n\nboundary (singular) fit: We get a message that the fit is singular. What does this mean? Some components of the variance-covariance matrix of the random effects are either exactly zero or exactly one. OK what about in English? Basically it means that the algorithm that fits the model parameters doesn’t have enough data to get a good estimate. This often happens when we are trying to fit a model that is too complex for the amount of data we have, or when the random effects are very small and can’t be distinguished from zero. We still get some output but this message should make us take a close look at the random effects and their variances.\n\n\n6.2.3 Check Model Assumptions\nModel Diagnostics: we are looking for a constant variance and normality of residuals. Checking normality requiring first extracting the model residuals and then generating a qq-plot and qq-line. we can do all at one using one function check_model().\n\nlme4nlme\n\n\n\ncheck_model(model_lmer, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model_lme, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\nHere, we didn’t observe any anomaly in model assumptions.\n\n\n6.2.4 Inference\nAnalysis of variance\n\nlme4nlme\n\n\n\ncar::Anova(model_lmer, type = 'III', test.statistic=\"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: yield\n                                   F Df Df.res  Pr(&gt;F)    \n(Intercept)                 102.1211  1 89.706 &lt; 2e-16 ***\nnitrogen                      1.9160  4 86.474 0.11496    \nmanagement                    3.6962  2 77.143 0.02932 *  \nvariety                       4.9129  2 60.000 0.01057 *  \nnitrogen:management           0.2118  8 77.143 0.98797    \nnitrogen:variety              2.6681  8 60.000 0.01413 *  \nmanagement:variety            2.2193  4 60.000 0.07754 .  \nnitrogen:management:variety   0.5289 16 60.000 0.92105    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model_lme, type = \"marginal\")\n\n                            numDF denDF   F-value p-value\n(Intercept)                     1    60 102.12108  &lt;.0001\nnitrogen                        4     8   1.91603  0.2012\nmanagement                      2    20   3.69617  0.0431\nvariety                         2    60   4.91295  0.0106\nnitrogen:management             8    20   0.21177  0.9850\nnitrogen:variety                8    60   2.66810  0.0141\nmanagement:variety              4    60   2.21929  0.0775\nnitrogen:management:variety    16    60   0.52893  0.9210\n\n\n\n\n\nWe can estimated the marginal means for each treatment factor (variety, nitrogen, management) which will averaged across other factors. and their interaction.\n\nlme4nlme\n\n\n\nemmeans(model_lmer, ~ nitrogen)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n nitrogen emmean    SE df lower.CL upper.CL\n 0          5.38 0.139 10     5.08     5.69\n 110        6.94 0.139 10     6.63     7.25\n 140        7.23 0.139 10     6.93     7.54\n 50         6.22 0.139 10     5.91     6.53\n 80         7.00 0.139 10     6.69     7.30\n\nResults are averaged over the levels of: management, variety \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\nemmeans(model_lmer, ~ nitrogen*variety|management)\n\nmanagement = m1:\n nitrogen variety emmean    SE   df lower.CL upper.CL\n 0        1         3.90 0.386 89.7     3.13     4.66\n 110      1         4.65 0.386 89.7     3.88     5.42\n 140      1         4.06 0.386 89.7     3.30     4.83\n 50       1         4.23 0.386 89.7     3.47     5.00\n 80       1         5.23 0.386 89.7     4.46     5.99\n 0        2         5.35 0.386 89.7     4.58     6.11\n 110      2         6.25 0.386 89.7     5.49     7.02\n 140      2         6.78 0.386 89.7     6.01     7.54\n 50       2         5.92 0.386 89.7     5.16     6.69\n 80       2         5.98 0.386 89.7     5.21     6.75\n 0        3         5.38 0.386 89.7     4.61     6.14\n 110      3         7.45 0.386 89.7     6.69     8.22\n 140      3         8.62 0.386 89.7     7.85     9.38\n 50       3         6.78 0.386 89.7     6.02     7.55\n 80       3         7.93 0.386 89.7     7.17     8.70\n\nmanagement = m2:\n nitrogen variety emmean    SE   df lower.CL upper.CL\n 0        1         4.32 0.386 89.7     3.55     5.08\n 110      1         5.45 0.386 89.7     4.68     6.21\n 140      1         5.20 0.386 89.7     4.43     5.97\n 50       1         4.58 0.386 89.7     3.81     5.34\n 80       1         5.73 0.386 89.7     4.97     6.50\n 0        2         4.71 0.386 89.7     3.95     5.48\n 110      2         7.00 0.386 89.7     6.24     7.77\n 140      2         7.08 0.386 89.7     6.32     7.85\n 50       2         5.82 0.386 89.7     5.05     6.58\n 80       2         6.50 0.386 89.7     5.73     7.27\n 0        3         6.50 0.386 89.7     5.73     7.26\n 110      3         8.62 0.386 89.7     7.86     9.39\n 140      3         9.40 0.386 89.7     8.63    10.17\n 50       3         7.82 0.386 89.7     7.05     8.58\n 80       3         8.57 0.386 89.7     7.80     9.33\n\nmanagement = m3:\n nitrogen variety emmean    SE   df lower.CL upper.CL\n 0        1         5.33 0.386 89.7     4.56     6.09\n 110      1         6.24 0.386 89.7     5.47     7.00\n 140      1         5.97 0.386 89.7     5.21     6.74\n 50       1         5.48 0.386 89.7     4.72     6.25\n 80       1         6.55 0.386 89.7     5.78     7.31\n 0        2         5.43 0.386 89.7     4.66     6.20\n 110      2         7.52 0.386 89.7     6.75     8.28\n 140      2         8.01 0.386 89.7     7.24     8.77\n 50       2         6.31 0.386 89.7     5.55     7.08\n 80       2         7.29 0.386 89.7     6.52     8.05\n 0        3         7.56 0.386 89.7     6.79     8.33\n 110      3         9.25 0.386 89.7     8.49    10.02\n 140      3         9.99 0.386 89.7     9.22    10.76\n 50       3         9.05 0.386 89.7     8.28     9.81\n 80       3         9.19 0.386 89.7     8.42     9.96\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(model_lme, ~ nitrogen)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n nitrogen emmean    SE df lower.CL upper.CL\n 0          5.38 0.139  2     4.79     5.98\n 110        6.94 0.139  2     6.34     7.53\n 140        7.23 0.139  2     6.64     7.83\n 50         6.22 0.139  2     5.62     6.82\n 80         7.00 0.139  2     6.40     7.59\n\nResults are averaged over the levels of: management, variety \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\nemmeans(model_lme, ~ nitrogen*variety|management)\n\nmanagement = m1:\n nitrogen variety emmean    SE df lower.CL upper.CL\n 0        1         3.90 0.386  2     2.24     5.56\n 110      1         4.65 0.386  2     2.99     6.31\n 140      1         4.06 0.386  2     2.40     5.72\n 50       1         4.23 0.386  2     2.57     5.89\n 80       1         5.23 0.386  2     3.57     6.89\n 0        2         5.35 0.386  2     3.69     7.01\n 110      2         6.25 0.386  2     4.59     7.91\n 140      2         6.78 0.386  2     5.12     8.43\n 50       2         5.92 0.386  2     4.26     7.58\n 80       2         5.98 0.386  2     4.32     7.64\n 0        3         5.38 0.386  2     3.72     7.04\n 110      3         7.45 0.386  2     5.79     9.11\n 140      3         8.62 0.386  2     6.96    10.28\n 50       3         6.78 0.386  2     5.12     8.44\n 80       3         7.93 0.386  2     6.27     9.59\n\nmanagement = m2:\n nitrogen variety emmean    SE df lower.CL upper.CL\n 0        1         4.32 0.386  2     2.66     5.98\n 110      1         5.45 0.386  2     3.79     7.11\n 140      1         5.20 0.386  2     3.54     6.86\n 50       1         4.58 0.386  2     2.92     6.24\n 80       1         5.73 0.386  2     4.07     7.39\n 0        2         4.71 0.386  2     3.05     6.37\n 110      2         7.00 0.386  2     5.34     8.66\n 140      2         7.08 0.386  2     5.43     8.74\n 50       2         5.82 0.386  2     4.16     7.47\n 80       2         6.50 0.386  2     4.84     8.16\n 0        3         6.50 0.386  2     4.84     8.16\n 110      3         8.62 0.386  2     6.97    10.28\n 140      3         9.40 0.386  2     7.74    11.06\n 50       3         7.82 0.386  2     6.16     9.48\n 80       3         8.57 0.386  2     6.91    10.23\n\nmanagement = m3:\n nitrogen variety emmean    SE df lower.CL upper.CL\n 0        1         5.33 0.386  2     3.67     6.98\n 110      1         6.24 0.386  2     4.58     7.90\n 140      1         5.97 0.386  2     4.31     7.63\n 50       1         5.48 0.386  2     3.82     7.14\n 80       1         6.55 0.386  2     4.89     8.21\n 0        2         5.43 0.386  2     3.77     7.09\n 110      2         7.52 0.386  2     5.86     9.18\n 140      2         8.01 0.386  2     6.35     9.66\n 50       2         6.31 0.386  2     4.65     7.97\n 80       2         7.29 0.386  2     5.63     8.95\n 0        3         7.56 0.386  2     5.90     9.22\n 110      3         9.25 0.386  2     7.59    10.91\n 140      3         9.99 0.386  2     8.33    11.65\n 50       3         9.05 0.386  2     7.39    10.70\n 80       3         9.19 0.386  2     7.53    10.85\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\nNotice we get a message that the estimated means for ‘nitrogen’ are averaged over the levels of ‘management’ and ‘variety’. So we need to be careful about how we interpret these estimates.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Split-Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/strip-plot.html",
    "href": "chapters/strip-plot.html",
    "title": "7  Strip Plot Design",
    "section": "",
    "text": "7.1 Background\nIn strip plot design each block or replication is divided into number of vertical and horizontal strips depending on the levels of the respective factors. 1. Vertical strip plot for the first factor – vertical factor 2. Horizontal strip plot for the second factor – horizontal factor\nDivide the experimental area into a horizontal strips and b vertical strips. Each level of , factor E is assigned to all the plots in one row, and each level of column. Each level of factor A is assigned to all the plots in one row, and each level of factor B is assigned to all the plots in one column.\nThe statistical model:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Strip Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/strip-plot.html#background",
    "href": "chapters/strip-plot.html#background",
    "title": "7  Strip Plot Design",
    "section": "",
    "text": "lme4nlme\n\n\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(performance); library(ggplot2)\nlibrary(broom.mixed)\n\n\n\n\nlibrary(nlme); library(performance); library(emmeans)\nlibrary(dplyr); library(ggplot2); library(broom.mixed)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Strip Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/strip-plot.html#example-analysis",
    "href": "chapters/strip-plot.html#example-analysis",
    "title": "7  Strip Plot Design",
    "section": "7.2 Example Analysis",
    "text": "7.2 Example Analysis\nA strip-plot experiment with three reps, variety as the horizontal strip and nitrogen fertilizer as the vertical strip.\n\ndata1 &lt;- agridat::gomez.stripplot\n\nIn this design, nitrogen rates were applied in a vertical strip and different varieties (Gen) were planted in a horizontal strips and were replicated over 3 times.\n\n\n\n\n\n\n\n\n\n\n7.2.1 Data integrity checks\n\nstr(data1)\n\n'data.frame':   54 obs. of  6 variables:\n $ yield: int  2373 4076 7254 4007 5630 7053 2620 4676 7666 2726 ...\n $ rep  : Factor w/ 3 levels \"R1\",\"R2\",\"R3\": 1 1 1 1 1 1 1 1 1 1 ...\n $ nitro: int  0 60 120 0 60 120 0 60 120 0 ...\n $ gen  : Factor w/ 6 levels \"G1\",\"G2\",\"G3\",..: 1 1 1 2 2 2 3 3 3 4 ...\n $ col  : int  1 3 2 1 3 2 1 3 2 1 ...\n $ row  : int  1 1 1 3 3 3 4 4 4 2 ...\n\n\n\ndata1$nitro &lt;- as.factor(data1$nitro)\n\n\ntable(data1$col, data1$row, data1$rep)\n\n, ,  = R1\n\n   \n    1 2 3 4 5 6\n  1 1 1 1 1 1 1\n  2 1 1 1 1 1 1\n  3 1 1 1 1 1 1\n  4 0 0 0 0 0 0\n  5 0 0 0 0 0 0\n  6 0 0 0 0 0 0\n  7 0 0 0 0 0 0\n  8 0 0 0 0 0 0\n  9 0 0 0 0 0 0\n\n, ,  = R2\n\n   \n    1 2 3 4 5 6\n  1 0 0 0 0 0 0\n  2 0 0 0 0 0 0\n  3 0 0 0 0 0 0\n  4 1 1 1 1 1 1\n  5 1 1 1 1 1 1\n  6 1 1 1 1 1 1\n  7 0 0 0 0 0 0\n  8 0 0 0 0 0 0\n  9 0 0 0 0 0 0\n\n, ,  = R3\n\n   \n    1 2 3 4 5 6\n  1 0 0 0 0 0 0\n  2 0 0 0 0 0 0\n  3 0 0 0 0 0 0\n  4 0 0 0 0 0 0\n  5 0 0 0 0 0 0\n  6 0 0 0 0 0 0\n  7 1 1 1 1 1 1\n  8 1 1 1 1 1 1\n  9 1 1 1 1 1 1\n\n\n\n\n7.2.2 Model Building\n\nlme4nlme\n\n\n\nmodel_lmer &lt;- lmer(yield ~  nitro*gen + \n                  (1|rep) + (1|row) + (1|col), \n                   data = data1)\n\n\nmodel_lmer1 &lt;- lmer(yield ~  nitro*gen + \n                   (1|rep:row) + (1|rep:col), \n                   data = data1)\n\n\nanova(model_lmer, model_lmer1)\n\nrefitting model(s) with ML (instead of REML)\n\n\nData: data1\nModels:\nmodel_lmer1: yield ~ nitro * gen + (1 | rep:row) + (1 | rep:col)\nmodel_lmer: yield ~ nitro * gen + (1 | rep) + (1 | row) + (1 | col)\n            npar    AIC    BIC  logLik deviance Chisq Df Pr(&gt;Chisq)\nmodel_lmer1   21 902.86 944.63 -430.43   860.86                    \nmodel_lmer    22 910.55 954.31 -433.28   866.55     0  1          1\n\ntidy(model_lmer1)\n\n# A tibble: 21 × 8\n   effect group term           estimate std.error statistic    df    p.value\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 fixed  &lt;NA&gt;  (Intercept)       3572.      562.     6.36   24.2 0.00000136\n 2 fixed  &lt;NA&gt;  nitro60           1560.      573.     2.72   17.4 0.0143    \n 3 fixed  &lt;NA&gt;  nitro120          3976.      573.     6.94   17.4 0.00000215\n 4 fixed  &lt;NA&gt;  genG2             1363.      756.     1.80   17.8 0.0886    \n 5 fixed  &lt;NA&gt;  genG3              678       756.     0.896  17.8 0.382     \n 6 fixed  &lt;NA&gt;  genG4              487.      756.     0.644  17.8 0.528     \n 7 fixed  &lt;NA&gt;  genG5              530.      756.     0.701  17.8 0.493     \n 8 fixed  &lt;NA&gt;  genG6             -364.      756.    -0.482  17.8 0.636     \n 9 fixed  &lt;NA&gt;  nitro60:genG2      219.      734.     0.298  20.8 0.768     \n10 fixed  &lt;NA&gt;  nitro120:genG2   -1699.      734.    -2.31   20.8 0.0310    \n# ℹ 11 more rows\n\n\n\n\n\nmodel_lme &lt;-lme(yield ~  nitro*gen,\n                 random = list (~1|rep, ~1|row, ~1|col), \n             #random = ~ 1|rep/time,\n             data = data1)\n\nmodel_lme1 &lt;-lme(yield ~  nitro*gen,\n                 random = list(~1|row, ~1|col), \n             #random = ~ 1|rep/time,\n             data = data1)\n\nanova(model_lme, model_lme1)\n\n           Model df     AIC      BIC    logLik   Test L.Ratio p-value\nmodel_lme      1 22 652.082 686.9194 -304.0410                       \nmodel_lme1     2 21 660.329 693.5829 -309.1645 1 vs 2  10.247  0.0014\n\ntidy(model_lme)\n\nWarning in tidy.lme(model_lme): ran_pars not yet implemented for multiple\nlevels of nesting\n\n\n# A tibble: 18 × 7\n   effect term           estimate std.error    df statistic     p.value\n   &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 fixed  (Intercept)      3572.       572.    24    6.24   0.00000188 \n 2 fixed  nitro60          1560.       558.    24    2.80   0.0100     \n 3 fixed  nitro120         3976.       558.    24    7.13   0.000000229\n 4 fixed  genG2            1363.       734.    10    1.86   0.0932     \n 5 fixed  genG3             678.       734.    10    0.923  0.378      \n 6 fixed  genG4             487.       734.    10    0.664  0.522      \n 7 fixed  genG5             530        734.    10    0.722  0.487      \n 8 fixed  genG6            -364.       734.    10   -0.496  0.630      \n 9 fixed  nitro60:genG2     219.       789.    24    0.278  0.784      \n10 fixed  nitro120:genG2  -1699.       789.    24   -2.15   0.0415     \n11 fixed  nitro60:genG3     312.       789.    24    0.396  0.696      \n12 fixed  nitro120:genG3   -358.       789.    24   -0.453  0.654      \n13 fixed  nitro60:genG4     -65.7      789.    24   -0.0832 0.934      \n14 fixed  nitro120:genG4   -941        789.    24   -1.19   0.245      \n15 fixed  nitro60:genG5     -28.7      789.    24   -0.0363 0.971      \n16 fixed  nitro120:genG5  -2066.       789.    24   -2.62   0.0151     \n17 fixed  nitro60:genG6   -1053.       789.    24   -1.33   0.194      \n18 fixed  nitro120:genG6  -4692.       789.    24   -5.95   0.00000389 \n\n\n\n\n\n\n7.2.2.1 Check Model Assumptions\n\nlme4nlme\n\n\n\ncheck_model(model_lmer1, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model_lme, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\nThe residuals fit the assumptions of the model well.\n\n\n7.2.2.2 Inference\nWe can evaluate the model for the analysis of variance, for main and interaction effects.\n\nlme4nlme\n\n\n\ncar::Anova(model_lmer1, type = \"III\", test.statistics = \"F\")\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: yield\n              Chisq Df Pr(&gt;Chisq)    \n(Intercept) 40.4229  1  2.045e-10 ***\nnitro       48.8489  2  2.469e-11 ***\ngen          6.1466  5     0.2922    \nnitro:gen   59.0350 10  5.516e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model_lme, type = \"marginal\")\n\n            numDF denDF  F-value p-value\n(Intercept)     1    24 38.97255  &lt;.0001\nnitro           2    24 25.78512  &lt;.0001\ngen             5    10  1.30451  0.3360\nnitro:gen      10    24  5.11314  0.0005\n\n\n\n\n\nestimate marginal means\n\nlme4nlme\n\n\n\nemm1 &lt;- emmeans(model_lmer1, ~ nitro*gen) \nemm1\n\n nitro gen emmean  SE   df lower.CL upper.CL\n 0     G1    3572 562 24.3     2413     4730\n 60    G1    5132 562 24.3     3973     6291\n 120   G1    7548 562 24.3     6389     8707\n 0     G2    4934 562 24.3     3776     6093\n 60    G2    6714 562 24.3     5555     7872\n 120   G2    7211 562 24.3     6053     8370\n 0     G3    4250 562 24.3     3091     5408\n 60    G3    6122 562 24.3     4964     7281\n 120   G3    7868 562 24.3     6710     9027\n 0     G4    4059 562 24.3     2900     5218\n 60    G4    5554 562 24.3     4395     6712\n 120   G4    7094 562 24.3     5936     8253\n 0     G5    4102 562 24.3     2943     5260\n 60    G5    5633 562 24.3     4475     6792\n 120   G5    6012 562 24.3     4853     7171\n 0     G6    3207 562 24.3     2049     4366\n 60    G6    3714 562 24.3     2556     4873\n 120   G6    2492 562 24.3     1333     3651\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n\nemm1 &lt;- emmeans(model_lme, ~ nitro*gen) \nemm1\n\n nitro gen emmean  SE df lower.CL upper.CL\n 0     G1    3572 572  2   1110.0     6033\n 60    G1    5132 572  2   2670.3     7594\n 120   G1    7548 572  2   5086.3    10010\n 0     G2    4934 572  2   2472.7     7396\n 60    G2    6714 572  2   4252.0     9175\n 120   G2    7211 572  2   4749.7     9673\n 0     G3    4250 572  2   1788.0     6711\n 60    G3    6122 572  2   3660.7     8584\n 120   G3    7868 572  2   5406.7    10330\n 0     G4    4059 572  2   1597.3     6521\n 60    G4    5554 572  2   3092.0     8015\n 120   G4    7094 572  2   4632.7     9556\n 0     G5    4102 572  2   1640.0     6563\n 60    G5    5633 572  2   3171.7     8095\n 120   G5    6012 572  2   3550.3     8474\n 0     G6    3207 572  2    745.7     5669\n 60    G6    3714 572  2   1252.7     6176\n 120   G6    2492 572  2     30.3     4954\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Strip Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html",
    "href": "chapters/factorial-design.html",
    "title": "8  Factorial Design",
    "section": "",
    "text": "8.1 Background\nFactorial design involves studying the impact of multiple factors simultaneously. Each factor can have multiple levels, and combinations of these levels form the experimental conditions. This design allows us to understand the main effects of individual factors and their interactions on the response variable. The statistical model for factorial design is: \\[y_{ij} = \\mu +  \\tau_i+ \\beta_j + \\tau_i\\beta_j + \\epsilon_{ij}\\] Where: \\(\\mu\\) = experiment mean, \\(\\tau\\) = effect of factor A, \\(\\beta\\) = effect of factor B, and \\(\\tau\\beta\\) = interaction effect of factor A and B.\nAssumptions of this model includes: independent and identically distributed error terms with a constant variance.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html#example-analysis",
    "href": "chapters/factorial-design.html#example-analysis",
    "title": "8  Factorial Design",
    "section": "8.2 Example Analysis",
    "text": "8.2 Example Analysis\nFirst step is to load the libraries required for the analysis:\n\nlme4nlme\n\n\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(broom.mixed); library(performance)\n\n\n\n\nlibrary(nlme); library(broom.mixed); library(emmeans)\nlibrary(dplyr); library(performance)\n\n\n\n\nNext, we will load the dataset named ‘cochran.factorial’ from the ‘agridat’ package. This data comprises a yield response of beans to different levels of manure (d), nitrogen (n), phosphorus The goal of this analysis is the estimate the effect on d, n, p, k, and their interactions on bean yield.\nNote, while importing the data, d, n, p, and k were converted into factor variables using the mutate() function from dplyr package. This helps in reducing the extra steps of converting each single variable to factor manually.\n\nlibrary(agridat)\ndata1 &lt;- agridat::cochran.factorial %&gt;% \n  mutate(d = as.factor(d),\n         n = as.factor(n),\n         p = as.factor(p),\n         k = as.factor(k))\n\n\nTable of variables in the data set\n\n\nblock\nblocking unit\n\n\nrep\nreplication unit\n\n\ntrt\ntreatment factor, 16 levels\n\n\nd\ndung treatment, 2 levels\n\n\nn\nnitrogen treatment, 2 levels\n\n\np\nphosphorus treatment, 2 levels\n\n\nk\npotassium treatment, 2 levels\n\n\nyield\nyield (lbs)\n\n\n\nThe objective of this example is evaluate the individual and interactive effect of “d”, “n”, “p”, and “k” treatments on yield.\n\n8.2.1 Data Integrity Checks\nVerify the class of variables, where rep, block, d, n, p, and k are supposed to be a factor/character and yield should be numeric/integer.\n\nstr(data1)\n\n'data.frame':   32 obs. of  8 variables:\n $ rep  : Factor w/ 2 levels \"R1\",\"R2\": 1 1 1 1 1 1 1 1 1 1 ...\n $ block: Factor w/ 2 levels \"B1\",\"B2\": 1 1 1 1 1 1 1 1 2 2 ...\n $ trt  : Factor w/ 16 levels \"(1)\",\"d\",\"dk\",..: 15 10 2 14 5 6 9 11 8 12 ...\n $ yield: int  45 55 53 36 41 48 55 42 50 44 ...\n $ d    : Factor w/ 2 levels \"0\",\"1\": 2 2 1 2 1 1 1 2 1 2 ...\n $ n    : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 1 1 2 1 2 1 ...\n $ p    : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 2 1 1 2 1 2 ...\n $ k    : Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 1 2 1 2 2 1 ...\n\n\nThis looks good.\nNext step is to inspect the independent variables and make sure the expected levels are present in the data.\n\ntable(data1$d, data1$n, data1$p, data1$k)\n\n, ,  = 0,  = 0\n\n   \n    0 1\n  0 2 2\n  1 2 2\n\n, ,  = 1,  = 0\n\n   \n    0 1\n  0 2 2\n  1 2 2\n\n, ,  = 0,  = 1\n\n   \n    0 1\n  0 2 2\n  1 2 2\n\n, ,  = 1,  = 1\n\n   \n    0 1\n  0 2 2\n  1 2 2\n\n\nThe design looks well balanced.\nLast step is to inspect the dependent variable to ensure its distribution follows the bell-shaped curve and no skewness is there.\n\n\n\n\n\n\n\n\n\nFigure 8.1: Histogram of the dependent variable.\n\n\n\n\n\nhist(data1$yield)\n\nThe range is roughly falling into the expected range. I didn’t observe any extreme observations (too high/low), indicating no issues with data. don’t see\n\n\n8.2.2 Model fitting\nModel fitting with R is exactly the same as shown in previous chapters: we need to include all effect, as well as the interaction, which is represented by using the colon indicator ‘:’. Therefore, model syntax is:\nyield ~ d + n + p + k + d:n + d:p + d:k + n:p + n:k + p:k + d:n:p:k\nwhich can be abbreviated as:\nyield ~ d*n*p*k\n\nlme4nlme\n\n\n\nmodel1_lmer &lt;- lmer(yield ~ d*n*p*k + (1|block),\n                   data = data1, \n                   na.action = na.exclude)\ntidy(model1_lmer)\n\n# A tibble: 18 × 8\n   effect   group    term           estimate std.error statistic    df   p.value\n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 fixed    &lt;NA&gt;     (Intercept)      49          3.70   13.2     16.0  4.91e-10\n 2 fixed    &lt;NA&gt;     d1               -9.5        5.24   -1.81    16.0  8.84e- 2\n 3 fixed    &lt;NA&gt;     n1                0.500      5.24    0.0955  16.0  9.25e- 1\n 4 fixed    &lt;NA&gt;     p1              -11.5        5.24   -2.20    16.0  4.31e- 2\n 5 fixed    &lt;NA&gt;     k1                1.00       5.24    0.191   16.0  8.51e- 1\n 6 fixed    &lt;NA&gt;     d1:n1            13.5        7.82    1.73    16.0  1.03e- 1\n 7 fixed    &lt;NA&gt;     d1:p1            15.5        7.82    1.98    16.0  6.49e- 2\n 8 fixed    &lt;NA&gt;     n1:p1             9.50       7.82    1.22    16.0  2.42e- 1\n 9 fixed    &lt;NA&gt;     d1:k1             4.00       7.82    0.512   16.0  6.16e- 1\n10 fixed    &lt;NA&gt;     n1:k1             0.500      7.82    0.0639  16.0  9.50e- 1\n11 fixed    &lt;NA&gt;     p1:k1             3.00       7.82    0.384   16.0  7.06e- 1\n12 fixed    &lt;NA&gt;     d1:n1:p1        -14.5       12.1    -1.19    16.0  2.50e- 1\n13 fixed    &lt;NA&gt;     d1:n1:k1        -17.0       12.1    -1.40    16.0  1.81e- 1\n14 fixed    &lt;NA&gt;     d1:p1:k1         -7.00      12.1    -0.576   16.0  5.72e- 1\n15 fixed    &lt;NA&gt;     n1:p1:k1         -4.50      12.1    -0.370   16.0  7.16e- 1\n16 fixed    &lt;NA&gt;     d1:n1:p1:k1      25.0       19.9     1.26    16.0  2.27e- 1\n17 ran_pars block    sd__(Intercep…    1.26      NA      NA       NA   NA       \n18 ran_pars Residual sd__Observati…    4.92      NA      NA       NA   NA       \n\n\n\n\n\nmodel2_lme &lt;- lme(yield ~ d*n*p*k,\n              random = ~ 1|block,\n              data = data1, \n              na.action = na.exclude)\ntidy(model2_lme)\n\n# A tibble: 18 × 8\n   effect   group    term           estimate std.error    df statistic   p.value\n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 fixed    &lt;NA&gt;     (Intercept)      49          4.79    15   10.2      3.66e-8\n 2 fixed    &lt;NA&gt;     d1               -9.5        6.77    15   -1.40     1.81e-1\n 3 fixed    &lt;NA&gt;     n1                0.500      6.77    15    0.0739   9.42e-1\n 4 fixed    &lt;NA&gt;     p1              -11.5        6.77    15   -1.70     1.10e-1\n 5 fixed    &lt;NA&gt;     k1                1.00       6.77    15    0.148    8.85e-1\n 6 fixed    &lt;NA&gt;     d1:n1            13.5       11.6     15    1.16     2.63e-1\n 7 fixed    &lt;NA&gt;     d1:p1            15.5       11.6     15    1.34     2.02e-1\n 8 fixed    &lt;NA&gt;     n1:p1             9.50      11.6     15    0.818    4.26e-1\n 9 fixed    &lt;NA&gt;     d1:k1             4.00      11.6     15    0.345    7.35e-1\n10 fixed    &lt;NA&gt;     n1:k1             0.500     11.6     15    0.0431   9.66e-1\n11 fixed    &lt;NA&gt;     p1:k1             3.00      11.6     15    0.258    8.00e-1\n12 fixed    &lt;NA&gt;     d1:n1:p1        -14.5       21.0     15   -0.690    5.01e-1\n13 fixed    &lt;NA&gt;     d1:n1:k1        -17.0       21.0     15   -0.809    4.31e-1\n14 fixed    &lt;NA&gt;     d1:p1:k1         -7.00      21.0     15   -0.333    7.44e-1\n15 fixed    &lt;NA&gt;     n1:p1:k1         -4.50      21.0     15   -0.214    8.33e-1\n16 fixed    &lt;NA&gt;     d1:n1:p1:k1      25.0       39.7     15    0.630    5.38e-1\n17 ran_pars block    sd_(Intercept)    3.28      NA       NA   NA       NA      \n18 ran_pars Residual sd_Observation    4.92      NA       NA   NA       NA      \n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInstead of summary() function, we used tidy() function from ‘broom.mixed’ package to get a short summary output of the model.\n\n\n\n\n8.2.3 Check Model Assumptions\n\nlme4nlme\n\n\n\ncheck_model(model1_lmer, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model2_lme, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\nThe linearity and homogeneity of variance plots show no trend. The normal Q-Q plots for the overall residuals and for the random effects all fall nearly on a straight line so we can be satisfied with that.\n\n\n8.2.4 Inference\nWe can get an ANOVA table for the linear mixed model using the function anova(), which works for both lmer() and lme() models..\n\nlme4nlme\n\n\n\ncar::Anova(model1_lmer, type = 'III', test.statistic=\"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: yield\n                   F Df Df.res    Pr(&gt;F)    \n(Intercept) 175.2030  1 20.439 1.729e-11 ***\nd             3.2928  1 20.439   0.08429 .  \nn             0.0091  1 20.439   0.92484    \np             4.8252  1 20.439   0.03974 *  \nk             0.0365  1 20.439   0.85040    \nd:n           2.9812  1 25.421   0.09637 .  \nd:p           3.9300  1 25.421   0.05834 .  \nn:p           1.4763  1 25.421   0.23552    \nd:k           0.2617  1 25.421   0.61335    \nn:k           0.0041  1 25.421   0.94951    \np:k           0.1472  1 25.421   0.70440    \nd:n:p         1.4251  1 37.012   0.24016    \nd:n:k         1.9589  1 37.012   0.16996    \nd:p:k         0.3321  1 37.012   0.56789    \nn:p:k         0.1373  1 37.012   0.71313    \nd:n:p:k       1.5778  1 66.709   0.21346    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova(model2_lme, type = \"marginal\")\n\n            numDF denDF   F-value p-value\n(Intercept)     1    15 104.83445  &lt;.0001\nd               1    15   1.97029  0.1808\nn               1    15   0.00546  0.9421\np               1    15   2.88720  0.1099\nk               1    15   0.02183  0.8845\nd:n             1    15   1.35278  0.2630\nd:p             1    15   1.78330  0.2017\nn:p             1    15   0.66990  0.4259\nd:k             1    15   0.11876  0.7352\nn:k             1    15   0.00186  0.9662\np:k             1    15   0.06680  0.7996\nd:n:p           1    15   0.47580  0.5009\nd:n:k           1    15   0.65401  0.4313\nd:p:k           1    15   0.11089  0.7437\nn:p:k           1    15   0.04583  0.8334\nd:n:p:k         1    15   0.39719  0.5380\n\n\n\n\n\nLet’s find estimates for some of the factors such as n, p, and n:k interaction. We will try the random intercept model first.\n\nlme4nlme\n\n\n\nemmeans(model1_lmer, specs = ~ n)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n n emmean   SE df lower.CL upper.CL\n 0   43.8 1.52 37     40.7     46.8\n 1   50.1 1.52 37     47.0     53.2\n\nResults are averaged over the levels of: d, p, k \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\nemmeans(model1_lmer, specs = ~ p)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n p emmean   SE df lower.CL upper.CL\n 0   47.4 1.52 37     44.3     50.5\n 1   46.5 1.52 37     43.4     49.6\n\nResults are averaged over the levels of: d, n, k \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\nemmeans(model1_lmer, specs = ~ n:k)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n n k emmean   SE   df lower.CL upper.CL\n 0 0   42.4 1.95 25.4     38.4     46.4\n 1 0   50.8 1.95 25.4     46.7     54.8\n 0 1   45.1 1.95 25.4     41.1     49.1\n 1 1   49.5 1.95 25.4     45.5     53.5\n\nResults are averaged over the levels of: d, p \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(model2_lme, specs = ~ n)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n n emmean   SE df lower.CL upper.CL\n 0   43.8 2.63  1     10.4     77.1\n 1   50.1 2.63  1     16.7     83.5\n\nResults are averaged over the levels of: d, p, k \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\nemmeans(model2_lme, specs = ~ p)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n p emmean   SE df lower.CL upper.CL\n 0   47.4 2.63  1     14.0     80.8\n 1   46.5 2.63  1     13.1     79.9\n\nResults are averaged over the levels of: d, n, k \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\nemmeans(model2_lme, specs = ~ n:k)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n n k emmean  SE df lower.CL upper.CL\n 0 0   42.4 2.9  1     5.50     79.2\n 1 0   50.8 2.9  1    13.88     87.6\n 0 1   45.1 2.9  1     8.25     82.0\n 1 1   49.5 2.9  1    12.63     86.4\n\nResults are averaged over the levels of: d, p \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\n\nUnbalanced factorial design",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html",
    "href": "chapters/incomplete-block-design.html",
    "title": "9  Incomplete Block Design",
    "section": "",
    "text": "9.1 Background\nThe block design in Chapter 4 was complete, meaning that every block contained all the treatments. In practice, it may not be possible to have too many treatments in each block. Sometimes, there are also situations where it is advised to not have many treatments in each block.\nIn such cases, incomplete block designs are used where we have to decide what subset of treatments to be used in an individual block. This will work well if we enough blocks. However, if we only have small number of blocks, there would be the risk that certain quantities are not estimable anymore.\nTo avoid having a disconnected design, a balanced incomplete block design can be used\nThe statistical model for balanced incomplete block design is:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\] Where:\n\\(\\mu\\) = overall experimental mean \\(\\alpha\\) = treatment effects (fixed) \\(\\beta\\) = block effects (random) \\(\\epsilon\\) = error terms\n\\[ \\epsilon \\sim N(0, \\sigma)\\]\n\\[ \\beta \\sim N(0, \\sigma_b)\\] There are few key points that we need to keep in mind while designing incomplete block designs:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Incomplete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html#background",
    "href": "chapters/incomplete-block-design.html#background",
    "title": "9  Incomplete Block Design",
    "section": "",
    "text": "A drawback of this design is that block effect and treatment effects are confounded.\nTo eliminate of block effects, better compare treatments within a block.\nNo treatment should appear twice in any block as they contributes nothing no within block comparisons.\n\n\n\n\n\n\n\nA note\n\n\n\nBecause the blocks are incomplete, the Type I and Type III sums of squares will be different. That is, the missing treatments in each block represent missing observations (but not missing ‘at random’).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Incomplete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html#example-analysis",
    "href": "chapters/incomplete-block-design.html#example-analysis",
    "title": "9  Incomplete Block Design",
    "section": "9.2 Example Analysis",
    "text": "9.2 Example Analysis\nWe will demonstrate an example data set designed in a balanced incomplete block design. First, load the libraries for analysis and estimation: ::: panel-tabset ### lme4\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr); library(broom.mixed); library(performance)\n\n\n9.2.1 nlme\n\nlibrary(nlme); library(broom.mixed); library(emmeans)\nlibrary(dplyr); library(performance)\n\n:::\nhttps://kwstat.github.io/agridat/reference/weiss.incblock.html\n\n library(agridat)\n  data(weiss.incblock)\n  dat &lt;- weiss.incblock\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.2 Data integrity checks\nThe first thing is to make sure the data is what we expect. There are two steps:\n\nmake sure data are the expected data type\ncheck the extent of missing data\ninspect the independent variables and make sure the expected levels are present in the data\ninspect the dependent variable to ensure its distribution is following expectations\n\n\nstr(dat)\n\n'data.frame':   186 obs. of  5 variables:\n $ block: Factor w/ 31 levels \"B01\",\"B02\",\"B03\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ gen  : Factor w/ 31 levels \"G01\",\"G02\",\"G03\",..: 24 15 20 18 20 5 22 1 9 14 ...\n $ yield: num  29.8 24.2 30.5 20 35.2 25 23.6 23.6 29.3 25.5 ...\n $ row  : int  42 36 30 24 18 12 6 42 36 30 ...\n $ col  : int  1 1 1 1 1 1 1 2 2 2 ...\n\n\nThese look okay with block and gen being factor variables and yield, row, and col being numeric variables.\nNext, check the independent variables. Running a cross tabulations is often sufficient to ascertain this.\n\ndat$row &lt;- as.factor(dat$row)\n\n\ntable(dat$gen, dat$block)\n\n     \n      B01 B02 B03 B04 B05 B06 B07 B08 B09 B10 B11 B12 B13 B14 B15 B16 B17 B18\n  G01   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1\n  G02   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   1   0   0\n  G03   0   0   1   0   0   0   0   1   1   1   0   0   1   0   0   0   0   0\n  G04   0   0   0   1   0   0   0   1   0   0   1   0   0   0   0   0   0   0\n  G05   0   0   0   0   1   1   0   1   0   0   0   0   0   1   1   0   0   0\n  G06   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0\n  G07   0   0   1   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n  G08   0   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   1   0\n  G09   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0\n  G10   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   1   0   1\n  G11   0   1   1   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0\n  G12   0   1   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0\n  G13   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   1   0   0\n  G14   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1\n  G15   0   1   0   1   1   0   0   0   1   0   0   0   0   0   0   0   1   0\n  G16   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   1   0   0\n  G17   0   0   0   0   0   0   1   0   0   1   1   1   0   0   1   0   1   0\n  G18   0   0   0   1   0   0   0   0   0   0   0   1   1   1   0   0   0   1\n  G19   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0\n  G20   0   0   1   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0\n  G21   1   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n  G22   1   0   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1\n  G23   1   0   0   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0\n  G24   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   1   0\n  G25   1   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0\n  G26   1   1   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0\n  G27   0   0   0   0   1   0   1   0   0   0   0   0   1   0   0   0   0   0\n  G28   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1\n  G29   0   0   0   1   0   1   0   0   0   1   0   0   0   0   0   1   0   0\n  G30   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n  G31   0   0   0   0   0   0   0   0   1   0   1   0   0   1   0   0   0   0\n     \n      B19 B20 B21 B22 B23 B24 B25 B26 B27 B28 B29 B30 B31\n  G01   1   0   0   0   0   0   0   0   0   0   1   1   0\n  G02   0   1   0   0   0   0   0   0   1   1   0   0   0\n  G03   0   0   0   0   1   0   0   0   0   0   0   0   0\n  G04   0   0   1   0   0   0   1   0   0   0   0   0   1\n  G05   0   0   0   0   0   1   0   0   0   0   0   0   0\n  G06   1   1   0   1   0   0   0   0   0   0   0   0   1\n  G07   0   0   0   1   0   1   0   0   0   0   1   0   0\n  G08   0   0   1   1   0   0   0   0   0   1   0   0   0\n  G09   0   0   0   1   0   0   1   0   1   0   0   1   0\n  G10   0   0   0   1   1   0   0   0   0   0   0   0   0\n  G11   1   0   0   0   0   0   0   0   1   0   0   0   0\n  G12   0   0   1   0   1   0   0   0   0   0   0   1   0\n  G13   0   0   0   0   0   0   0   0   0   0   1   0   1\n  G14   0   0   0   0   0   1   1   0   0   1   0   0   0\n  G15   0   1   0   0   0   0   0   0   0   0   0   0   0\n  G16   1   0   1   0   0   1   0   0   0   0   0   0   0\n  G17   0   0   0   0   0   0   0   0   0   0   0   0   0\n  G18   0   0   0   0   0   0   0   0   1   0   0   0   0\n  G19   0   1   0   0   1   0   1   0   0   0   1   0   0\n  G20   0   0   0   0   0   0   0   0   0   1   0   1   1\n  G21   1   0   0   0   1   0   0   0   0   1   0   0   0\n  G22   0   0   0   0   0   0   0   0   0   0   0   0   1\n  G23   0   1   0   0   0   1   0   0   0   0   0   1   0\n  G24   0   0   0   0   0   0   1   0   0   0   0   0   0\n  G25   0   0   1   0   0   0   0   0   1   0   1   0   0\n  G26   0   0   0   1   0   0   0   1   0   0   0   0   0\n  G27   1   0   0   0   0   0   1   1   0   0   0   0   0\n  G28   0   1   1   0   0   0   0   1   0   0   0   0   0\n  G29   0   0   0   0   0   0   0   1   0   0   0   1   0\n  G30   0   0   0   0   1   1   0   1   1   0   0   0   1\n  G31   0   0   0   0   0   0   0   1   0   1   1   0   0\n\n\nThere are 31 varieties and it is perfectly balanced, with exactly one observation per treatment per block.\nHere is a quick check I run to count the number of missing data in each column.\n\napply(dat, 2, function(x) sum(is.na(x)))\n\nblock   gen yield   row   col \n    0     0     0     0     0 \n\n\nWe observed no missing data!\nLast, check the dependent variable. A histogram is often quite sufficient to accomplish this. This is designed to be a quick check, so no need to spend time making the plot look good.\n\nhist(dat$yield, main = \"\", xlab = \"yield\")\n\n\n\n\n\n\n\n\n\n\nFigure 9.1: Histogram of the dependent variable.\n\n\n\n\nThis data set is ready for analysis!\n\n\n9.2.3 Model Building\n\nlme4nlme\n\n\n\nmodel_icbd &lt;- lmer(yield ~ gen + (1|block),\n                   data = dat, \n                   na.action = na.exclude)\ntidy(model_icbd)\n\n# A tibble: 33 × 8\n   effect group term        estimate std.error statistic    df  p.value\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  &lt;NA&gt;  (Intercept)  24.6        0.922   26.7     153. 2.30e-59\n 2 fixed  &lt;NA&gt;  genG02        2.40       1.17     2.06    129. 4.17e- 2\n 3 fixed  &lt;NA&gt;  genG03        8.04       1.17     6.88    129. 2.31e-10\n 4 fixed  &lt;NA&gt;  genG04        2.37       1.17     2.03    129. 4.42e- 2\n 5 fixed  &lt;NA&gt;  genG05        1.60       1.17     1.37    129. 1.73e- 1\n 6 fixed  &lt;NA&gt;  genG06        7.39       1.17     6.32    129. 3.82e- 9\n 7 fixed  &lt;NA&gt;  genG07       -0.419      1.17    -0.359   129. 7.20e- 1\n 8 fixed  &lt;NA&gt;  genG08        3.04       1.17     2.60    129. 1.04e- 2\n 9 fixed  &lt;NA&gt;  genG09        4.84       1.17     4.14    129. 6.22e- 5\n10 fixed  &lt;NA&gt;  genG10       -0.0429     1.17    -0.0367  129. 9.71e- 1\n# ℹ 23 more rows\n\n\n\n#model_icbd1 &lt;- lmer(yield ~ gen + (1|block) +  (1|row:block),\n#                   data = dat, \n#                   na.action = na.exclude)\n#tidy(model_icbd1)\n\n\n\n\nmodel_icbd &lt;- lme(yield ~ gen,\n                  random = ~ 1|block,\n                  data = dat, \n                  na.action = na.exclude)\ntidy(model_icbd)\n\n\n\n\n\n\n9.2.4 Check Model Assumptions\n\ncheck_model(model_icbd)\n\n\n\n\n\n\n\n\n\n\n9.2.5 Inference\n\nanova(model_icbd)\n\nType III Analysis of Variance Table with Satterthwaite's method\n    Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ngen 1901.1  63.369    30 129.06  17.675 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nemmeans(model_icbd, ~ gen)\n\n gen emmean    SE  df lower.CL upper.CL\n G01   24.6 0.923 153     22.7     26.4\n G02   27.0 0.923 153     25.2     28.8\n G03   32.6 0.923 153     30.8     34.4\n G04   26.9 0.923 153     25.1     28.8\n G05   26.2 0.923 153     24.4     28.0\n G06   32.0 0.923 153     30.1     33.8\n G07   24.2 0.923 153     22.3     26.0\n G08   27.6 0.923 153     25.8     29.4\n G09   29.4 0.923 153     27.6     31.2\n G10   24.5 0.923 153     22.7     26.4\n G11   27.1 0.923 153     25.2     28.9\n G12   29.3 0.923 153     27.4     31.1\n G13   29.9 0.923 153     28.1     31.8\n G14   24.2 0.923 153     22.4     26.1\n G15   26.1 0.923 153     24.3     27.9\n G16   25.9 0.923 153     24.1     27.8\n G17   19.7 0.923 153     17.9     21.5\n G18   25.7 0.923 153     23.9     27.5\n G19   29.0 0.923 153     27.2     30.9\n G20   33.2 0.923 153     31.3     35.0\n G21   31.1 0.923 153     29.3     32.9\n G22   25.2 0.923 153     23.3     27.0\n G23   29.8 0.923 153     28.0     31.6\n G24   33.6 0.923 153     31.8     35.5\n G25   27.0 0.923 153     25.2     28.8\n G26   27.1 0.923 153     25.3     29.0\n G27   23.8 0.923 153     22.0     25.6\n G28   26.5 0.923 153     24.6     28.3\n G29   24.8 0.923 153     22.9     26.6\n G30   36.2 0.923 153     34.4     38.0\n G31   27.1 0.923 153     25.3     28.9\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Incomplete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/repeated-measures.html",
    "href": "chapters/repeated-measures.html",
    "title": "10  Repeated measures mixed models",
    "section": "",
    "text": "11 Example Analysis\nFirst, we will start with the first example from a randomized complete block design with repeated measures.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Repeated measures mixed models</span>"
    ]
  },
  {
    "objectID": "chapters/repeated-measures.html#rcbd-repeated-measures",
    "href": "chapters/repeated-measures.html#rcbd-repeated-measures",
    "title": "10  Repeated measures mixed models",
    "section": "11.1 RCBD Repeated Measures",
    "text": "11.1 RCBD Repeated Measures\nThe example shown below contains data from a sorghum trial laid out as a randomized complete block design (5 blocks) with variety (4 varieties) treatment effect. The response variable ‘y’ is the leaf area index assessed in five consecutive weeks on each plot.\nWe need to have time as numeric and factor variable. In the model, to assess the week effect, week was used as a factor (factweek). For the correlation matrix, week needs to be numeric (week).\n\ndat &lt;- agriTutorial::sorghum %&gt;%   \n  mutate(week = as.numeric(factweek),\n         block = as.character(varblock)) \n\n\nTable of variables in the data set\n\n\nblock\nblocking unit\n\n\nReplicate\nreplication unit\n\n\nWeek\nTime points when data was collected\n\n\nvariety\ntreatment factor, 4 levels\n\n\ny\nyield (lbs)\n\n\n\n\n11.1.1 Data Integrity Checks\nLet’s do preliminary data check including evaluating data structure, distribution of treatments, number of missing values, and distribution of response variable.\n\nstr(dat)\n\n'data.frame':   100 obs. of  9 variables:\n $ y        : num  5 4.84 4.02 3.75 3.13 4.42 4.3 3.67 3.23 2.83 ...\n $ variety  : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Replicate: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 2 2 2 2 2 ...\n $ factweek : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 5 1 2 3 4 5 ...\n $ factplot : Factor w/ 20 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 2 2 2 2 2 ...\n $ varweek  : int  1 2 3 4 5 1 2 3 4 5 ...\n $ varblock : int  1 1 1 1 1 2 2 2 2 2 ...\n $ week     : num  1 2 3 4 5 1 2 3 4 5 ...\n $ block    : chr  \"1\" \"1\" \"1\" \"1\" ...\n\n\nIn this data, we have block, factplot, factweek as factor variables and y & week as numeric.\n\ntable(dat$variety, dat$block)\n\n   \n    1 2 3 4 5\n  1 5 5 5 5 5\n  2 5 5 5 5 5\n  3 5 5 5 5 5\n  4 5 5 5 5 5\n\n\nThe cross tabulation shows a equal number of varieties in each block.\n\nggplot(data = dat, aes(y = y, x = factweek, fill = variety)) +\n  geom_boxplot() +  \n  #scale_fill_brewer(palette=\"Dark2\") +\n  scale_fill_viridis_d(option = \"F\") +\n    theme_bw()\n\n\n\n\n\n\n\n\nLooks like variety ‘1’ has the lowest yield and showed drastic reduction in yield over weeks compared to other varieties.\nOne last step before we fit model is to look at the distribution of response variable.\n\nhist(dat$y, main = \"\", xlab = \"yield\")\n\n\n\n\n\n\n\n\n\n\nFigure 11.1: Histogram of the dependent variable.\n\n\n\n\n\n\n11.1.2 Model Building\nLet’s fit the basic model first using lme() from the nlme package.\n\nlm1 &lt;- lme(y ~ variety + factweek + variety:factweek, random = ~1|block/factplot,\n              data = dat,\n              na.action = na.exclude)\n\nThe model fitted above doesn’t account for the repeated measures effect. To account for the variation caused by repeated measurements, we can model the correlation among responses for a given subject which is plot (factor variable) in this case.\nBy adding this correlation structure, what we are implying is to keep each plot independent, but to allowing AR1 or compound symmetry correlations between responses for a given subject, here time variable is week and it must be numeric.\n\ncs1 &lt;- corAR1(form = ~ week|block/factplot,  value = 0.2, fixed = FALSE)\ncs2 &lt;- corCompSymm(form = ~ week|block/factplot,  value = 0.2, fixed = FALSE)\n\nIn the code chunk above, we fitted two correlation structures including AR1 and compound symmetry matrices. Next we will update the model lm1, with these two matrices. In nlme, please search the help tool to know more about functions for different correlation structure classes.\n\nlm2 &lt;- update(lm1, corr = cs1)\nlm3 &lt;- update(lm1, corr= cs2)\n\nNow let’s compare how model fitness differs among models with no correlation structure (lm1), with AR1 correlation structure (lm2), and with compound symmetry structure (lm3). We will compare these models by using anova() or by compare_performance() function from the ‘performance’ library.\n\nanovaperformance\n\n\n\nanova(lm1, lm2, lm3)\n\n    Model df       AIC      BIC   logLik   Test  L.Ratio p-value\nlm1     1 23 18.837478 73.62409 13.58126                        \nlm2     2 24 -2.347391 54.82125 25.17370 1 vs 2 23.18487  &lt;.0001\nlm3     3 24 20.837478 78.00612 13.58126                        \n\n\n\n\n\nresult &lt;- compare_performance(lm1, lm2, lm3)\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\nprint_md(result)\n\n\nComparison of Model Performance Indices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nModel\nAIC (weights)\nAICc (weights)\nBIC (weights)\nR2 (cond.)\nR2 (marg.)\nICC\nRMSE\nSigma\n\n\n\n\nlm1\nlme\n-50.5 (&lt;.001)\n-36.0 (&lt;.001)\n9.4 (&lt;.001)\n0.99\n0.37\n0.98\n0.10\n0.13\n\n\nlm2\nlme\n-77.5 (&gt;.999)\n-61.5 (&gt;.999)\n-15.0 (&gt;.999)\n0.97\n0.41\n0.95\n0.15\n0.18\n\n\nlm3\nlme\n-48.5 (&lt;.001)\n-32.5 (&lt;.001)\n14.0 (&lt;.001)\n0.98\n0.37\n0.98\n0.11\n0.14\n\n\n\n\n\n\n\n\nWe prefer to chose model with lower AIC and BIC values. In this scenario, we will move forward with lm2 model containing AR1 structure.\nLet’s run a tidy() on lm2 model to look at the estimates for random and fixed effects.\n\ntidy(lm2)\n\nWarning in tidy.lme(lm2): ran_pars not yet implemented for multiple levels of\nnesting\n\n\n# A tibble: 20 × 7\n   effect term               estimate std.error    df statistic  p.value\n   &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 fixed  (Intercept)          4.24      0.291     64    14.6   5.44e-22\n 2 fixed  variety2             0.906     0.114     12     7.94  4.05e- 6\n 3 fixed  variety3             0.646     0.114     12     5.66  1.05e- 4\n 4 fixed  variety4             0.912     0.114     12     8.00  3.78e- 6\n 5 fixed  factweek2           -0.196     0.0571    64    -3.44  1.04e- 3\n 6 fixed  factweek3           -0.836     0.0755    64   -11.1   1.60e-16\n 7 fixed  factweek4           -1.16      0.0867    64   -13.3   4.00e-20\n 8 fixed  factweek5           -1.54      0.0943    64   -16.3   1.57e-24\n 9 fixed  variety2:factweek2   0.0280    0.0807    64     0.347 7.30e- 1\n10 fixed  variety3:factweek2   0.382     0.0807    64     4.73  1.26e- 5\n11 fixed  variety4:factweek2  -0.0140    0.0807    64    -0.174 8.63e- 1\n12 fixed  variety2:factweek3   0.282     0.107     64     2.64  1.03e- 2\n13 fixed  variety3:factweek3   0.662     0.107     64     6.20  4.55e- 8\n14 fixed  variety4:factweek3   0.388     0.107     64     3.64  5.55e- 4\n15 fixed  variety2:factweek4   0.228     0.123     64     1.86  6.77e- 2\n16 fixed  variety3:factweek4   0.744     0.123     64     6.06  7.86e- 8\n17 fixed  variety4:factweek4   0.390     0.123     64     3.18  2.28e- 3\n18 fixed  variety2:factweek5   0.402     0.133     64     3.01  3.70e- 3\n19 fixed  variety3:factweek5   0.672     0.133     64     5.04  4.11e- 6\n20 fixed  variety4:factweek5   0.222     0.133     64     1.66  1.01e- 1\n\n\n\n\n11.1.3 Check Model Assumptions\n\ncheck_model(lm2, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n11.1.4 Inference\nThe ANOVA table suggests a highly significant effect of the variety, week, and variety x week interaction effect.\n\nanova(lm2, type = \"marginal\")\n\n                 numDF denDF   F-value p-value\n(Intercept)          1    64 212.10509  &lt;.0001\nvariety              3    12  28.28895  &lt;.0001\nfactweek             4    64  74.79758  &lt;.0001\nvariety:factweek    12    64   7.03546  &lt;.0001\n\n\nWe can estimate the marginal means for variety and week effect and their interaction using emmeans() function.\n\nmean_1 &lt;- emmeans(lm2, ~ variety)\n\nNOTE: Results may be misleading due to involvement in interactions\n\nmean_1\n\n variety emmean    SE df lower.CL upper.CL\n 1         3.50 0.288  4     2.70     4.29\n 2         4.59 0.288  4     3.79     5.39\n 3         4.63 0.288  4     3.84     5.43\n 4         4.61 0.288  4     3.81     5.40\n\nResults are averaged over the levels of: factweek \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\nmean_2 &lt;- emmeans(lm2, ~ variety*factweek)\nmean_2\n\n variety factweek emmean    SE df lower.CL upper.CL\n 1       1          4.24 0.291  4     3.43     5.05\n 2       1          5.15 0.291  4     4.34     5.96\n 3       1          4.89 0.291  4     4.08     5.70\n 4       1          5.15 0.291  4     4.35     5.96\n 1       2          4.05 0.291  4     3.24     4.85\n 2       2          4.98 0.291  4     4.17     5.79\n 3       2          5.07 0.291  4     4.27     5.88\n 4       2          4.94 0.291  4     4.14     5.75\n 1       3          3.41 0.291  4     2.60     4.21\n 2       3          4.59 0.291  4     3.79     5.40\n 3       3          4.71 0.291  4     3.91     5.52\n 4       3          4.71 0.291  4     3.90     5.51\n 1       4          3.09 0.291  4     2.28     3.89\n 2       4          4.22 0.291  4     3.41     5.03\n 3       4          4.48 0.291  4     3.67     5.28\n 4       4          4.39 0.291  4     3.58     5.20\n 1       5          2.70 0.291  4     1.89     3.51\n 2       5          4.01 0.291  4     3.20     4.82\n 3       5          4.02 0.291  4     3.21     4.83\n 4       5          3.83 0.291  4     3.03     4.64\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\nTime variable\n\n\n\nHere is a quick step to make sure your fitting model correctly: make sure to have two time variables in your data one being numeric (e.g. ‘day’ as number) and other being factor/character(e.g. ‘day_factor’ as a factor/character). Where, numeric variable is used for fitting correlation matrix and factor/character variable used in model statement to evaluate the time variable effect on response variable.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Repeated measures mixed models</span>"
    ]
  },
  {
    "objectID": "chapters/repeated-measures.html#split-plot-repeated-measures",
    "href": "chapters/repeated-measures.html#split-plot-repeated-measures",
    "title": "10  Repeated measures mixed models",
    "section": "11.2 Split Plot Repeated Measures",
    "text": "11.2 Split Plot Repeated Measures\nRecall, we have evaluated split plot design Chapter 5. In this example we will use the same methodology used in Chapter 5 and update it with repeated measures component.\nNext, let’s load “Yield” data. It is located here.\n\nYield &lt;- read.csv(here::here(\"data/Yield.csv\"))\n\nThis example contains yield data in a split-plot design. The yield data was collected repeatedly from the same Reps over 5 Sample_times. In this data set, we have:\n\nTable of variables in the data set\n\n\nRep\nreplication unit\n\n\nVariety\nMain plot, 2 levels\n\n\nFertilizer\nSplit plot, 3 levels\n\n\nYield\ncrop yield\n\n\nSample_time\ntime points for data collection\n\n\n\n\n11.2.1 Data Integrity Checks\nFirstly, we need to look at the class of variables in the data set.\n\nstr(Yield)\n\n'data.frame':   120 obs. of  6 variables:\n $ Sample_time: int  1 1 1 1 1 1 1 1 1 1 ...\n $ Variety    : chr  \"VAR1\" \"VAR1\" \"VAR1\" \"VAR1\" ...\n $ Fertilizer : int  1 1 1 1 2 2 2 2 3 3 ...\n $ Rep        : int  1 2 3 4 1 2 3 4 1 2 ...\n $ pH         : num  7.07 7.06 7.08 7.09 7.13 7.12 7.15 7.14 7.18 7.18 ...\n $ Yield      : num  0.604 0.595 3.145 3.091 2.415 ...\n\n\nWe will now convert the fertilizer and Rep into factor. In addition, we need to create a new factor variable (sample_time1) to analyze the time effect.\n\n\nFor lme(), independent variables in a character/factor form works fine. But, for mmrm() independent variables must be a factor. Thus, for sake of consistancy, we will be using independent variables in factor class.\n\nYield$Variety &lt;- factor(Yield$Variety) \nYield$Fertilizer &lt;- factor(Yield$Fertilizer) \nYield$Sample_time1 &lt;- factor(Yield$Sample_time) \nYield$Rep &lt;- factor(Yield$Rep)  \n\nTo fit model, we first need to convert Variety, Fertilizer, and Sample_time as factors. In addition, we need to create a new variable named ‘plot’ with a unique value for each plot. In addition, we need a create variable for each subject which is plot in this case and contains a unique value for each plot. The plot variable is needed to model the variation in each plot over the sampling time. The plot will be used as a subject with repeated measures. The subject variable can be factor or numeric but the time (it could be year, or sample_time) has to be a factor.\n\n##creating a plot variable \nYield$plot &lt;- factor(paste(Yield$Rep, Yield$Fertilizer, Yield$Variety, sep='-')) \nYield$Rep2 &lt;- factor(paste(Yield$Rep, Yield$Variety, sep='-')) \ntable(Yield$plot) \n\n\n1-1-VAR1 1-1-VAR2 1-2-VAR1 1-2-VAR2 1-3-VAR1 1-3-VAR2 2-1-VAR1 2-1-VAR2 \n       5        5        5        5        5        5        5        5 \n2-2-VAR1 2-2-VAR2 2-3-VAR1 2-3-VAR2 3-1-VAR1 3-1-VAR2 3-2-VAR1 3-2-VAR2 \n       5        5        5        5        5        5        5        5 \n3-3-VAR1 3-3-VAR2 4-1-VAR1 4-1-VAR2 4-2-VAR1 4-2-VAR2 4-3-VAR1 4-3-VAR2 \n       5        5        5        5        5        5        5        5 \n\n\n\ntable(Yield$Fertilizer, Yield$Variety) \n\n   \n    VAR1 VAR2\n  1   20   20\n  2   20   20\n  3   20   20\n\n\nLooks like a well balanced design with 2 variety treatments and 3 fertilizer treatments.\nBefore fitting a model, let’s check the distribution of the response variable.\n\n\n\n\n\n\n\n\n\nFigure 11.2: Histogram of the dependent variable.\n\n\n\n\n\nhist(Yield$Yield)\n\n\n\n11.2.2 Model fit\nThis data can be analyze either using nlme or mmrm.\nusing lme() from nlme package.\nLet’s say we want to fit a model using AR1 structure as shown in the RCBD repeated measures example. Previously, we used lme() from nlme package to fit the model. In this example, along with nlme() we will also mmrm() function from the mmrm package. In addition, instead of summary() function we will use tidy() function from the ‘broom.mixed’ packageto look at estimates of mixed and random effects. In this model we used tidy(). This will generate a tidy workflow in particular by providing standardized verbs that provide information on estimates, standard errors, confidence intervals, etc.\n\nnlmemmrm\n\n\n\ncorr_str1 = corAR1(form = ~ Sample_time|Rep/Variety/plot, value = 0.2, fixed = FALSE)\n\nmod &lt;- lme(Yield ~ Sample_time1*Variety*Fertilizer,\n                random = ~ 1|Rep/Variety/plot,\n                corr= corr_str1,\n                data = Yield, na.action= na.exclude)\n\n#summary(mod)\n\ntidy(mod)\n\n# A tibble: 30 × 7\n   effect term                      estimate std.error    df statistic   p.value\n   &lt;chr&gt;  &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 fixed  (Intercept)                  1.86      0.708    72     2.63  0.0105   \n 2 fixed  Sample_time12                0.515     0.688    72     0.748 0.457    \n 3 fixed  Sample_time13                0.787     0.674    72     1.17  0.247    \n 4 fixed  Sample_time14                1.35      0.675    72     2.00  0.0496   \n 5 fixed  Sample_time15                2.84      0.675    72     4.21  0.0000731\n 6 fixed  VarietyVAR2                 -0.996     0.861     3    -1.16  0.331    \n 7 fixed  Fertilizer2                  1.27      0.861    12     1.47  0.167    \n 8 fixed  Fertilizer3                  2.07      0.861    12     2.40  0.0333   \n 9 fixed  Sample_time12:VarietyVAR2    0.739     0.974    72     0.759 0.451    \n10 fixed  Sample_time13:VarietyVAR2    0.269     0.954    72     0.282 0.779    \n# ℹ 20 more rows\n\n\n\n\n\nfit1 &lt;- mmrm(\n  formula = Yield ~ Sample_time1*Variety*Fertilizer +  ar1(Sample_time1|Rep/plot),\n  data = Yield)\n\ntidy(fit1)\n\n# A tibble: 30 × 6\n   term                      estimate std.error    df statistic   p.value\n   &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)                  2.86      0.464 12.7      6.16  0.0000387\n 2 Sample_time12                0.656     0.310  1.81     2.12  0.182    \n 3 Sample_time13                1.40      0.414  2.29     3.39  0.0636   \n 4 Sample_time14                1.46      0.484  2.87     3.01  0.0605   \n 5 Sample_time15                2.47      0.549  3.14     4.50  0.0186   \n 6 VarietyVAR2                 -1.07      0.656 12.7     -1.63  0.128    \n 7 Fertilizer2                  1.67      0.656 12.7      2.55  0.0245   \n 8 Fertilizer3                  0.595     0.656 12.7      0.908 0.381    \n 9 Sample_time12:VarietyVAR2   -0.591     0.438  1.81    -1.35  0.321    \n10 Sample_time13:VarietyVAR2   -0.412     0.586  2.29    -0.704 0.546    \n# ℹ 20 more rows\n\n\n\n\n\n\n\n11.2.3 Model diagnostics\nWe will use check_model() from ‘performance()’ package to evaluate the model fitness of model fitted using nlme (mod1). However, the mmrm model class doesn’t work with performance package, so we will evalute the model diagnostics by plotting the residuals using base R functions.\n\nnlmemmrm\n\n\n\ncheck_model(mod, check = c('normality', 'linearity'))\n\n\n\n\n\n\n\n\n\n\n\n## performance package doesn't work with mmrm model class.\nplot(residuals(fit1)) \n\n\n\n\n\n\n\nqqnorm(residuals(fit1)); qqline(residuals(fit1))\n\n\n\n\n\n\n\n\n\n\n\nThese diagnostic plots look great! The linearity and homogeneity of variance plots show no trend. The normal Q-Q plots for the overall residuals and for the random effects all fall on a straight line so we can be satisfied with that.\n\n\n11.2.4 Inference\n\nnlmemmrm\n\n\n\nanova(mod, type = \"marginal\")\n\n                                numDF denDF  F-value p-value\n(Intercept)                         1    72 6.899272  0.0105\nSample_time1                        4    72 5.318690  0.0008\nVariety                             1     3 1.338879  0.3310\nFertilizer                          2    12 2.936073  0.0916\nSample_time1:Variety                4    72 0.998154  0.4143\nSample_time1:Fertilizer             8    72 8.158884  &lt;.0001\nVariety:Fertilizer                  2    12 0.237417  0.7923\nSample_time1:Variety:Fertilizer     8    72 0.731698  0.6631\n\n\n\n\n\n#car::Anova(fit1, type = \"III\")\n#Anova.mmrm(fit1, type = \"III\")\n\n\n\n\nNext, we can estimate marginal means and confidence intervals for the independent variables using emmeans().\n\nnlmemmrm\n\n\n\nemmeans(mod,~ Fertilizer)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n Fertilizer emmean    SE df lower.CL upper.CL\n 1            2.44 0.472  3    0.937     3.94\n 2            6.69 0.472  3    5.192     8.20\n 3            8.06 0.472  3    6.554     9.56\n\nResults are averaged over the levels of: Sample_time1, Variety \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\nemmeans(mod,~ Variety)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n Variety emmean    SE df lower.CL upper.CL\n VAR1      6.09 0.438  3     4.69     7.48\n VAR2      5.37 0.438  3     3.98     6.77\n\nResults are averaged over the levels of: Sample_time1, Fertilizer \nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(fit1,~ Fertilizer)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n Fertilizer emmean    SE   df lower.CL upper.CL\n 1            3.27 0.246 8.02     2.70     3.83\n 2            7.93 0.246 8.02     7.37     8.50\n 3            8.51 0.246 8.02     7.94     9.07\n\nResults are averaged over the levels of: Sample_time1, Variety, Rep \nConfidence level used: 0.95 \n\n emmeans(fit1,~ Variety)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n Variety emmean  SE   df lower.CL upper.CL\n VAR1      6.89 0.2 8.02     6.42     7.35\n VAR2      6.25 0.2 8.02     5.79     6.71\n\nResults are averaged over the levels of: Sample_time1, Fertilizer, Rep \nConfidence level used: 0.95 \n\n\n\n\n\n\n\nAdd a link for further exploring emmeans and contrast statements.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Repeated measures mixed models</span>"
    ]
  },
  {
    "objectID": "chapters/repeated-measures.html#split-split-plot-repeated-measures",
    "href": "chapters/repeated-measures.html#split-split-plot-repeated-measures",
    "title": "10  Repeated measures mixed models",
    "section": "11.3 Split-split plot repeated measures",
    "text": "11.3 Split-split plot repeated measures\nRecall, we have evaluated the split-split experiment design in Chapter 5, where we had a one factor in main-plot, other in subplot and the third factor in sub-subplot. In this example we will be adding a repeated measures statement.\n\nagridat::caribbean.maize\n\n         isle site block plot  trt ears yield\n1     Antigua DBAN    B1    1 T111   42  4.96\n2     Antigua DBAN    B1    2 T000   41  3.94\n3     Antigua DBAN    B1    3 T311   49  6.35\n4     Antigua DBAN    B1    4 T202   48  5.56\n5     Antigua DBAN    B1    5 T111   45  5.36\n6     Antigua DBAN    B1    6 T220   46  6.18\n7     Antigua DBAN    B1    7 T113   42  4.71\n8     Antigua DBAN    B1    8 T131   44  6.03\n9     Antigua DBAN    B1    9 T022   42  2.88\n10    Antigua DBAN    B2   10 T222   44  5.68\n11    Antigua DBAN    B2   11 T311   42  5.80\n12    Antigua DBAN    B2   12 T020   42  4.16\n13    Antigua DBAN    B2   13 T200   46  4.90\n14    Antigua DBAN    B2   14 T111   44  5.25\n15    Antigua DBAN    B2   15 T131   48  5.80\n16    Antigua DBAN    B2   16 T002   46  2.18\n17    Antigua DBAN    B2   17 T111   48  4.36\n18    Antigua DBAN    B2   18 T113   45  4.36\n19    Antigua DBAN    B3   19 T131   43  4.81\n20    Antigua DBAN    B3   20 T111   47  5.19\n21    Antigua DBAN    B3   21 T311   47  5.96\n22    Antigua DBAN    B3   22 T000   45  3.88\n23    Antigua DBAN    B3   23 T220   50  5.72\n24    Antigua DBAN    B3   24 T022   44  2.51\n25    Antigua DBAN    B3   25 T111   47  4.94\n26    Antigua DBAN    B3   26 T113   44  3.70\n27    Antigua DBAN    B3   27 T202   40  2.77\n28    Antigua DBAN    B4   28 T111   41  4.34\n29    Antigua DBAN    B4   29 T200   45  4.33\n30    Antigua DBAN    B4   30 T111   41  4.68\n31    Antigua DBAN    B4   31 T113   46  4.76\n32    Antigua DBAN    B4   32 T131   47  5.24\n33    Antigua DBAN    B4   33 T020   42  1.86\n34    Antigua DBAN    B4   34 T222   41  3.84\n35    Antigua DBAN    B4   35 T002   41  1.36\n36    Antigua DBAN    B4   36 T311   36  3.98\n37    Antigua LFAN    B1    1 T111   37  2.92\n38    Antigua LFAN    B1    2 T022   36  1.68\n39    Antigua LFAN    B1    3 T113   42  4.50\n40    Antigua LFAN    B1    4 T220   41  4.74\n41    Antigua LFAN    B1    5 T202   40  4.44\n42    Antigua LFAN    B1    6 T311   44  4.66\n43    Antigua LFAN    B1    7 T111   44  2.94\n44    Antigua LFAN    B1    8 T000   44  1.60\n45    Antigua LFAN    B1    9 T131   38  1.82\n46    Antigua LFAN    B2   10 T113   39  4.44\n47    Antigua LFAN    B2   11 T222   40  5.78\n48    Antigua LFAN    B2   12 T311   46  6.24\n49    Antigua LFAN    B2   13 T111   47  5.40\n50    Antigua LFAN    B2   14 T200   46  5.62\n51    Antigua LFAN    B2   15 T002   35  1.72\n52    Antigua LFAN    B2   16 T131   43  4.42\n53    Antigua LFAN    B2   17 T111   46  4.14\n54    Antigua LFAN    B2   18 T020   40  3.94\n55    Antigua LFAN    B3   19 T220   41  5.00\n56    Antigua LFAN    B3   20 T202   46  5.26\n57    Antigua LFAN    B3   21 T000   36  2.90\n58    Antigua LFAN    B3   22 T111   43  4.94\n59    Antigua LFAN    B3   23 T113   45  4.43\n60    Antigua LFAN    B3   24 T311   47  5.42\n61    Antigua LFAN    B3   25 T022   34  1.22\n62    Antigua LFAN    B3   26 T111   42  3.72\n63    Antigua LFAN    B3   27 T131   41  3.70\n64    Antigua LFAN    B4   28 T131   46  5.61\n65    Antigua LFAN    B4   29 T111   45  6.02\n66    Antigua LFAN    B4   30 T020   45  3.18\n67    Antigua LFAN    B4   31 T311   47  6.07\n68    Antigua LFAN    B4   32 T002   38  1.48\n69    Antigua LFAN    B4   33 T222   47  5.94\n70    Antigua LFAN    B4   34 T111   42  3.58\n71    Antigua LFAN    B4   35 T200   39  3.95\n72    Antigua LFAN    B4   36 T113   44  3.38\n73    Antigua TEAN    B1    1 T113   32  1.27\n74    Antigua TEAN    B1    2 T111   29  2.10\n75    Antigua TEAN    B1    3 T022   46  2.37\n76    Antigua TEAN    B1    4 T202   28  2.08\n77    Antigua TEAN    B1    5 T000   31  1.74\n78    Antigua TEAN    B1    6 T131   39  3.16\n79    Antigua TEAN    B1    7 T220   42  4.55\n80    Antigua TEAN    B1    8 T111   36  3.20\n81    Antigua TEAN    B1    9 T311   35  3.69\n82    Antigua TEAN    B2   10 T200   28  1.52\n83    Antigua TEAN    B2   11 T311   30  2.02\n84    Antigua TEAN    B2   12 T222   29  1.97\n85    Antigua TEAN    B2   13 T020   29  1.94\n86    Antigua TEAN    B2   14 T131   30  2.01\n87    Antigua TEAN    B2   15 T111   35  2.18\n88    Antigua TEAN    B2   16 T002   36  3.24\n89    Antigua TEAN    B2   17 T113   39  3.91\n90    Antigua TEAN    B2   18 T111   48  4.20\n91    Antigua TEAN    B3   19 T111   34  2.57\n92    Antigua TEAN    B3   20 T202   37  2.88\n93    Antigua TEAN    B3   21 T220   37  3.45\n94    Antigua TEAN    B3   22 T000   42  2.89\n95    Antigua TEAN    B3   23 T111   38  3.01\n96    Antigua TEAN    B3   24 T113   39  2.87\n97    Antigua TEAN    B3   25 T311   35  3.25\n98    Antigua TEAN    B3   26 T131   41  3.92\n99    Antigua TEAN    B3   27 T022   28  0.88\n100   Antigua TEAN    B4   28 T311   25  1.14\n101   Antigua TEAN    B4   29 T111   43  3.61\n102   Antigua TEAN    B4   30 T113   42  3.05\n103   Antigua TEAN    B4   31 T002   44  3.41\n104   Antigua TEAN    B4   32 T222   48  4.46\n105   Antigua TEAN    B4   33 T200   41  4.36\n106   Antigua TEAN    B4   34 T111   39  3.42\n107   Antigua TEAN    B4   35 T131   28  1.06\n108   Antigua TEAN    B4   36 T020   NA    NA\n109   Antigua WEAN    B1    1 T000   48  4.02\n110   Antigua WEAN    B1    2 T311   47  5.80\n111   Antigua WEAN    B1    3 T202   32  2.16\n112   Antigua WEAN    B1    4 T220   43  5.31\n113   Antigua WEAN    B1    5 T111   42  5.12\n114   Antigua WEAN    B1    6 T131   45  5.98\n115   Antigua WEAN    B1    7 T113   46  5.46\n116   Antigua WEAN    B1    8 T022   43  3.45\n117   Antigua WEAN    B1    9 T111   45  4.96\n118   Antigua WEAN    B2   10 T111   46  4.26\n119   Antigua WEAN    B2   11 T131   48  6.35\n120   Antigua WEAN    B2   12 T020   47  4.28\n121   Antigua WEAN    B2   13 T111   41  4.94\n122   Antigua WEAN    B2   14 T311   38  4.39\n123   Antigua WEAN    B2   15 T002   44  3.92\n124   Antigua WEAN    B2   16 T113   43  5.74\n125   Antigua WEAN    B2   17 T200   46  4.98\n126   Antigua WEAN    B2   18 T222   44  5.40\n127   Antigua WEAN    B3   19 T111   45  6.10\n128   Antigua WEAN    B3   20 T113   45  5.86\n129   Antigua WEAN    B3   21 T022   47  4.59\n130   Antigua WEAN    B3   22 T311   36  4.36\n131   Antigua WEAN    B3   23 T000   41  4.16\n132   Antigua WEAN    B3   24 T111   46  6.58\n133   Antigua WEAN    B3   25 T220   38  5.11\n134   Antigua WEAN    B3   26 T131   48  5.96\n135   Antigua WEAN    B3   27 T202   36  3.45\n136   Antigua WEAN    B4   28 T020   43  5.77\n137   Antigua WEAN    B4   29 T111   46  6.60\n138   Antigua WEAN    B4   30 T200   43  3.88\n139   Antigua WEAN    B4   31 T222   34  4.04\n140   Antigua WEAN    B4   32 T002   32  2.76\n141   Antigua WEAN    B4   33 T311   42  6.31\n142   Antigua WEAN    B4   34 T131   38  5.28\n143   Antigua WEAN    B4   35 T113   44  4.61\n144   Antigua WEAN    B4   36 T111   46  5.65\n145   Antigua WLAN    B1    1 T000   58  2.00\n146   Antigua WLAN    B1    2 T113   56  2.39\n147   Antigua WLAN    B1    3 T131   52  2.04\n148   Antigua WLAN    B1    4 T202   44  1.64\n149   Antigua WLAN    B1    5 T220   45  1.83\n150   Antigua WLAN    B1    6 T111   47  2.08\n151   Antigua WLAN    B1    7 T022   55  3.13\n152   Antigua WLAN    B1    8 T111   53  1.96\n153   Antigua WLAN    B1    9 T311   43  1.30\n154   Antigua WLAN    B2   10 T311   68  2.16\n155   Antigua WLAN    B2   11 T002   40  1.74\n156   Antigua WLAN    B2   12 T111   58  2.46\n157   Antigua WLAN    B2   13 T200   44  2.17\n158   Antigua WLAN    B2   14 T020   42  2.72\n159   Antigua WLAN    B2   15 T113   55  2.07\n160   Antigua WLAN    B2   16 T111   54  2.87\n161   Antigua WLAN    B2   17 T222   48  2.14\n162   Antigua WLAN    B2   18 T131   38  1.45\n163   Antigua WLAN    B3   19 T311   69  2.05\n164   Antigua WLAN    B3   20 T022   60  2.44\n165   Antigua WLAN    B3   21 T111   50  2.88\n166   Antigua WLAN    B3   22 T000   40  2.28\n167   Antigua WLAN    B3   23 T111   51  3.44\n168   Antigua WLAN    B3   24 T113   54  2.56\n169   Antigua WLAN    B3   25 T202   41  2.41\n170   Antigua WLAN    B3   26 T131   53  3.24\n171   Antigua WLAN    B3   27 T220   51  1.66\n172   Antigua WLAN    B4   28 T200   57  1.76\n173   Antigua WLAN    B4   29 T113   55  2.84\n174   Antigua WLAN    B4   30 T002   39  2.25\n175   Antigua WLAN    B4   31 T131   63  2.73\n176   Antigua WLAN    B4   32 T111   48  3.55\n177   Antigua WLAN    B4   33 T311   51  3.13\n178   Antigua WLAN    B4   34 T020   39  2.41\n179   Antigua WLAN    B4   35 T111   43  3.49\n180   Antigua WLAN    B4   36 T222   56  1.96\n181   Antigua NSAN    B1    1 T202   25  2.43\n182   Antigua NSAN    B1    2 T111   13  1.28\n183   Antigua NSAN    B1    3 T311   10  0.83\n184   Antigua NSAN    B1    4 T131   24  2.44\n185   Antigua NSAN    B1    5 T022   30  1.30\n186   Antigua NSAN    B1    6 T000   25  1.34\n187   Antigua NSAN    B1    7 T113   25  2.06\n188   Antigua NSAN    B1    8 T220   32  3.02\n189   Antigua NSAN    B1    9 T111   27  2.18\n190   Antigua NSAN    B2   10 T131   26  2.35\n191   Antigua NSAN    B2   11 T002   28  2.15\n192   Antigua NSAN    B2   12 T111   36  3.24\n193   Antigua NSAN    B2   13 T020   34  2.78\n194   Antigua NSAN    B2   14 T222   27  2.91\n195   Antigua NSAN    B2   15 T111   32  3.10\n196   Antigua NSAN    B2   16 T200   28  2.86\n197   Antigua NSAN    B2   17 T113   32  3.33\n198   Antigua NSAN    B2   18 T311   32  3.00\n199   Antigua NSAN    B3   19 T022   32  2.75\n200   Antigua NSAN    B3   20 T131   36  2.92\n201   Antigua NSAN    B3   21 T000   28  1.70\n202   Antigua NSAN    B3   22 T220   34  3.36\n203   Antigua NSAN    B3   23 T111   30  1.58\n204   Antigua NSAN    B3   24 T202   27  1.98\n205   Antigua NSAN    B3   25 T311   39  2.90\n206   Antigua NSAN    B3   26 T113   26  2.05\n207   Antigua NSAN    B3   27 T111   24  1.40\n208   Antigua NSAN    B4   28 T002   33  1.95\n209   Antigua NSAN    B4   29 T111   29  2.34\n210   Antigua NSAN    B4   30 T200   19  1.55\n211   Antigua NSAN    B4   31 T222   22  1.73\n212   Antigua NSAN    B4   32 T020   30  2.05\n213   Antigua NSAN    B4   33 T131   33  3.44\n214   Antigua NSAN    B4   34 T113   33  2.11\n215   Antigua NSAN    B4   35 T311   35  3.22\n216   Antigua NSAN    B4   36 T111   21  1.60\n217   Antigua OVAN    B1    1 T111   28  2.04\n218   Antigua OVAN    B1    2 T113   35  3.88\n219   Antigua OVAN    B1    3 T311   38  5.53\n220   Antigua OVAN    B1    4 T131   42  6.61\n221   Antigua OVAN    B1    5 T000   31  2.97\n222   Antigua OVAN    B1    6 T111   35  4.47\n223   Antigua OVAN    B1    7 T220   26  4.06\n224   Antigua OVAN    B1    8 T022   37  5.02\n225   Antigua OVAN    B1    9 T202   38  4.56\n226   Antigua OVAN    B2   10 T111   41  3.50\n227   Antigua OVAN    B2   11 T020   37  4.58\n228   Antigua OVAN    B2   12 T131   30  4.42\n229   Antigua OVAN    B2   13 T200   47  6.16\n230   Antigua OVAN    B2   14 T311   45  6.09\n231   Antigua OVAN    B2   15 T113   38  4.94\n232   Antigua OVAN    B2   16 T222   37  5.83\n233   Antigua OVAN    B2   17 T111   37  5.05\n234   Antigua OVAN    B2   18 T002   30  3.90\n235   Antigua OVAN    B3   19 T131   35  3.92\n236   Antigua OVAN    B3   20 T022   42  4.78\n237   Antigua OVAN    B3   21 T111   40  5.26\n238   Antigua OVAN    B3   22 T220   40  5.52\n239   Antigua OVAN    B3   23 T111   42  5.87\n240   Antigua OVAN    B3   24 T311   43  6.19\n241   Antigua OVAN    B3   25 T000   39  5.26\n242   Antigua OVAN    B3   26 T202   30  3.08\n243   Antigua OVAN    B3   27 T113   29  3.14\n244   Antigua OVAN    B4   28 T222   45  4.56\n245   Antigua OVAN    B4   29 T113   38  4.74\n246   Antigua OVAN    B4   30 T311   38  5.32\n247   Antigua OVAN    B4   31 T111   45  5.57\n248   Antigua OVAN    B4   32 T002   26  1.69\n249   Antigua OVAN    B4   33 T020   40  4.57\n250   Antigua OVAN    B4   34 T131   38  6.18\n251   Antigua OVAN    B4   35 T111   48  6.90\n252   Antigua OVAN    B4   36 T200   33  3.93\n253   Antigua ORAN    B1    1 T113   43  5.26\n254   Antigua ORAN    B1    2 T111   44  6.87\n255   Antigua ORAN    B1    3 T202   44  7.78\n256   Antigua ORAN    B1    4 T311   41  6.75\n257   Antigua ORAN    B1    5 T022   44  6.56\n258   Antigua ORAN    B1    6 T131   42  6.47\n259   Antigua ORAN    B1    7 T111   41  6.71\n260   Antigua ORAN    B1    8 T220   41  6.74\n261   Antigua ORAN    B1    9 T000   45  6.92\n262   Antigua ORAN    B2   10 T002   36  3.75\n263   Antigua ORAN    B2   11 T020   35  3.56\n264   Antigua ORAN    B2   12 T113   38  5.45\n265   Antigua ORAN    B2   13 T311   40  7.55\n266   Antigua ORAN    B2   14 T111   40  7.20\n267   Antigua ORAN    B2   15 T222   44  6.48\n268   Antigua ORAN    B2   16 T200   41  7.36\n269   Antigua ORAN    B2   17 T131   41  7.18\n270   Antigua ORAN    B2   18 T111   48  7.53\n271   Antigua ORAN    B3   19 T000   36  5.74\n272   Antigua ORAN    B3   20 T311   44  7.52\n273   Antigua ORAN    B3   21 T220   46  7.87\n274   Antigua ORAN    B3   22 T111   43  6.39\n275   Antigua ORAN    B3   23 T113   46  7.04\n276   Antigua ORAN    B3   24 T111   40  6.48\n277   Antigua ORAN    B3   25 T131   47  7.56\n278   Antigua ORAN    B3   26 T202   46  6.87\n279   Antigua ORAN    B3   27 T022   41  6.12\n280   Antigua ORAN    B4   28 T200   47  7.45\n281   Antigua ORAN    B4   29 T111   45  6.75\n282   Antigua ORAN    B4   30 T131   42  6.41\n283   Antigua ORAN    B4   31 T020   37  5.28\n284   Antigua ORAN    B4   32 T311   35  5.27\n285   Antigua ORAN    B4   33 T002   46  7.28\n286   Antigua ORAN    B4   34 T111   45  7.39\n287   Antigua ORAN    B4   35 T222   43  6.61\n288   Antigua ORAN    B4   36 T113   37  4.75\n289 StVincent CPSV    B1    1 T022   NA 24.00\n290 StVincent CPSV    B1    2 T131   NA 27.10\n291 StVincent CPSV    B1    3 T111   NA 26.50\n292 StVincent CPSV    B1    4 T000   NA 23.10\n293 StVincent CPSV    B1    5 T202   NA 22.10\n294 StVincent CPSV    B1    6 T220   NA 24.10\n295 StVincent CPSV    B1    7 T111   NA 26.10\n296 StVincent CPSV    B1    8 T113   NA 22.50\n297 StVincent CPSV    B1    9 T311   NA 23.00\n298 StVincent CPSV    B2   10 T111   NA 26.40\n299 StVincent CPSV    B2   11 T311   NA 24.80\n300 StVincent CPSV    B2   12 T111   NA 23.80\n301 StVincent CPSV    B2   13 T222   NA 24.00\n302 StVincent CPSV    B2   14 T200   NA 22.80\n303 StVincent CPSV    B2   15 T131   NA 26.00\n304 StVincent CPSV    B2   16 T002   NA 20.50\n305 StVincent CPSV    B2   17 T113   NA 24.40\n306 StVincent CPSV    B2   18 T020   NA 26.00\n307 StVincent CPSV    B3   19 T220   NA 19.00\n308 StVincent CPSV    B3   20 T111   NA 21.00\n309 StVincent CPSV    B3   21 T111   NA 24.10\n310 StVincent CPSV    B3   22 T311   NA 23.10\n311 StVincent CPSV    B3   23 T131   NA 20.10\n312 StVincent CPSV    B3   24 T022   NA 23.20\n313 StVincent CPSV    B3   25 T202   NA 19.80\n314 StVincent CPSV    B3   26 T113   NA 19.00\n315 StVincent CPSV    B3   27 T000   NA 22.20\n316 StVincent CPSV    B4   28 T131   NA 25.20\n317 StVincent CPSV    B4   29 T222   NA 24.80\n318 StVincent CPSV    B4   30 T200   NA 21.20\n319 StVincent CPSV    B4   31 T111   NA 23.10\n320 StVincent CPSV    B4   32 T002   NA 20.90\n321 StVincent CPSV    B4   33 T311   NA 20.00\n322 StVincent CPSV    B4   34 T020   NA 20.90\n323 StVincent CPSV    B4   35 T111   NA 21.50\n324 StVincent CPSV    B4   36 T113   NA 13.40\n325 StVincent MPSV    B1    1 T311   NA 16.70\n326 StVincent MPSV    B1    2 T131   NA 13.00\n327 StVincent MPSV    B1    3 T111   NA 17.80\n328 StVincent MPSV    B1    4 T111   NA 11.50\n329 StVincent MPSV    B1    5 T022   NA 12.40\n330 StVincent MPSV    B1    6 T113   NA 12.10\n331 StVincent MPSV    B1    7 T220   NA 13.50\n332 StVincent MPSV    B1    8 T000   NA  8.50\n333 StVincent MPSV    B1    9 T202   NA 13.00\n334 StVincent MPSV    B2   10 T131   NA 12.20\n335 StVincent MPSV    B2   11 T222   NA 15.10\n336 StVincent MPSV    B2   12 T200   NA 11.80\n337 StVincent MPSV    B2   13 T111   NA 12.80\n338 StVincent MPSV    B2   14 T002   NA  7.10\n339 StVincent MPSV    B2   15 T311   NA 17.00\n340 StVincent MPSV    B2   16 T020   NA  6.20\n341 StVincent MPSV    B2   17 T111   NA 12.50\n342 StVincent MPSV    B2   18 T113   NA 15.20\n343 StVincent MPSV    B3   19 T000   NA  8.10\n344 StVincent MPSV    B3   20 T113   NA 13.10\n345 StVincent MPSV    B3   21 T202   NA 14.20\n346 StVincent MPSV    B3   22 T311   NA 18.90\n347 StVincent MPSV    B3   23 T022   NA 12.50\n348 StVincent MPSV    B3   24 T131   NA 17.00\n349 StVincent MPSV    B3   25 T111   NA 13.50\n350 StVincent MPSV    B3   26 T220   NA 12.00\n351 StVincent MPSV    B3   27 T111   NA 12.80\n352 StVincent MPSV    B4   28 T113   NA 14.00\n353 StVincent MPSV    B4   29 T002   NA 10.50\n354 StVincent MPSV    B4   30 T020   NA 14.40\n355 StVincent MPSV    B4   31 T111   NA 13.80\n356 StVincent MPSV    B4   32 T311   NA 12.80\n357 StVincent MPSV    B4   33 T131   NA 14.50\n358 StVincent MPSV    B4   34 T222   NA 13.10\n359 StVincent MPSV    B4   35 T200   NA 14.00\n360 StVincent MPSV    B4   36 T111   NA 13.50\n361 StVincent AGSV    B1    1 T220   NA 10.40\n362 StVincent AGSV    B1    2 T000   NA  9.10\n363 StVincent AGSV    B1    3 T131   NA  9.20\n364 StVincent AGSV    B1    4 T022   NA 10.10\n365 StVincent AGSV    B1    5 T311   NA 15.20\n366 StVincent AGSV    B1    6 T111   NA 13.90\n367 StVincent AGSV    B1    7 T113   NA 15.10\n368 StVincent AGSV    B1    8 T111   NA 12.20\n369 StVincent AGSV    B1    9 T202   NA  9.80\n370 StVincent AGSV    B2   10 T113   NA 11.80\n371 StVincent AGSV    B2   11 T002   NA 10.10\n372 StVincent AGSV    B2   12 T020   NA 13.00\n373 StVincent AGSV    B2   13 T111   NA 13.20\n374 StVincent AGSV    B2   14 T311   NA 10.20\n375 StVincent AGSV    B2   15 T131   NA 12.00\n376 StVincent AGSV    B2   16 T222   NA 13.20\n377 StVincent AGSV    B2   17 T200   NA 10.90\n378 StVincent AGSV    B2   18 T111   NA 15.10\n379 StVincent AGSV    B3   19 T220   NA  9.90\n380 StVincent AGSV    B3   20 T022   NA 12.00\n381 StVincent AGSV    B3   21 T113   NA 12.50\n382 StVincent AGSV    B3   22 T111   NA 14.50\n383 StVincent AGSV    B3   23 T131   NA 12.20\n384 StVincent AGSV    B3   24 T111   NA 11.50\n385 StVincent AGSV    B3   25 T202   NA 11.50\n386 StVincent AGSV    B3   26 T311   NA 16.50\n387 StVincent AGSV    B3   27 T000   NA  7.80\n388 StVincent AGSV    B4   28 T200   NA 13.00\n389 StVincent AGSV    B4   29 T311   NA  7.00\n390 StVincent AGSV    B4   30 T111   NA 12.40\n391 StVincent AGSV    B4   31 T222   NA 14.00\n392 StVincent AGSV    B4   32 T131   NA 13.10\n393 StVincent AGSV    B4   33 T111   NA 13.00\n394 StVincent AGSV    B4   34 T020   NA 16.00\n395 StVincent AGSV    B4   35 T113   NA 14.50\n396 StVincent AGSV    B4   36 T002   NA 11.00\n397 StVincent CASV    B1    1 T311   NA 22.00\n398 StVincent CASV    B1    2 T113   NA 18.20\n399 StVincent CASV    B1    3 T022   NA 14.40\n400 StVincent CASV    B1    4 T111   NA 22.40\n401 StVincent CASV    B1    5 T220   NA 22.30\n402 StVincent CASV    B1    6 T111   NA 20.00\n403 StVincent CASV    B1    7 T000   NA 16.00\n404 StVincent CASV    B1    8 T202   NA 17.20\n405 StVincent CASV    B1    9 T131   NA 16.10\n406 StVincent CASV    B2   10 T311   NA 22.10\n407 StVincent CASV    B2   11 T113   NA 20.30\n408 StVincent CASV    B2   12 T020   NA 16.00\n409 StVincent CASV    B2   13 T111   NA 23.80\n410 StVincent CASV    B2   14 T131   NA 20.20\n411 StVincent CASV    B2   15 T111   NA 24.50\n412 StVincent CASV    B2   16 T222   NA 26.80\n413 StVincent CASV    B2   17 T200   NA 19.90\n414 StVincent CASV    B2   18 T002   NA 13.70\n415 StVincent CASV    B3   19 T202   NA  9.10\n416 StVincent CASV    B3   20 T113   NA 12.20\n417 StVincent CASV    B3   21 T000   NA 11.10\n418 StVincent CASV    B3   22 T131   NA 10.50\n419 StVincent CASV    B3   23 T311   NA 21.80\n420 StVincent CASV    B3   24 T111   NA 17.20\n421 StVincent CASV    B3   25 T111   NA 20.50\n422 StVincent CASV    B3   26 T220   NA 20.00\n423 StVincent CASV    B3   27 T022   NA 16.10\n424 StVincent CASV    B4   28 T002   NA 19.10\n425 StVincent CASV    B4   29 T111   NA 22.20\n426 StVincent CASV    B4   30 T111   NA 24.20\n427 StVincent CASV    B4   31 T131   NA 20.20\n428 StVincent CASV    B4   32 T311   NA 21.10\n429 StVincent CASV    B4   33 T200   NA 22.80\n430 StVincent CASV    B4   34 T020   NA 20.10\n431 StVincent CASV    B4   35 T113   NA 20.30\n432 StVincent CASV    B4   36 T222   NA 22.00\n433 StVincent SSSV    B1    1 T022   NA  9.50\n434 StVincent SSSV    B1    2 T202   NA 10.50\n435 StVincent SSSV    B1    3 T000   NA 14.10\n436 StVincent SSSV    B1    4 T220   NA  9.70\n437 StVincent SSSV    B1    5 T131   NA 11.20\n438 StVincent SSSV    B1    6 T111   NA 13.10\n439 StVincent SSSV    B1    7 T311   NA  9.20\n440 StVincent SSSV    B1    8 T113   NA 13.10\n441 StVincent SSSV    B1    9 T111   NA 11.50\n442 StVincent SSSV    B2   10 T111   NA 11.20\n443 StVincent SSSV    B2   11 T020   NA 12.10\n444 StVincent SSSV    B2   12 T002   NA 11.00\n445 StVincent SSSV    B2   13 T111   NA 16.10\n446 StVincent SSSV    B2   14 T200   NA 12.50\n447 StVincent SSSV    B2   15 T131   NA  9.90\n448 StVincent SSSV    B2   16 T222   NA 17.50\n449 StVincent SSSV    B2   17 T131   NA 11.80\n450 StVincent SSSV    B2   18 T311   NA 12.20\n451 StVincent SSSV    B3   19 T202   NA  8.70\n452 StVincent SSSV    B3   20 T131   NA 16.40\n453 StVincent SSSV    B3   21 T113   NA 16.10\n454 StVincent SSSV    B3   22 T220   NA  9.10\n455 StVincent SSSV    B3   23 T022   NA 12.20\n456 StVincent SSSV    B3   24 T111   NA 12.40\n457 StVincent SSSV    B3   25 T111   NA 10.00\n458 StVincent SSSV    B3   26 T000   NA 12.30\n459 StVincent SSSV    B3   27 T311   NA  9.00\n460 StVincent SSSV    B4   28 T111   NA 15.20\n461 StVincent SSSV    B4   29 T113   NA 20.20\n462 StVincent SSSV    B4   30 T020   NA 13.70\n463 StVincent SSSV    B4   31 T111   NA 14.20\n464 StVincent SSSV    B4   32 T200   NA 14.50\n465 StVincent SSSV    B4   33 T222   NA 12.00\n466 StVincent SSSV    B4   34 T002   NA 11.50\n467 StVincent SSSV    B4   35 T311   NA 11.20\n468 StVincent SSSV    B4   36 T131   NA 10.20\n469 StVincent UISV    B1    1 T202   NA 15.40\n470 StVincent UISV    B1    2 T000   NA 12.20\n471 StVincent UISV    B1    3 T220   NA 26.00\n472 StVincent UISV    B1    4 T111   NA 20.10\n473 StVincent UISV    B1    5 T022   NA 14.10\n474 StVincent UISV    B1    6 T131   NA 21.80\n475 StVincent UISV    B1    7 T113   NA 20.10\n476 StVincent UISV    B1    8 T311   NA 28.10\n477 StVincent UISV    B1    9 T111   NA 23.10\n478 StVincent UISV    B2   10 T311   NA 22.40\n479 StVincent UISV    B2   11 T113   NA 28.90\n480 StVincent UISV    B2   12 T111   NA 19.00\n481 StVincent UISV    B2   13 T131   NA 21.40\n482 StVincent UISV    B2   14 T111   NA 20.50\n483 StVincent UISV    B2   15 T020   NA 14.00\n484 StVincent UISV    B2   16 T200   NA 29.50\n485 StVincent UISV    B2   17 T002   NA 13.30\n486 StVincent UISV    B2   18 T222   NA 23.70\n487 StVincent UISV    B3   19 T202   NA 25.10\n488 StVincent UISV    B3   20 T220   NA 30.10\n489 StVincent UISV    B3   21 T111   NA 23.10\n490 StVincent UISV    B3   22 T113   NA 24.50\n491 StVincent UISV    B3   23 T131   NA 17.80\n492 StVincent UISV    B3   24 T022   NA 15.10\n493 StVincent UISV    B3   25 T311   NA 25.80\n494 StVincent UISV    B3   26 T111   NA 23.20\n495 StVincent UISV    B3   27 T000   NA 17.20\n496 StVincent UISV    B4   28 T113   NA 20.40\n497 StVincent UISV    B4   29 T111   NA 22.50\n498 StVincent UISV    B4   30 T200   NA 22.20\n499 StVincent UISV    B4   31 T311   NA 26.80\n500 StVincent UISV    B4   32 T131   NA 23.00\n501 StVincent UISV    B4   33 T002   NA 11.40\n502 StVincent UISV    B4   34 T020   NA 19.50\n503 StVincent UISV    B4   35 T222   NA 25.50\n504 StVincent UISV    B4   36 T111   NA 19.80\n505 StVincent OOSV    B1    1 T111   NA 16.00\n506 StVincent OOSV    B1    2 T000   NA 12.00\n507 StVincent OOSV    B1    3 T113   NA 21.10\n508 StVincent OOSV    B1    4 T311   NA 22.10\n509 StVincent OOSV    B1    5 T111   NA 20.00\n510 StVincent OOSV    B1    6 T220   NA 23.20\n511 StVincent OOSV    B1    7 T202   NA 20.60\n512 StVincent OOSV    B1    8 T131   NA 12.80\n513 StVincent OOSV    B1    9 T022   NA  9.00\n514 StVincent OOSV    B2   10 T020   NA 12.30\n515 StVincent OOSV    B2   11 T002   NA 11.00\n516 StVincent OOSV    B2   12 T111   NA 17.00\n517 StVincent OOSV    B2   13 T113   NA 24.00\n518 StVincent OOSV    B2   14 T311   NA 28.50\n519 StVincent OOSV    B2   15 T200   NA 25.70\n520 StVincent OOSV    B2   16 T111   NA 13.10\n521 StVincent OOSV    B2   17 T222   NA 16.30\n522 StVincent OOSV    B2   18 T131   NA 15.00\n523 StVincent OOSV    B3   19 T131   NA 13.10\n524 StVincent OOSV    B3   20 T022   NA 10.00\n525 StVincent OOSV    B3   21 T202   NA 14.00\n526 StVincent OOSV    B3   22 T220   NA 18.80\n527 StVincent OOSV    B3   23 T111   NA 14.00\n528 StVincent OOSV    B3   24 T113   NA 11.00\n529 StVincent OOSV    B3   25 T111   NA 18.10\n530 StVincent OOSV    B3   26 T000   NA 12.10\n531 StVincent OOSV    B3   27 T311   NA 28.00\n532 StVincent OOSV    B4   28 T311   NA 20.60\n533 StVincent OOSV    B4   29 T113   NA 10.10\n534 StVincent OOSV    B4   30 T200   NA 19.20\n535 StVincent OOSV    B4   31 T002   NA  7.60\n536 StVincent OOSV    B4   32 T020   NA  8.20\n537 StVincent OOSV    B4   33 T222   NA 23.10\n538 StVincent OOSV    B4   34 T111   NA 15.80\n539 StVincent OOSV    B4   35 T111   NA 18.60\n540 StVincent OOSV    B4   36 T113   NA 20.00\n541 StVincent OTSV    B1    1 T022   NA 12.20\n542 StVincent OTSV    B1    2 T113   NA 19.80\n543 StVincent OTSV    B1    3 T131   NA 19.90\n544 StVincent OTSV    B1    4 T311   NA 25.30\n545 StVincent OTSV    B1    5 T111   NA 19.00\n546 StVincent OTSV    B1    6 T111   NA 20.50\n547 StVincent OTSV    B1    7 T000   NA  7.80\n548 StVincent OTSV    B1    8 T202   NA 17.80\n549 StVincent OTSV    B1    9 T220   NA 19.70\n550 StVincent OTSV    B2   10 T020   NA 13.10\n551 StVincent OTSV    B2   11 T311   NA 22.40\n552 StVincent OTSV    B2   12 T113   NA 23.20\n553 StVincent OTSV    B2   13 T111   NA 17.80\n554 StVincent OTSV    B2   14 T200   NA 20.00\n555 StVincent OTSV    B2   15 T002   NA 20.00\n556 StVincent OTSV    B2   16 T131   NA 15.60\n557 StVincent OTSV    B2   17 T222   NA 15.70\n558 StVincent OTSV    B2   18 T111   NA 29.10\n559 StVincent OTSV    B3   19 T311   NA 13.10\n560 StVincent OTSV    B3   20 T022   NA 20.40\n561 StVincent OTSV    B3   21 T111   NA 10.80\n562 StVincent OTSV    B3   22 T000   NA 18.40\n563 StVincent OTSV    B3   23 T220   NA 14.00\n564 StVincent OTSV    B3   24 T131   NA 14.20\n565 StVincent OTSV    B3   25 T111   NA 14.10\n566 StVincent OTSV    B3   26 T113   NA 18.40\n567 StVincent OTSV    B3   27 T202   NA 20.50\n568 StVincent OTSV    B4   28 T113   NA 13.00\n569 StVincent OTSV    B4   29 T020   NA  8.40\n570 StVincent OTSV    B4   30 T002   NA 10.00\n571 StVincent OTSV    B4   31 T311   NA 14.10\n572 StVincent OTSV    B4   32 T200   NA 18.10\n573 StVincent OTSV    B4   33 T222   NA 22.20\n574 StVincent OTSV    B4   34 T131   NA 14.20\n575 StVincent OTSV    B4   35 T111   NA 12.10\n576 StVincent OTSV    B4   36 T111   NA 13.00\n577 StVincent LPSV    B1    1 T311   NA 14.20\n578 StVincent LPSV    B1    2 T111   NA  8.20\n579 StVincent LPSV    B1    3 T220   NA  3.50\n580 StVincent LPSV    B1    4 T022   NA  7.20\n581 StVincent LPSV    B1    5 T131   NA  9.20\n582 StVincent LPSV    B1    6 T202   NA  8.50\n583 StVincent LPSV    B1    7 T111   NA  6.70\n584 StVincent LPSV    B1    8 T000   NA  7.50\n585 StVincent LPSV    B1    9 T113   NA 14.20\n586 StVincent LPSV    B2   10 T111   NA  4.50\n587 StVincent LPSV    B2   11 T200   NA  8.00\n588 StVincent LPSV    B2   12 T222   NA  5.50\n589 StVincent LPSV    B2   13 T131   NA  9.10\n590 StVincent LPSV    B2   14 T111   NA  7.20\n591 StVincent LPSV    B2   15 T311   NA  8.70\n592 StVincent LPSV    B2   16 T020   NA  6.10\n593 StVincent LPSV    B2   17 T113   NA 16.30\n594 StVincent LPSV    B2   18 T002   NA 15.20\n595 StVincent LPSV    B3   19 T111   NA  7.10\n596 StVincent LPSV    B3   20 T000   NA  6.10\n597 StVincent LPSV    B3   21 T220   NA 16.00\n598 StVincent LPSV    B3   22 T202   NA 16.80\n599 StVincent LPSV    B3   23 T131   NA 13.50\n600 StVincent LPSV    B3   24 T022   NA  8.80\n601 StVincent LPSV    B3   25 T111   NA 18.20\n602 StVincent LPSV    B3   26 T311   NA 13.50\n603 StVincent LPSV    B3   27 T113   NA 15.90\n604 StVincent LPSV    B4   28 T111   NA 17.50\n605 StVincent LPSV    B4   29 T113   NA 11.00\n606 StVincent LPSV    B4   30 T131   NA 11.40\n607 StVincent LPSV    B4   31 T111   NA 14.90\n608 StVincent LPSV    B4   32 T200   NA 24.50\n609 StVincent LPSV    B4   33 T002   NA  9.00\n610 StVincent LPSV    B4   34 T020   NA  7.10\n611 StVincent LPSV    B4   35 T222   NA 12.90\n612 StVincent LPSV    B4   36 T311   NA  6.80\n\n\n\nlibrary(agridat)\ndata(\"durban.splitplot\")\ndata(\"brandle.rape\")\n\ndata1 &lt;- brandle.rape\ntable(data1$gen, data1$loc)\n\n        \n         Bagot Beausejour Dauphin Mariapolis Roblin ShoalLake Souris SwanRiver\n  Altex      3          3       3          3      3         3      3         3\n  Andor      3          3       3          3      3         3      3         3\n  Regent     3          3       3          3      3         3      3         3\n  Triton     3          3       3          3      3         3      3         3\n  Westar     3          3       3          3      3         3      3         3\n        \n         Teulon\n  Altex       3\n  Andor       3\n  Regent      3\n  Triton      3\n  Westar      3\n\n\n\ndata(\"hunter.corn\")\ndata2 &lt;- hunter.corn\n\ntable(data2$nitro, data2$loc, data2$year)\n\n, ,  = 1950\n\n     \n      Benedict Cloud Custer Hobson Malheur MalheurSp Martin Moeller VdeW\n  0          0     0      0      1       1         0      0       1    0\n  50         0     0      0      1       1         0      0       1    0\n  100        0     0      0      1       1         0      0       1    0\n  150        0     0      0      1       1         0      0       1    0\n  200        0     0      0      0       0         0      0       0    0\n\n, ,  = 1951\n\n     \n      Benedict Cloud Custer Hobson Malheur MalheurSp Martin Moeller VdeW\n  0          0     0      1      0       1         0      0       1    1\n  50         0     0      1      0       1         0      0       1    1\n  100        0     0      1      0       1         0      0       1    1\n  150        0     0      1      0       1         0      0       1    1\n  200        0     0      1      0       0         0      0       1    1\n\n, ,  = 1952\n\n     \n      Benedict Cloud Custer Hobson Malheur MalheurSp Martin Moeller VdeW\n  0          1     1      0      0       1         1      1       0    0\n  50         1     1      0      0       1         1      1       0    0\n  100        1     1      0      0       1         1      1       0    0\n  150        1     1      0      0       1         1      1       0    0\n  200        1     1      0      0       0         0      1       0    0\n\n\n\nFactorial design repeated measures\n\nAs explained in Chapter 6, factorial designs involve examining several factors simultaneously\nhttps://search.r-project.org/CRAN/refmans/agridat/html/gregory.cotton.html\n\ndata3 &lt;- agridat::gregory.cotton\nstr(data3)\n\n'data.frame':   144 obs. of  6 variables:\n $ yield   : num  0.99 1.34 1.26 1.44 1.4 1.36 1.23 1.28 1.56 1.64 ...\n $ year    : Factor w/ 2 levels \"Y1\",\"Y2\": 1 1 1 1 1 1 1 1 1 1 ...\n $ nitrogen: Factor w/ 2 levels \"N0\",\"N1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ date    : Factor w/ 4 levels \"D1\",\"D2\",\"D3\",..: 1 1 1 1 1 1 1 1 1 2 ...\n $ water   : Factor w/ 3 levels \"I1\",\"I2\",\"I3\": 1 1 1 2 2 2 3 3 3 1 ...\n $ spacing : Factor w/ 3 levels \"S1\",\"S2\",\"S3\": 1 2 3 1 2 3 1 2 3 1 ...\n\n\n\ntable(data3$nitrogen, data3$date)\n\n    \n     D1 D2 D3 D4\n  N0 18 18 18 18\n  N1 18 18 18 18\n\n\nThe biggest advantage of mixed models is their incredible flexibility. They handle clustered individuals as well as repeated measures (even in the same model). They handle crossed random factors as well as nested\nThe biggest disadvantage of mixed models, at least for someone new to them, is their incredible flexibility. It’s easy to mis-specify a mixed model, and this is a place where a little knowledge is definitely dangerous.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Repeated measures mixed models</span>"
    ]
  },
  {
    "objectID": "chapters/special-conditions.html",
    "href": "chapters/special-conditions.html",
    "title": "11  Combining Scenarios",
    "section": "",
    "text": "11.1 Split plot with repeated measures\nNormally-distributed data",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Combining Scenarios</span>"
    ]
  },
  {
    "objectID": "chapters/special-conditions.html#split-plot-with-repeated-measures",
    "href": "chapters/special-conditions.html#split-plot-with-repeated-measures",
    "title": "11  Combining Scenarios",
    "section": "",
    "text": "11.1.0.1 Load data\nThis is an alfalfa study consisting of two treatments: irrigation level and planting mix with four reps. Each plot (the experimental unit) was harvested three times and the yield was measured.\n\nalfalfa &lt;- read.csv(here::here(\"data\", \"alfalfa_intercropping.csv\"))\n\n|———-|—————————————-| | cut | a cutting (harvest) of alfalfa within a single growing season. This is a temporal unit for repeated measures analysis. There were three cuttings in total for that year and field. The dates are not known, so we cannot assume they are evenly spaced apart |\n|irrigation | main plot, irrigation treatment (“Full” or “Deficit”) |\n|plot | a number referring to each experimental unit |\n|block | the blocking unit |\n|yield | alfalfa yield (the response variable) |\n|row | plot position for row |\n|col | plot positions for column or range. |\nTwo new variables need to be created:\n\nblock: character version of the original ‘block’\ncut_num: integer version of ‘cut’. This is required by nlme::lme for specialized correlation structures. The numeric order of this variable matches the cut order.\n\n\nalfalfa_sp &lt;- alfalfa %&gt;% \n  mutate(block = as.character(block)) %&gt;% \n  mutate(cut_num = case_when(\n    cut == \"First\" ~ 1L,\n    cut == \"Second\" ~ 2L,\n    cut == \"Third\" ~ 3L,\n    is.na(cut) ~ NA_integer_)) \n\n\n\n11.1.0.2 Data integrity checks\nData type check:\n\nstr(alfalfa_sp)\n\n'data.frame':   240 obs. of  9 variables:\n $ cut       : chr  \"First\" \"First\" \"First\" \"First\" ...\n $ irrigation: chr  \"Full\" \"Full\" \"Full\" \"Full\" ...\n $ plot      : int  1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 ...\n $ block     : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ mix       : chr  \"50A+50O\" \"75A+25O\" \"50A+50F\" \"75A+25M\" ...\n $ yield     : num  221 289 467 557 423 ...\n $ row       : int  1 1 1 1 1 2 2 2 2 2 ...\n $ col       : int  1 2 3 4 5 1 2 3 4 5 ...\n $ cut_num   : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\nData balance check:\n\ntable(alfalfa_sp$irrigation, alfalfa_sp$mix, alfalfa_sp$cut)\n\n, ,  = First\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n, ,  = Second\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n, ,  = Third\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n\nCheck missingness:\n\napply(alfalfa_sp, 2, function(x) sum(is.na(x)))\n\n       cut irrigation       plot      block        mix      yield        row \n         0          0          0          0          0          0          0 \n       col    cut_num \n         0          0 \n\n\nCheck dependent data:\n\nhist(alfalfa_sp$yield)\n\n\n\n\n\n\n\n\nThere are some very high values that we should keep an eye on.\nExperimental layout:\n\nalfalfa_sp %&gt;% filter(cut == \"First\") %&gt;% \n  ggplot(aes(x = col, y = row)) +\n    geom_raster(aes(fill = irrigation)) +\n    geom_tileborder(aes(group = 1, grp = block), lwd = 1.5) + \n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n11.1.0.3 Data analysis\nModel statement:\n\\[y_{ijk} = \\mu + \\alpha_i+ \\beta_j + \\gamma_k + (\\alpha\\beta)_{ij} + (\\alpha\\gamma)_{ik} + (\\beta\\gamma)_{jk} + (\\alpha\\beta\\gamma)_{ijk} +\\epsilon_{ijk}\\]\nwhere\n\\(\\mu\\) = overall mean\n\\(\\alpha_i\\) = effect of the \\(i^{th}\\) irrigation treatment\n\\(\\beta_j\\) = effect of the \\(j^{th}\\) planting mix treatment\n\\(\\gamma_k\\) = effect of the \\(k^{th}\\) cutting\nAnd the remaining terms reflect two-way and three-way interactions.\nThe error terms are assumed to follow this distribution, \\(\\epsilon \\sim N(0, \\sigma)\\), and each plot is assumed to follow an auto-regressive correlation structure.\nThe starting model is very similar to the other split plot example in this guide where the main plot “irrigation” is nested with “block”. An additional level of nesting is used for “plot” since that is the experimental unit we are designating for the repeated measures term.\nI usually build the model in two steps: first the basic model is estimated, and next a correlation structure is added. This is not strictly needed; the model can be estimated in one step.\n\nm1 &lt;- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|block/irrigation/plot,\n          data = alfalfa_sp)\n\nSince we don’t know the temporal spacing for each cutting, a compound symmetry correlation structure will be used. This type assumes a single correlation across time. This has a starting value of 0.3 and this may chagne during the fitting process since fixed = FALSE.\n\ncorstr &lt;- corCompSymm(value = 0.3, \n                      form = ~ cut|block/irrigation/plot,\n                      fixed = FALSE)\n\nIt is required by nlme that two terms match after the “|” in the random and form arguments match exactly. The plot term is needed because this is the unit to calculate correlations at.\n\ncorstr &lt;- corCompSymm(value = 0.3, \n                      form = ~ cut|block/irrigation/plot,\n                      fixed = FALSE)\n\nm1 &lt;- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|block/irrigation/plot,\n          data = alfalfa_sp)\n\nUpdate the model with the correlation structure:\n\nm2 &lt;- update(m1, cor = corstr)\n\n\n\n11.1.0.4 Check model assumpotion\n\nplot(m2)\n\n\n\n\n\n\n\nqqnorm(m2, ~ resid(., type = \"p\"), abline = c(0, 1))\n\n\n\n\n\n\n\n\nThere are some very large outliers at the right side of the plot.\n\n\n11.1.0.5 Run ANOVA\n\nanova(m2)\n\n                   numDF denDF   F-value p-value\n(Intercept)            1   102 1432.6369  &lt;.0001\nmix                    9   102   13.6932  &lt;.0001\nirrigation             1     3    4.8770  0.1143\ncut                    2   102    6.0434  0.0033\nmix:irrigation         9   102    0.5256  0.8530\nmix:cut               18   102    0.8029  0.6927\nirrigation:cut         2   102   14.2649  &lt;.0001\nmix:irrigation:cut    18   102    1.0226  0.4418\n\n\nAlways check the degrees of freedom (denominator and numerator) to make sure the model is specified correctly.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Combining Scenarios</span>"
    ]
  },
  {
    "objectID": "chapters/variance-components.html",
    "href": "chapters/variance-components.html",
    "title": "12  Variance Components",
    "section": "",
    "text": "For when there are multiple variance components and an interest in understanding them.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Variance Components</span>"
    ]
  },
  {
    "objectID": "chapters/summary.html",
    "href": "chapters/summary.html",
    "title": "13  Summary",
    "section": "",
    "text": "In summary, mixed models are complicated.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "chapters/resources.html",
    "href": "chapters/resources.html",
    "title": "14  Additional Resources",
    "section": "",
    "text": "14.0.1 Further Reading\n\nlme4 vignette for fitting linear mixed models\n\n\n\n14.0.2 Other Resources",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Additional Resources</span>"
    ]
  }
]