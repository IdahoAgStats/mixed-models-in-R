[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Field Guide to the R Mixed Model Wilderness",
    "section": "",
    "text": "Preface\n‚ÄúPath in the Wilderness‚Äù by Erich Taeubel, Jr.\nRunning mixed models in R is no easy task. There are dozens of packages supporting these aims, each with varying functionality, syntax, and conventions. The linear mixed model ecosystem in R consists of over 80 libraries that either construct and solve mixed model equations or helper packages the process the results from mixed model analysis. These libraries provide a patchwork of overlapping and unique functionality regarding the fundamental structure of mixed models: allowable distributions, nested and crossed random effects, heterogeneous error structures and other facets. No single library has all possible functionality enabled.\nThis patchwork of packages makes it very challenging for statisticians to conduct mixed model analysis and to teach others how to run mixed models in R. The purpose of this guide to to provide some recipes for handling common analytical scenario‚Äôs that require mixed models. As a field guide, it is intended to be succinct, and help researchers meet their analytic goals.\nIn general, the content from this website may not be copied or reproduced. However, the example code and required data sets to run the code are MIT licensed. These can be accessed on GitHub.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Field Guide to the R Mixed Model Wilderness",
    "section": "Recent Updates",
    "text": "Recent Updates\nThis is a work-in-progress and will be updated over time.\n\nRCBD lesson has been completed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "1.1 Terms\nPlease read this section and refer back to if when you forget what these terms mean.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#terms",
    "href": "chapters/intro.html#terms",
    "title": "1¬† Introduction",
    "section": "",
    "text": "Table¬†1.1: Terms definitions\n\n\n\n\n\n\n\n\n\nTerm\nDefinition /Explanation\n\n\n\n\nRandom effect\nAn independent variable where the levels being estimated compose a random sample from a population whose variance will be estimated\n\n\nFixed effect\nAn independent variable with specific, predefined levels to estimate\n\n\nExperimental unit\nThe smallest unit being used for analysis. This could be an animal, a field plot, a person, a meat or muscle sample. The unit may be assessed multitple times or through multiple point in time. When the analysis is all said and done, the predictions occur at this level.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#packages",
    "href": "chapters/intro.html#packages",
    "title": "1¬† Introduction",
    "section": "1.2 Packages",
    "text": "1.2 Packages\n\n1.2.1 Table of required packages for modelling\n\n\n\nTable¬†1.2: Table of required packages\n\n\n\n\n\n\n\n\n\nPackage\nFunction\n\n\n\n\nlme4\nmain package for linear mixed models\n\n\nlmerTest\nfor computing p-values when using lme4\n\n\nnlme\nmain package for linear mixed models\n\n\nemmeans\nfor estimating fixed effects, their confidence intervals and conducting contrasts\n\n\nbroom.mixed\npackage for presenting the model summary output into a tidy workflow.\n\n\nDHARMa\nfor evaluating residuals (error terms) in generalized linear models\n\n\nPerformance\nFor creating diagnostic plots or to compute fit measures\n\n\n\n\n\n\n\n\n1.2.2 Optional packages\n\n\n\nTable¬†1.3: Table of optional packages\n\n\n\n\n\nPackage Name\nFunction\n\n\nhere\nFor setting work directory\n\n\nggplot\nplotting\n\n\ndesplot\nplotting\n\n\nagridat\nto download example dataset\n\n\nagricolae\nto download example dataset\n\n\n\n\n\n\nThis entire guide will use the here package for loading data. If you can load your data fine without ths package, please carry on. {here} is certainly not required for running mixed models.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/background.html",
    "href": "chapters/background.html",
    "title": "2¬† Mixed model theory and background",
    "section": "",
    "text": "2.1 Model\nRecall simple linear regression with intercept (Œ≤0) and slope (Œ≤1) effect for subject i. The (Œ≤0) and (Œ≤1) are chosen in a way so that the residual sum of squares is as small as possible.\n\\[  Y = \\beta_0 + \\beta_1(X) + ùú∫\\]\nIf we consider this model in a mixed model framework, Œ≤0 and Œ≤1 are considered fixed effects (also known as the population-averaged values) and bi is a random effect for subject i. The random effect can be thought of as each subject‚Äôs deviation from the fixed intercept parameter. The key assumption about bi is that it is independent, identically and normally distributed with a mean of zero and associated variance. Random effects are especially useful when we have (1) lots of levels (e.g., many species or blocks), (2) relatively little data on each level (although we need multiple samples from most of the levels), and (3) uneven sampling across levels.\nFor example, if we let the intercept be a random effect, it takes the form:\n\\[  Y = \\beta_0 + b_i + \\beta_1(X) + ùú∫\\]\nIn this model, predictions would vary depending on each subject‚Äôs random intercept term, but slopes would be the same:\nIn second case, we can have a fixed intercept and a random slope. The model will be:\n\\[  Y = \\beta_0 + (\\beta_1 + b_i)(X) + ùú∫\\]\nIn this model, the bi is a random effect for subject i applied to the slope. Predictions would vary with random slope term, but the intercept will be the same:\nThird case would be the mixed model with random slope and intercept:\n\\[  Y = (\\beta_0 + ai) + (\\beta_1 + b_i)(X) + ùú∫\\]\nIn this model, ai and bi are random effects for subject i applied to the intercept and slope, respectively. Predictions would vary depending on each subject‚Äôs slope and intercept terms:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#model",
    "href": "chapters/background.html#model",
    "title": "2¬† Mixed model theory and background",
    "section": "",
    "text": "Example mixed model with random intercepts but identical slopes.\n\n\n\n\n\n\n\n\nMixed model with random slopes but identical intercepts.\n\n\n\n\n\n\n\n\nMixed Model with random intercept and slope",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#random-effect-syntax",
    "href": "chapters/background.html#random-effect-syntax",
    "title": "2¬† Mixed model theory and background",
    "section": "2.2 Random-effect syntax",
    "text": "2.2 Random-effect syntax\n\n(1| group): Random intercept with fixed mean.\n(1| g1/g2): intercepts vary among g1 and g2 within g1.\n(1 | g1) + (1 | g2): random intercepts for 2 variables.\nx + (x | g): correlated random slope and intercept.\nx + (x || g): uncorrelated random slope and intercept.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Mixed model theory and background</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html",
    "href": "chapters/rcbd.html",
    "title": "3¬† Randomized Complete Block Design",
    "section": "",
    "text": "3.1 Background\nThe statistical model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\] Where:\n\\(\\mu\\) = overall experimental mean \\(\\alpha\\) = treatment effects (fixed) \\(\\beta\\) = block effects (random) \\(\\epsilon\\) = error terms\n\\[ \\epsilon \\sim N(0, \\sigma)\\]\n\\[ \\beta \\sim N(0, \\sigma_b)\\]\nBoth the overall error and the block effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(sigma_B\\), respectively.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html#background",
    "href": "chapters/rcbd.html#background",
    "title": "3¬† Randomized Complete Block Design",
    "section": "",
    "text": "‚Äòiid‚Äô assumption for error terms\n\n\n\nIn this model, the error terms, \\(\\epsilon\\) are assumed to be ‚Äúiid‚Äù, that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\nThis guide will later address examples when this assumption is violated and how to handle it.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/rcbd.html#example-analysis",
    "href": "chapters/rcbd.html#example-analysis",
    "title": "3¬† Randomized Complete Block Design",
    "section": "3.2 Example Analysis",
    "text": "3.2 Example Analysis\nFirst, load the libraries for analysis and estimation:\n\nlme4tidymodels\n\n\n\nlibrary(lme4); library(lmerTest); library(emmeans)\nlibrary(dplyr)\n\n\n\n\nlibrary(dplyr)\nlibrary(multilevelmod); library(broom)\n\n\n\n\nNext, let‚Äôs load some data. It is located here if you want to download it yourself (recommended).\nThis data set is for a single wheat variety trial conducted in Aberdeen, Idaho in 2015. The trial includes 4 blocks and 42 different treatments (wheat varieties in this case). This experiment consists of a series of plots (the experimental unit) laid out in a rectangular grid in a farm field. The goal of this analysis is the estimate the yield and test weight of each variety and the determine the rankings of each variety with regard to yield.\n\nvar_trial &lt;- read.csv(here::here(\"data\", \"aberdeen2015.csv\"))\n\n\nTable of variables in the data set\n\n\n\n\n\n\nblock\nblocking unit\n\n\nrange\ncolumn position for each plot\n\n\nrow\nrow position for each plot\n\n\nvariety\ncrop variety (the treatment) being evaluated\n\n\nstand_pct\npercentage of the plot with actual plants growing in them\n\n\ndays_to_heading_julian\nJulian days (starting January 1st) until plot ‚Äúheaded‚Äù (first spike emerged)\n\n\nlodging\npercentage of plants in the plot that fell down and hence could not be harvested\n\n\nyield_bu_a\nyield (bushels per acre)\n\n\n\nThere are several variables present that are not useful for this analysis. The only thing we are concerned about is block, variety, yield_bu_a, and test_weight.\n\n3.2.1 Data integrity checks\nThe first thing is to make sure the data is what we expect. There are two steps:\n\nmake sure data are the expected data type\ncheck the extent of missing data\ninspect the independent variables and make sure the expected levels are present in the data\ninspect the dependent variable to ensure its distribution is following expectations\n\n\nstr(var_trial)\n\n'data.frame':   168 obs. of  10 variables:\n $ block                 : int  4 4 4 4 4 4 4 4 4 4 ...\n $ range                 : int  1 1 1 1 1 1 1 1 1 1 ...\n $ row                   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ variety               : chr  \"DAS004\" \"Kaseberg\" \"Bruneau\" \"OR2090473\" ...\n $ stand_pct             : int  100 98 96 100 98 100 100 100 99 100 ...\n $ days_to_heading_julian: int  149 146 149 146 146 151 145 145 146 146 ...\n $ height                : int  39 35 33 31 33 44 30 36 36 29 ...\n $ lodging               : int  0 0 0 0 0 0 0 0 0 0 ...\n $ yield_bu_a            : num  128 130 119 115 141 ...\n $ test_weight           : num  56.4 55 55.3 54.1 54.1 56.4 54.7 57.5 56.1 53.8 ...\n\n\nThese look okay except for block, which is currently coded as integer (numeric). We don‚Äôt want run a regression of block, where block 1 has twice the effect of block 2, and so on. So, converting it to a character will fix that. It can also be converted to a factor, but I find character easier to work with, and ultimately, equivalent to factor conversion\n\nvar_trial$block &lt;- as.character(var_trial$block)\n\nNext, check the independent variables. Running a cross tabulations is often sufficient to ascertain this.\n\ntable(var_trial$variety, var_trial$block)\n\n                        \n                         1 2 3 4\n  06-03303B              1 1 1 1\n  Bobtail                1 1 1 1\n  Brundage               1 1 1 1\n  Bruneau                1 1 1 1\n  DAS003                 1 1 1 1\n  DAS004                 1 1 1 1\n  Eltan                  1 1 1 1\n  IDN-01-10704A          1 1 1 1\n  IDN-02-29001A          1 1 1 1\n  IDO1004                1 1 1 1\n  IDO1005                1 1 1 1\n  Jasper                 1 1 1 1\n  Kaseberg               1 1 1 1\n  LCS Artdeco            1 1 1 1\n  LCS Biancor            1 1 1 1\n  LCS Drive              1 1 1 1\n  LOR-833                1 1 1 1\n  LOR-913                1 1 1 1\n  LOR-978                1 1 1 1\n  Madsen                 1 1 1 1\n  Madsen / Eltan (50/50) 1 1 1 1\n  Mary                   1 1 1 1\n  Norwest Duet           1 1 1 1\n  Norwest Tandem         1 1 1 1\n  OR2080637              1 1 1 1\n  OR2080641              1 1 1 1\n  OR2090473              1 1 1 1\n  OR2100940              1 1 1 1\n  Rosalyn                1 1 1 1\n  Stephens               1 1 1 1\n  SY  Ovation            1 1 1 1\n  SY 107                 1 1 1 1\n  SY Assure              1 1 1 1\n  UI Castle CLP          1 1 1 1\n  UI Magic CLP           1 1 1 1\n  UI Palouse             1 1 1 1\n  UI Sparrow             1 1 1 1\n  UI-WSU Huffman         1 1 1 1\n  WB 456                 1 1 1 1\n  WB 528                 1 1 1 1\n  WB1376 CLP             1 1 1 1\n  WB1529                 1 1 1 1\n\n\nThere are 42 varieties and there appears to be no misspellings among them that might confuse R into thinking varieties are different when they are actually the same. R is sensitive to case and white space, which can make it easy to create near duplicate treatments, such as ‚Äúeltan‚Äù and ‚ÄúEltan‚Äù and ‚ÄúEltan‚Äù. There is no evidence of that in this data set. Additionally, it is perfectly balanced, with exactly one observation per treatment per rep. Please note that this does not tell us anything about the extent of missing data.\nHere is a quick check I run to count the number of missing data in each column.\n\napply(var_trial, 2, function(x) sum(is.na(x)))\n\n                 block                  range                    row \n                     0                      0                      0 \n               variety              stand_pct days_to_heading_julian \n                     0                      0                      0 \n                height                lodging             yield_bu_a \n                     0                      0                      0 \n           test_weight \n                     0 \n\n\nAlas, no missing data!\nIf there were independent variables with a continuous distribution (a covariate), I would plot those data.\nLast, check the dependent variable. A histogram is often quite sufficient to accomplish this. This is designed to be a quick check, so no need to spend time making the plot look good.\n\nhist(var_trial$yield_bu_a, main = \"\", xlab = \"yield\")\n\n\n\n\n\n\n\n\nFigure¬†3.1: Histogram of the dependent variable.\n\n\n\n\nThe range is roughly falling into the range we expect. I know this from talking with the person who generated the data, not through my own intuition. I do not see any large spikes of points at a single value (indicating something odd), nor do I see any extreme values (low or high) that might indicate some larger problems.\nData are not expected to be normally distributed at this point, so don‚Äôt bother running any Shapiro-Wilk tests. This histogram is a check to ensure the the data are entered correctly and they appear valid. It requires a mixture of domain knowledge and statistical training to know this, but over time, if you look at these plots with regularity, you will gain a feel for what your data should look like at this stage.\nThese are not complicated checks. They are designed to be done quickly and should be done for every analysis if you not previously already inspected the data as thus. I do this before every analysis and often discover surprising things! Best to discover these things early, since they are likely to impact the final analysis.\nThis data set is ready for analysis!\n\n\n3.2.2 Model Building\n\n\nRecall the model:\n\\[y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\\]\nFor this model, \\(\\alpha_i\\) is the variety effect (fixed) and \\(\\beta_j\\) is the block effect (random).\nHere is the R syntax for the RCBD statistical model:\n\nlme4tidymodels\n\n\n\nmodel_rcbd &lt;- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\n\n\n\n\ntidy_rcbd &lt;- linear_reg() %&gt;% \n  set_engine(\"lmer\") %&gt;%\n  fit(yield_bu_a ~ variety + (1|block), data = var_trial, na.action = na.exclude)\n\n\n\n\nThe parentheses are used to indicate that ‚Äòblock‚Äô is a random effect, and this particular notation (1|block) indicates that a ‚Äòrandom intercept‚Äô model is being fit. This is the most common approach. It means there is one overall effect fit for each block. I use the argument na.action = na.exclude as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.\n\n\n\n\n\n\nFormula notation\n\n\n\nFormula notation is often used in the R syntax for linear models. It looks like this: \\(Y ~ X\\), where Y is the dependent variable (the response) and X is/are the independent variable(s) (e.g.¬†the experimental treatments).\n\nmy_formula &lt;- formula(Y ~ treatment1 + treatment2)\nclass(my_formula)\n\n[1] \"formula\"\n\n\nThe package ‚Äòlmer‚Äô has some additional conventions regarding the formula. Random effects are put in parentheses and a 1| is used to denote random intercepts (rather than random slopes).\n\n\n\n\n3.2.3 Check Model Assumptions\nRemember those iid assumptions? Let‚Äôs make sure we actually met them.\nThere is a special plotting function written for lme4 objects for checking the homoscedasticity (constant variance):\n\nplot(model_rcbd)\n\n\n\n\n\n\n\n\nFigure¬†3.2: Plot of residuals versus fitted values\n\n\n\n\nWe are looking for a random and uniform distribution of points. This looks good!\nChecking normality requiring first extracting the model residuals with resid() and then generaing a qq-plot and line.\n\nqqnorm(resid(model_rcbd)); qqline(resid(model_rcbd))\n\n\n\n\n\n\n\n\nFigure¬†3.3: QQ-plot of residuals\n\n\n\n\nThis is reasonably good. Things do tend to fall apart at the tails.\n\n\n3.2.4 Inference\nEstimates for each treatment level can be obtained with the ‚Äòemmeans‚Äô package.\n\nrcbd_emm &lt;- emmeans(model_rcbd, ~ variety)\nas.data.frame(rcbd_emm) %&gt;% arrange(desc(emmean))\n\n variety                  emmean       SE    df  lower.CL upper.CL\n Rosalyn                155.2703 7.212203 77.85 140.91149 169.6292\n IDO1005                153.5919 7.212203 77.85 139.23310 167.9508\n OR2080641              152.6942 7.212203 77.85 138.33536 167.0530\n Bobtail                151.6403 7.212203 77.85 137.28149 165.9992\n UI Sparrow             151.6013 7.212203 77.85 137.24245 165.9601\n Kaseberg               150.9768 7.212203 77.85 136.61794 165.3356\n IDN-01-10704A          148.9861 7.212203 77.85 134.62729 163.3450\n 06-03303B              148.8300 7.212203 77.85 134.47116 163.1888\n WB1529                 148.2445 7.212203 77.85 133.88568 162.6034\n DAS003                 145.2000 7.212203 77.85 130.84116 159.5588\n IDN-02-29001A          144.5755 7.212203 77.85 130.21665 158.9343\n Bruneau                143.9900 7.212203 77.85 129.63116 158.3488\n SY 107                 143.6387 7.212203 77.85 129.27987 157.9975\n WB 528                 142.9752 7.212203 77.85 128.61633 157.3340\n OR2080637              141.7652 7.212203 77.85 127.40633 156.1240\n Jasper                 141.2968 7.212203 77.85 126.93794 155.6556\n UI Magic CLP           139.5403 7.212203 77.85 125.18149 153.8992\n Madsen                 139.2671 7.212203 77.85 124.90826 153.6259\n LCS Biancor            139.1110 7.212203 77.85 124.75213 153.4698\n SY  Ovation            138.6426 7.212203 77.85 124.28375 153.0014\n OR2090473              137.8229 7.212203 77.85 123.46407 152.1817\n Madsen / Eltan (50/50) 136.9642 7.212203 77.85 122.60536 151.3230\n UI-WSU Huffman         135.4810 7.212203 77.85 121.12213 149.8398\n Mary                   134.8564 7.212203 77.85 120.49762 149.2153\n Norwest Tandem         134.3490 7.212203 77.85 119.99020 148.7079\n Brundage               134.0758 7.212203 77.85 119.71697 148.4346\n IDO1004                132.5145 7.212203 77.85 118.15568 146.8733\n DAS004                 132.2413 7.212203 77.85 117.88245 146.6001\n Norwest Duet           132.0852 7.212203 77.85 117.72633 146.4440\n Eltan                  131.4606 7.212203 77.85 117.10181 145.8195\n LCS Artdeco            130.8361 7.212203 77.85 116.47729 145.1950\n UI Palouse             130.4848 7.212203 77.85 116.12600 144.8437\n LOR-978                130.4458 7.212203 77.85 116.08697 144.8046\n LCS Drive              128.7674 7.212203 77.85 114.40858 143.1262\n Stephens               127.1671 7.212203 77.85 112.80826 141.5259\n OR2100940              126.1523 7.212203 77.85 111.79342 140.5111\n UI Castle CLP          125.5277 7.212203 77.85 111.16891 139.8866\n WB1376 CLP             123.6932 7.212203 77.85 109.33439 138.0521\n LOR-833                122.7565 7.212203 77.85 108.39762 137.1153\n LOR-913                118.7752 7.212203 77.85 104.41633 133.1340\n WB 456                 118.4629 7.212203 77.85 104.10407 132.8217\n SY Assure              111.0468 7.212203 77.85  96.68794 125.4056\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\nThis table indicates the estimated marginal means (‚Äúemmean‚Äù, sometimes called ‚Äúleast squares means‚Äù), the standard error (‚ÄúSE‚Äù) of those means, the degrees of freedom and the upper and lower bounds of the 95% confidence interval. As an additional step, the emmeans were sorted from largest to smallest.\nAt this point, the analysis goals have been met: we know the estimated means for each treatment and their rankings.\n\n\n3.2.5 Flotsam & Jetsam\nSometimes, researchers want to conduct an ANOVA or add the letters for indicating differences among treatments, even though we have reached the original goals of analysis. It is important to evaluate why you want to do these extra things, what extra information it will bring and what you plan to do with those results.\nRunning an ANOVA may increase or decrease confidence in the results, depending on what results. That is not at all what ANOVA is intended to do, nor is this what p-values can tell us!\nLabelling each treatment, especially when there are this many (42 in total), has its own perils. The biggest problem is that this creates a multiple testing problem: with 42 treatments, a total of 861 comparison are being run (=\\(42*(42-1)/2\\)), and then adjusted for multiple tests. With that many tests, a severe adjustment is likely and hence things that are different are not detected. With so many tests, it could be that there is an overall effect due to variety, but they all share the same letter!\nThe second problem is one of interpretation. Just because two treatments or varieties share a letter does not mean they are equivalent. It only means that they were not found to be different. A funny distinction, but alas. There is an entire branch of statistics, ‚Äòequivalence testing‚Äô devoted to just this topic - how to test if two things are actually the same. This involves the user declaring a maximum allowable numeric difference for a variable in order to determine if two items are statistically different or equivalent - something that these pairwise comparisons are not doing.\nIf you want to run ANOVA, it can be done quite easily:\n\nanova(model_rcbd)\n\nType III Analysis of Variance Table with Satterthwaite's method\n        Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nvariety  18354  447.65    41   123  2.4528 8.017e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBut, please be thoughtful in your usage of it.\n\n\n\n\n\n\nna.action = na.exclude\n\n\n\nYou may have noticed the final argument for na.action in the model statement:\nmodel_rcbd &lt;- lmer(yield_bu_a ~ variety + (1|block),\n                   data = var_trial, \n                   na.action = na.exclude)\nI use the argument na.action = na.exclude as instruction for how to handle missing data: conduct the analysis, adjusting as needed for the missing data, and when prediction or residuals are output, please pad them in the appropriate places for missing data so they can be easily merged into the main data set if need be.\nSince there are no missing data, this step was not strictly necessary, but it‚Äôs a good habit to be in.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Randomized Complete Block Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html",
    "href": "chapters/factorial-design.html",
    "title": "4¬† Factorial Design",
    "section": "",
    "text": "4.1 Background\nadd description of factorial design",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html#background",
    "href": "chapters/factorial-design.html#background",
    "title": "4¬† Factorial Design",
    "section": "",
    "text": "A note",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html#example-analysis",
    "href": "chapters/factorial-design.html#example-analysis",
    "title": "4¬† Factorial Design",
    "section": "4.2 Example Analysis",
    "text": "4.2 Example Analysis\n\nlibrary(dplyr) \nlibrary(nlme)\nlibrary(mmrm)\nlibrary(emmeans)\nlibrary(performance)\nlibrary(lme4); library(lmerTest)\n\n\nA 4x4 Factorial design\n\nThe response variable: yield\nA data frame with 32 observations on the following 4 variables.\n\nrep: replication factor\nblock: block factor\ntrt: treatment factor, 16 levels\n\nThere were 4 treatment factors: d (dung treatment, 2 levels), n (nitrogen treatment, 2 levels), p (phosphorous treatment, 2 levels), and k (potassium treatment, 2 levels)\n\nlibrary(agridat)\n\ndata1 &lt;- agridat::cochran.factorial %&gt;% mutate(d = as.factor(d),\n         n = as.factor(n),\n         p = as.factor(p),\n         k = as.factor(k))\nstr(data1)\n\n'data.frame':   32 obs. of  8 variables:\n $ rep  : Factor w/ 2 levels \"R1\",\"R2\": 1 1 1 1 1 1 1 1 1 1 ...\n $ block: Factor w/ 2 levels \"B1\",\"B2\": 1 1 1 1 1 1 1 1 2 2 ...\n $ trt  : Factor w/ 16 levels \"(1)\",\"d\",\"dk\",..: 15 10 2 14 5 6 9 11 8 12 ...\n $ yield: int  45 55 53 36 41 48 55 42 50 44 ...\n $ d    : Factor w/ 2 levels \"0\",\"1\": 2 2 1 2 1 1 1 2 1 2 ...\n $ n    : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 1 1 2 1 2 1 ...\n $ p    : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 2 1 1 2 1 2 ...\n $ k    : Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 1 2 1 2 2 1 ...",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/factorial-design.html#model-fitting",
    "href": "chapters/factorial-design.html#model-fitting",
    "title": "4¬† Factorial Design",
    "section": "4.3 Model fitting",
    "text": "4.3 Model fitting\nModel fitting with R is exactly the same as shown in previous chapters: we need to include all effect, as well as the interaction, which is represented by using the colon indicator ‚Äò:‚Äô. Therefore, model syntax is:\nyield ~ d + n + p + k + d:n + d:p + d:k + n:p + n:k + p:k + d:n:p:k\nwhich can be abbreviated as:\nyield ~ d*n*p*k\n\nmodel1 &lt;- lmer(yield ~ d*n*p*k + (1|block),\n                   data = data1, \n                   na.action = na.exclude)\n\nWarning in as_lmerModLT(model, devfun): Model may not have converged with 1\neigenvalue close to zero: 4.0e-09\n\nsummary(model1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: yield ~ d * n * p * k + (1 | block)\n   Data: data1\n\nREML criterion at convergence: 107.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.1169 -0.5331  0.0000  0.5331  1.1169 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n block    (Intercept)  1.579   1.257   \n Residual             24.250   4.924   \nNumber of obs: 32, groups:  block, 2\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   49.000      3.702  16.000  13.236 4.91e-10 ***\nd1            -9.500      5.235  16.000  -1.815   0.0884 .  \nn1             0.500      5.235  16.000   0.096   0.9251    \np1           -11.500      5.235  16.000  -2.197   0.0431 *  \nk1             1.000      5.235  16.000   0.191   0.8509    \nd1:n1         13.500      7.819  16.000   1.727   0.1035    \nd1:p1         15.500      7.819  16.000   1.982   0.0649 .  \nn1:p1          9.500      7.819  16.000   1.215   0.2420    \nd1:k1          4.000      7.819  16.000   0.512   0.6159    \nn1:k1          0.500      7.819  16.000   0.064   0.9498    \np1:k1          3.000      7.819  16.000   0.384   0.7063    \nd1:n1:p1     -14.500     12.146  16.000  -1.194   0.2500    \nd1:n1:k1     -17.000     12.146  16.000  -1.400   0.1807    \nd1:p1:k1      -7.000     12.146  16.000  -0.576   0.5724    \nn1:p1:k1      -4.500     12.146  16.000  -0.370   0.7159    \nd1:n1:p1:k1   25.000     19.903  16.000   1.256   0.2271    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 16 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\n\n\n\n\n\n\nModel fit using lme()\n\n\n\nThis same model can be fitted by using lme() from the ‚Äònlme‚Äô package as well.\n\nmodel2 &lt;- lme(yield ~ d*n*p*k,\n              random = ~1|block,\n                   data = data1, \n                   na.action = na.exclude)\n\nmodel2 \n\nLinear mixed-effects model fit by REML\n  Data: data1 \n  Log-restricted-likelihood: -53.75553\n  Fixed: yield ~ d * n * p * k \n(Intercept)          d1          n1          p1          k1       d1:n1 \n       49.0        -9.5         0.5       -11.5         1.0        13.5 \n      d1:p1       n1:p1       d1:k1       n1:k1       p1:k1    d1:n1:p1 \n       15.5         9.5         4.0         0.5         3.0       -14.5 \n   d1:n1:k1    d1:p1:k1    n1:p1:k1 d1:n1:p1:k1 \n      -17.0        -7.0        -4.5        25.0 \n\nRandom effects:\n Formula: ~1 | block\n        (Intercept) Residual\nStdDev:    3.282953 4.924429\n\nNumber of Observations: 32\nNumber of Groups: 2 \n\nanova(model2)\n\n            numDF denDF  F-value p-value\n(Intercept)     1    15 358.4246  &lt;.0001\nd               1    15   0.0825  0.7779\nn               1    15  13.4072  0.0023\np               1    15   0.2526  0.6226\nk               1    15   0.1856  0.6728\nd:n             1    15   1.3196  0.2687\nd:p             1    15   9.9794  0.0065\nn:p             1    15   3.2216  0.0928\nd:k             1    15   0.2526  0.6226\nn:k             1    15   1.3196  0.2687\np:k             1    15   1.0103  0.3308\nd:n:p           1    15   0.0825  0.7779\nd:n:k           1    15   0.4175  0.5279\nd:p:k           1    15   0.6237  0.4420\nn:p:k           1    15   1.3196  0.2687\nd:n:p:k         1    15   0.3972  0.5380\n\n\nThe results are same from both models with lmer() or lme().\n\n\n\nanova(model1)\n\nType III Analysis of Variance Table with Satterthwaite's method\n        Sum Sq Mean Sq NumDF DenDF F value   Pr(&gt;F)   \nd         2.00    2.00     1    16  0.0825 0.777658   \nn       325.12  325.12     1    16 13.4072 0.002107 **\np         6.12    6.12     1    16  0.2526 0.622113   \nk         4.50    4.50     1    16  0.1856 0.672379   \nd:n      32.00   32.00     1    16  1.3196 0.267550   \nd:p     242.00  242.00     1    16  9.9794 0.006079 **\nn:p      78.12   78.12     1    16  3.2216 0.091583 . \nd:k       6.12    6.12     1    16  0.2526 0.622113   \nn:k      32.00   32.00     1    16  1.3196 0.267550   \np:k      24.50   24.50     1    16  1.0103 0.329789   \nd:n:p     2.00    2.00     1    16  0.0825 0.777658   \nd:n:k    10.13   10.13     1    16  0.4175 0.527334   \nd:p:k    15.13   15.13     1    16  0.6237 0.441219   \nn:p:k    32.00   32.00     1    16  1.3196 0.267550   \nd:n:p:k  38.26   38.26     1    16  1.5778 0.227113   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n4.3.1 Check Model Assumptions\nthe residuals seem to fit the assumption required for normality.\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n4.3.2 Inference\n\nm1 &lt;- emmeans(model1, specs = ~ d|k)\n\nNOTE: Results may be misleading due to involvement in interactions\n\nm1\n\nk = 0:\n d emmean   SE   df lower.CL upper.CL\n 0   45.9 1.95 25.4     41.9     49.9\n 1   47.2 1.95 25.4     43.2     51.3\n\nk = 1:\n d emmean   SE   df lower.CL upper.CL\n 0   47.5 1.95 25.4     43.5     51.5\n 1   47.1 1.95 25.4     43.1     51.1\n\nResults are averaged over the levels of: n, p \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\npairs(m1)\n\nk = 0:\n contrast estimate   SE df t.ratio p.value\n d0 - d1    -1.375 2.46 16  -0.558  0.5843\n\nk = 1:\n contrast estimate   SE df t.ratio p.value\n d0 - d1     0.375 2.46 16   0.152  0.8809\n\nResults are averaged over the levels of: n, p \nDegrees-of-freedom method: kenward-roger \n\n\n\nm2 &lt;- emmeans(model1, specs = ~ n)\n\nNOTE: Results may be misleading due to involvement in interactions\n\nm2\n\n n emmean   SE df lower.CL upper.CL\n 0   43.8 1.52 37     40.7     46.8\n 1   50.1 1.52 37     47.0     53.2\n\nResults are averaged over the levels of: d, p, k \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\npairs(m2)\n\n contrast estimate   SE df t.ratio p.value\n n0 - n1     -6.38 1.74 16  -3.662  0.0021\n\nResults are averaged over the levels of: d, p, k \nDegrees-of-freedom method: kenward-roger \n\n\n\nlme4tidymodels\n\n\n\n\n\n\nlibrary(tidymodels)\ntidy_rcbd &lt;- linear_reg(engine = \"lm\") %&gt;% \n  fit(yield ~ d*n*p*k + (1|block),\n                   data = data1, \n                   na.action = na.exclude)\n\n\n\n\n\nUnbalanced factorial design\n\n\n\n4.3.3 Data integrity checks\n\n\n4.3.4 Model Building\n\n\nRecall the model:\n\\[        \\]\nHere is the R syntax for that statistical model:\n\nlme4tidymodels\n\n\n\n\n\n\n\n\n\n\n\n4.3.5 Flotsam & Jetsam",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Factorial Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html",
    "href": "chapters/split-plot-design.html",
    "title": "5¬† Split Plot Design",
    "section": "",
    "text": "5.1 Details for Split Plot Designs\nThe statistical model structure this design:\n\\[y_{ijk} = \\mu + \\alpha_i + \\beta_k + (\\alpha_j\\beta_k) + \\epsilon_{ij} + \\delta_{ijk} \\] Where:\n\\(\\mu\\)= overall experimental mean, \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\tau\\) = interaction between factors A and B, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\\[ \\epsilon \\sim N(0, \\sigma_\\epsilon)\\]\n\\[\\ \\delta  \\sim N(0, \\sigma_\\delta)\\]\nBoth the error and the rep effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma_\\epsilon\\) and \\(\\sigma_\\delta\\), respectively.\nThis is also referred as ‚ÄúSplit-Block RCB‚Äù design. The statistical model structure for split plot design:\n\\[y_{ijk} = \\mu + \\rho_j +  \\alpha_i + \\beta_k + (\\alpha_i\\beta_k) + \\epsilon_{ij} + \\delta_{ijk}\\] Where:\n\\(\\mu\\) = overall experimental mean, \\(\\rho\\) = block effect (random), \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\beta\\) = interaction between factors A and B, \\(\\epsilon_{ij}\\) = whole plot error, \\(\\delta_{ijk}\\) = subplot error.\n\\[ \\epsilon \\sim N(0, \\sigma_\\epsilon)\\]\n\\[\\ \\delta  \\sim N(0, \\sigma_\\delta)\\]\nBoth the overall error and the rep effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(\\sigma_\\delta\\), respectively.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html#details-for-split-plot-designs",
    "href": "chapters/split-plot-design.html#details-for-split-plot-designs",
    "title": "5¬† Split Plot Design",
    "section": "",
    "text": "Whole Plot Randomized as a completely randomized design\n\n\n\n\n\n\n\n\nWhole Plot Randomized as an RCBD\n\n\n\n\n\n\n\n\n5.1.0.1 ‚Äòiid‚Äô assumption for error terms\nIn these model, the error terms, \\(\\epsilon\\) are assumed to be ‚Äúiid‚Äù, that is, independently and identically distributed. This means they have constant variance and they each individual error term is independent from the others.\n\n\n\nSplit Plot CRD Design\n\n\n\n\n\nSplit Plot RCBD Design\n\n\n\n\n5.1.1 Analysis Examples\n\n\n5.1.2 Example model for CRD Split Plot Designs\nheight_data used for this example has a split plot design as follows: 3 replicates, in each rep there are four plots (whole-plot) representing time; Besides, the whole-plot is divided into 8 sub-plots to apply different management (manage) levels.\n\nLoad required libraries\n\n\nlibrary(ggplot2)\nlibrary(emmeans)\nlibrary(lme4)\nlibrary(multcompView)\nlibrary(performance)\n\n\nImport height data and check the structure of the data.\n\n\nlibrary(readxl)\nheight_data &lt;- read_excel(here::here(\"data\", \"height_data.xlsx\"))\n\ntable(height_data$time, height_data$manage)\n\n    \n     M1 M2 M3 M4 M5 M6 M7 M8\n  T1  6  6  6  6  6  6  6  6\n  T2  6  6  6  6  6  6  6  6\n  T3  6  6  6  6  6  6  6  6\n  T4  6  6  6  6  6  6  6  6\n\nstr(height_data)\n\ntibble [192 √ó 5] (S3: tbl_df/tbl/data.frame)\n $ time  : chr [1:192] \"T1\" \"T1\" \"T1\" \"T1\" ...\n $ manage: chr [1:192] \"M1\" \"M2\" \"M3\" \"M4\" ...\n $ rep   : chr [1:192] \"R1\" \"R1\" \"R1\" \"R1\" ...\n $ sample: chr [1:192] \"S1\" \"S1\" \"S1\" \"S1\" ...\n $ height: num [1:192] 104.5 92.3 96.8 94.7 105.7 ...\n\n\n\nExplore data\n\n\nggplot(data = height_data, aes(y = height, x = time)) +\n  geom_boxplot(aes(colour = manage))\n\n\n\n\n\n\n\n\n\nlibrary(agridat)\ndata(gomez.splitplot.subsample.txt)\n\nWarning in data(gomez.splitplot.subsample.txt): data set\n'gomez.splitplot.subsample.txt' not found\n\n\n\nSpecify a model for data\n\nThe statistical model structure for split plot design:\n\\[y_{ijk} = \\mu + \\gamma_i +  \\alpha_j + \\beta_k + (\\alpha_j\\beta_k) + \\epsilon_{ijk}\\]\nWhere:\n\\(\\mu\\) = overall experimental mean, \\(\\gamma\\) = block/rep effect (random), \\(\\alpha\\) = main effect of whole plot (fixed), \\(\\beta\\) = main effect of subplot (fixed), \\(\\alpha\\)\\(\\beta\\) = interaction between factors A and B, \\(\\epsilon\\) = error.\n\\[ \\epsilon \\sim N(0, \\sigma)\\]\n\\[ \\gamma \\sim N(0, \\sigma_b)\\]\nBoth the overall error and the rep effects are assumed to be normally distributed with a mean of zero and standard deviations of \\(\\sigma\\) and \\(sigma_B\\), respectively.\n\nmodel1&lt;-lmer(height ~ time*manage + (1|rep/time), data=height_data)\n\nsummary(model1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: height ~ time * manage + (1 | rep/time)\n   Data: height_data\n\nREML criterion at convergence: 997.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.53183 -0.60511 -0.07333  0.62458  1.97914 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n time:rep (Intercept)  0.6118  0.7822  \n rep      (Intercept) 20.1069  4.4841  \n Residual             19.5318  4.4195  \nNumber of obs: 192, groups:  time:rep, 12; rep, 3\n\nFixed effects:\n                Estimate Std. Error t value\n(Intercept)     108.0333     3.1877  33.890\ntimeT2            3.1833     2.6303   1.210\ntimeT3           -2.2500     2.6303  -0.855\ntimeT4            1.2833     2.6303   0.488\nmanageM2         -4.4500     2.5516  -1.744\nmanageM3         -5.3000     2.5516  -2.077\nmanageM4         -6.1833     2.5516  -2.423\nmanageM5         -5.0167     2.5516  -1.966\nmanageM6         -3.4167     2.5516  -1.339\nmanageM7         -9.7500     2.5516  -3.821\nmanageM8         -4.6667     2.5516  -1.829\ntimeT2:manageM2  -1.4167     3.6085  -0.393\ntimeT3:manageM2   0.4667     3.6085   0.129\ntimeT4:manageM2  -4.6667     3.6085  -1.293\ntimeT2:manageM3  -1.9667     3.6085  -0.545\ntimeT3:manageM3  -2.3500     3.6085  -0.651\ntimeT4:manageM3  -0.8667     3.6085  -0.240\ntimeT2:manageM4   3.1000     3.6085   0.859\ntimeT3:manageM4   0.9000     3.6085   0.249\ntimeT4:manageM4   7.8500     3.6085   2.175\ntimeT2:manageM5  -1.0167     3.6085  -0.282\ntimeT3:manageM5  -0.9000     3.6085  -0.249\ntimeT4:manageM5  -2.4667     3.6085  -0.684\ntimeT2:manageM6   0.5333     3.6085   0.148\ntimeT3:manageM6  -3.9333     3.6085  -1.090\ntimeT4:manageM6   1.1167     3.6085   0.309\ntimeT2:manageM7  -1.9333     3.6085  -0.536\ntimeT3:manageM7   1.0667     3.6085   0.296\ntimeT4:manageM7  -1.3833     3.6085  -0.383\ntimeT2:manageM8  -1.3167     3.6085  -0.365\ntimeT3:manageM8  -0.8167     3.6085  -0.226\ntimeT4:manageM8  -0.2000     3.6085  -0.055\n\n\n\nCorrelation matrix not shown by default, as p = 32 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\n\nplot(model1)\n\n\n\n\n\n\n\nqqnorm(resid(model1)); qqline(resid(model1))\n\n\n\n\n\n\n\n# checking model assumptions\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\nInterpretation of the model:\n\n\nanova(model1)\n\nAnalysis of Variance Table\n            npar  Sum Sq Mean Sq F value\ntime           3  546.78 182.260  9.3314\nmanage         7 1482.42 211.774 10.8425\ntime:manage   21  475.31  22.634  1.1588\n\n\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nemmeans(model1, ~ time*manage)\n\n time manage emmean   SE   df lower.CL upper.CL\n T1   M1      108.0 3.19 4.38     99.5      117\n T2   M1      111.2 3.19 4.38    102.7      120\n T3   M1      105.8 3.19 4.38     97.2      114\n T4   M1      109.3 3.19 4.38    100.8      118\n T1   M2      103.6 3.19 4.38     95.0      112\n T2   M2      105.3 3.19 4.38     96.8      114\n T3   M2      101.8 3.19 4.38     93.2      110\n T4   M2      100.2 3.19 4.38     91.6      109\n T1   M3      102.7 3.19 4.38     94.2      111\n T2   M3      104.0 3.19 4.38     95.4      113\n T3   M3       98.1 3.19 4.38     89.6      107\n T4   M3      103.2 3.19 4.38     94.6      112\n T1   M4      101.8 3.19 4.38     93.3      110\n T2   M4      108.1 3.19 4.38     99.6      117\n T3   M4      100.5 3.19 4.38     91.9      109\n T4   M4      111.0 3.19 4.38    102.4      120\n T1   M5      103.0 3.19 4.38     94.5      112\n T2   M5      105.2 3.19 4.38     96.6      114\n T3   M5       99.9 3.19 4.38     91.3      108\n T4   M5      101.8 3.19 4.38     93.3      110\n T1   M6      104.6 3.19 4.38     96.1      113\n T2   M6      108.3 3.19 4.38     99.8      117\n T3   M6       98.4 3.19 4.38     89.9      107\n T4   M6      107.0 3.19 4.38     98.5      116\n T1   M7       98.3 3.19 4.38     89.7      107\n T2   M7       99.5 3.19 4.38     91.0      108\n T3   M7       97.1 3.19 4.38     88.5      106\n T4   M7       98.2 3.19 4.38     89.6      107\n T1   M8      103.4 3.19 4.38     94.8      112\n T2   M8      105.2 3.19 4.38     96.7      114\n T3   M8      100.3 3.19 4.38     91.7      109\n T4   M8      104.5 3.19 4.38     95.9      113\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\n\n5.1.3 Example model for RCBD Split Plot Designs\nDesign Summary:\nMain plot = Variety (V), 3 levels\nSubplot = Nitrogen (N), 4 levels\nNumber of blocks (B) = 6\nDependent variable = yield (Y)\nTo fully examine the yield of oats due to varieties and nutrient levels in a split plots. We will need to statistically analyse and compare the effects of varieties, nutrient levels, their interaction, and the effects of plots and subplots.\nLoad the data:\n\nlibrary(MASS)\ndata(\"oats\")\nhead(oats,10)\n\n   B           V      N   Y\n1  I     Victory 0.0cwt 111\n2  I     Victory 0.2cwt 130\n3  I     Victory 0.4cwt 157\n4  I     Victory 0.6cwt 174\n5  I Golden.rain 0.0cwt 117\n6  I Golden.rain 0.2cwt 114\n7  I Golden.rain 0.4cwt 161\n8  I Golden.rain 0.6cwt 141\n9  I  Marvellous 0.0cwt 105\n10 I  Marvellous 0.2cwt 140\n\n\nEvaluate the structure of the data. The ‚ÄúB‚Äù, ‚ÄúV‚Äù, and ‚ÄúN‚Äù needs to be ‚Äòfactor‚Äô and ‚ÄúY‚Äù should be numeric.\n\nstr(oats)\n\n'data.frame':   72 obs. of  4 variables:\n $ B: Factor w/ 6 levels \"I\",\"II\",\"III\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ V: Factor w/ 3 levels \"Golden.rain\",..: 3 3 3 3 1 1 1 1 2 2 ...\n $ N: Factor w/ 4 levels \"0.0cwt\",\"0.2cwt\",..: 1 2 3 4 1 2 3 4 1 2 ...\n $ Y: int  111 130 157 174 117 114 161 141 105 140 ...\n\n\n\ntable(oats$V, oats$N)\n\n             \n              0.0cwt 0.2cwt 0.4cwt 0.6cwt\n  Golden.rain      6      6      6      6\n  Marvellous       6      6      6      6\n  Victory          6      6      6      6\n\n\nBuilding the Model\n\nmodel2 &lt;- lmer(Y ~ V + N + V:N + (1|B) + (1|B:V), data = oats)\nsummary(model2)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Y ~ V + N + V:N + (1 | B) + (1 | B:V)\n   Data: oats\n\nREML criterion at convergence: 529\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.81301 -0.56145  0.01758  0.63865  1.57034 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n B:V      (Intercept) 106.1    10.30   \n B        (Intercept) 214.5    14.65   \n Residual             177.1    13.31   \nNumber of obs: 72, groups:  B:V, 18; B, 6\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)          80.0000     9.1070   8.784\nVMarvellous           6.6667     9.7150   0.686\nVVictory             -8.5000     9.7150  -0.875\nN0.2cwt              18.5000     7.6829   2.408\nN0.4cwt              34.6667     7.6829   4.512\nN0.6cwt              44.8333     7.6829   5.835\nVMarvellous:N0.2cwt   3.3333    10.8653   0.307\nVVictory:N0.2cwt     -0.3333    10.8653  -0.031\nVMarvellous:N0.4cwt  -4.1667    10.8653  -0.383\nVVictory:N0.4cwt      4.6667    10.8653   0.430\nVMarvellous:N0.6cwt  -4.6667    10.8653  -0.430\nVVictory:N0.6cwt      2.1667    10.8653   0.199\n\nCorrelation of Fixed Effects:\n            (Intr) VMrvll VVctry N0.2cw N0.4cw N0.6cw VM:N0.2 VV:N0.2 VM:N0.4\nVMarvellous -0.533                                                           \nVVictory    -0.533  0.500                                                    \nN0.2cwt     -0.422  0.395  0.395                                             \nN0.4cwt     -0.422  0.395  0.395  0.500                                      \nN0.6cwt     -0.422  0.395  0.395  0.500  0.500                               \nVMrvll:N0.2  0.298 -0.559 -0.280 -0.707 -0.354 -0.354                        \nVVctry:N0.2  0.298 -0.280 -0.559 -0.707 -0.354 -0.354  0.500                 \nVMrvll:N0.4  0.298 -0.559 -0.280 -0.354 -0.707 -0.354  0.500   0.250         \nVVctry:N0.4  0.298 -0.280 -0.559 -0.354 -0.707 -0.354  0.250   0.500   0.500 \nVMrvll:N0.6  0.298 -0.559 -0.280 -0.354 -0.354 -0.707  0.500   0.250   0.500 \nVVctry:N0.6  0.298 -0.280 -0.559 -0.354 -0.354 -0.707  0.250   0.500   0.250 \n            VV:N0.4 VM:N0.6\nVMarvellous                \nVVictory                   \nN0.2cwt                    \nN0.4cwt                    \nN0.6cwt                    \nVMrvll:N0.2                \nVVctry:N0.2                \nVMrvll:N0.4                \nVVctry:N0.4                \nVMrvll:N0.6  0.250         \nVVctry:N0.6  0.500   0.500 \n\n## use broom.mixed here instead of summary\n\nAssumption tests\nNormality of residuals and homogenous variance\n\n# checking model assumptions\ncheck_model(model2)\n\n\n\n\n\n\n\n\nAnalysis of Variance (ANOVA)\n\nanova(model2)\n\nAnalysis of Variance Table\n    npar  Sum Sq Mean Sq F value\nV      2   526.1   263.0  1.4853\nN      3 20020.5  6673.5 37.6857\nV:N    6   321.7    53.6  0.3028\n\n\nPost-Hoc analysis\n\nemm &lt;- emmeans(model2, ~ V *N) \nomparison &lt;- cld(emm, Letters = LETTERS, reversed = T)\n\n\n\n\n\n\n\nna.action = na.exclude\n\n\n\nThe RCBD split-plot design is also commonly called split-block Design or the strip-plot Design",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/split-plot-design.html#split-split-plot-design-in-r",
    "href": "chapters/split-plot-design.html#split-split-plot-design-in-r",
    "title": "5¬† Split Plot Design",
    "section": "5.2 Split-split plot design in R",
    "text": "5.2 Split-split plot design in R\nIn this example, we have a yield data of 3 different rice varieties grown under 3 management practices and 5 Nitrogen levels. In this split-split design:\nblocks = block (3 blocks),\nWhole plot factor = Nitrogen (5 levels)\nSub plot = management (3 levels)\nsub-subplot = variety (3 levels)\nStatistical model:\nadd model equation here\nHere, we are extracting the rice yield data from agricolae package.\n\nlibrary(agricolae)\nf &lt;- system.file(\"external/ssp.csv\", package=\"agricolae\")\nrice &lt;-read.csv(f)\n\nExploratory analysis\n\nstr(rice)\n\n'data.frame':   135 obs. of  5 variables:\n $ block     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ nitrogen  : int  0 0 0 50 50 50 80 80 80 110 ...\n $ management: chr  \"m1\" \"m2\" \"m3\" \"m1\" ...\n $ variety   : int  1 1 1 1 1 1 1 1 1 1 ...\n $ yield     : num  3.32 3.77 4.66 3.19 3.62 ...\n\n\nConvert block, nitrogen, variety, and management to factors.\n\nrice$block&lt;-factor(rice$block)\nrice$nitrogen&lt;-factor(rice$nitrogen)\nrice$management&lt;-factor(rice$management)\nrice$variety&lt;-factor(rice$variety)\n\nStatistical model:\nHere is the basic split-split plot analysis. We can use the nesting notation in the random part because nitrogen and management are nested in blocks. We can do blocks as fixed or random.\n\nmodel3 &lt;-lmer(yield ~  block + nitrogen*management*variety + (1|block/nitrogen/management),data=rice, na.action = na.exclude)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(model3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nyield ~ block + nitrogen * management * variety + (1 | block/nitrogen/management)\n   Data: rice\n\nREML criterion at convergence: 234.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.61416 -0.54059 -0.04774  0.58135  2.01690 \n\nRandom effects:\n Groups                      Name        Variance Std.Dev.\n management:(nitrogen:block) (Intercept) 0.000000 0.00000 \n nitrogen:block              (Intercept) 0.013257 0.11514 \n block                       (Intercept) 0.001708 0.04132 \n Residual                                0.437110 0.66114 \nNumber of obs: 135, groups:  \nmanagement:(nitrogen:block), 45; nitrogen:block, 15; block, 3\n\nFixed effects:\n                                   Estimate Std. Error t value\n(Intercept)                        3.877430   0.400091   9.691\nblock2                             0.117933   0.167765   0.703\nblock3                            -0.059222   0.167765  -0.353\nnitrogen50                         0.335000   0.547946   0.611\nnitrogen80                         1.329000   0.547946   2.425\nnitrogen110                        0.753333   0.547946   1.375\nnitrogen140                        0.164667   0.547946   0.301\nmanagementm2                       0.420333   0.539821   0.779\nmanagementm3                       1.428000   0.539821   2.645\nvariety2                           1.449000   0.539821   2.684\nvariety3                           1.481333   0.539821   2.744\nnitrogen50:managementm2           -0.076000   0.763422  -0.100\nnitrogen80:managementm2            0.086000   0.763422   0.113\nnitrogen110:managementm2           0.376667   0.763422   0.493\nnitrogen140:managementm2           0.718000   0.763422   0.941\nnitrogen50:managementm3           -0.177333   0.763422  -0.232\nnitrogen80:managementm3           -0.107667   0.763422  -0.141\nnitrogen110:managementm3           0.158000   0.763422   0.207\nnitrogen140:managementm3           0.482000   0.763422   0.631\nnitrogen50:variety2                0.240667   0.763422   0.315\nnitrogen80:variety2               -0.695333   0.763422  -0.911\nnitrogen110:variety2               0.152667   0.763422   0.200\nnitrogen140:variety2               1.265000   0.763422   1.657\nnitrogen50:variety3                1.068000   0.763422   1.399\nnitrogen80:variety3                1.226000   0.763422   1.606\nnitrogen110:variety3               1.321000   0.763422   1.730\nnitrogen140:variety3               3.075000   0.763422   4.028\nmanagementm2:variety2             -1.054667   0.763422  -1.381\nmanagementm3:variety2             -1.343000   0.763422  -1.759\nmanagementm2:variety3              0.697333   0.763422   0.913\nmanagementm3:variety3              0.753667   0.763422   0.987\nnitrogen50:managementm2:variety2   0.603667   1.079642   0.559\nnitrogen80:managementm2:variety2   1.068667   1.079642   0.990\nnitrogen110:managementm2:variety2  1.009667   1.079642   0.935\nnitrogen140:managementm2:variety2  0.225000   1.079642   0.208\nnitrogen50:managementm3:variety2   0.482667   1.079642   0.447\nnitrogen80:managementm3:variety2   1.329000   1.079642   1.231\nnitrogen110:managementm3:variety2  1.022667   1.079642   0.947\nnitrogen140:managementm3:variety2  0.662667   1.079642   0.614\nnitrogen50:managementm2:variety3  -0.006333   1.079642  -0.006\nnitrogen80:managementm2:variety3  -0.569667   1.079642  -0.528\nnitrogen110:managementm2:variety3 -0.322333   1.079642  -0.299\nnitrogen140:managementm2:variety3 -1.054333   1.079642  -0.977\nnitrogen50:managementm3:variety3   0.259667   1.079642   0.241\nnitrogen80:managementm3:variety3  -0.816667   1.079642  -0.756\nnitrogen110:managementm3:variety3 -0.541000   1.079642  -0.501\nnitrogen140:managementm3:variety3 -1.292333   1.079642  -1.197\n\n\n\nCorrelation matrix not shown by default, as p = 47 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nModel Diagnostics: we observed a constant variance and normality of residuals.\n\nplot(model3)\n\n\n\n\n\n\n\nqqnorm(residuals(model3)); qqline(residuals(model3))\n\n\n\n\n\n\n\nlibrary(see)\ncheck_model(model3)\n\n\n\n\n\n\n\n\nAnalysis of variance\n\nanova(model3)\n\nAnalysis of Variance Table\n                            npar  Sum Sq Mean Sq  F value\nblock                          2   0.505   0.253   0.5780\nnitrogen                       4  48.424  12.106  27.6953\nmanagement                     2  42.936  21.468  49.1136\nvariety                        2 206.013 103.007 235.6535\nnitrogen:management            8   1.103   0.138   0.3154\nnitrogen:variety               8  14.145   1.768   4.0449\nmanagement:variety             4   3.852   0.963   2.2030\nnitrogen:management:variety   16   3.699   0.231   0.5289\n\n\nPost-Hoc analysis\n\nemmeans(model3, ~ nitrogen)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n nitrogen emmean    SE df lower.CL upper.CL\n 0          5.38 0.156  0     -Inf      Inf\n 50         6.22 0.145  0     -Inf      Inf\n 80         7.00 0.145  0     -Inf      Inf\n 110        6.94 0.144  0     -Inf      Inf\n 140        7.23 0.144  0     -Inf      Inf\n\nResults are averaged over the levels of: block, management, variety \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\nemmeans(model3, ~ variety*management)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n variety management emmean    SE df lower.CL upper.CL\n 1       m1           4.41 0.164  0     -Inf      Inf\n 2       m1           6.05 0.175  0     -Inf      Inf\n 3       m1           7.23 0.176  0     -Inf      Inf\n 1       m2           5.05 0.176  0     -Inf      Inf\n 2       m2           6.22 0.174  0     -Inf      Inf\n 3       m2           8.18 0.173  0     -Inf      Inf\n 1       m3           5.91 0.177  0     -Inf      Inf\n 2       m3           6.91 0.174  0     -Inf      Inf\n 3       m3           9.01 0.174  0     -Inf      Inf\n\nResults are averaged over the levels of: block, nitrogen \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\nemm &lt;- emmeans(model3, ~ nitrogen*variety) \n\nNOTE: Results may be misleading due to involvement in interactions\n\ncomparison &lt;- cld(emm, Letters = LETTERS, reversed = T) \ncomparison\n\n nitrogen variety emmean    SE df lower.CL upper.CL .group     \n 140      3         9.34 0.231  0     -Inf      Inf  A         \n 80       3         8.56 0.231  0     -Inf      Inf  AB        \n 110      3         8.44 0.231  0     -Inf      Inf  ABC       \n 50       3         7.88 0.231  0     -Inf      Inf   BCD      \n 140      2         7.29 0.230  0     -Inf      Inf    CDE     \n 110      2         6.92 0.230  0     -Inf      Inf     DEF    \n 80       2         6.59 0.231  0     -Inf      Inf      EFG   \n 0        3         6.48 0.229  0     -Inf      Inf      EFG   \n 50       2         6.02 0.230  0     -Inf      Inf       FGH  \n 80       1         5.83 0.232  0     -Inf      Inf       FGHI \n 110      1         5.44 0.230  0     -Inf      Inf        GHIJ\n 0        2         5.16 0.232  0     -Inf      Inf         HIJ\n 140      1         5.08 0.231  0     -Inf      Inf         HIJ\n 50       1         4.76 0.233  0     -Inf      Inf          IJ\n 0        1         4.51 0.229  0     -Inf      Inf           J\n\nResults are averaged over the levels of: block, management \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 15 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Split Plot Design</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html",
    "href": "chapters/incomplete-block-design.html",
    "title": "6¬† Balanced Incomplete Block Experiment",
    "section": "",
    "text": "7 Balanced incomplete block experiment",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Balanced Incomplete Block Experiment</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html#background",
    "href": "chapters/incomplete-block-design.html#background",
    "title": "6¬† Balanced Incomplete Block Experiment",
    "section": "7.1 Background",
    "text": "7.1 Background\nThe block design in link RCBD guide was complete, meaning that every block contained all the treatments. In practice, it may not be possible to have too many treatments in each block. Sometimes, there are also situations where it is advised to not have many treatments in each block.\nIn such cases, incomplete block designs are used where we have to decide what subset of treatments to be used in an individual block. This will work well if we enough blocks. However, if we only have small number of blocks, there would be the risk that certain quantities are not estimable anymore.\nTo avoid having a disconnected design, a balanced incomplete block design can be used\n\n\n\n\n\n\nA note",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Balanced Incomplete Block Experiment</span>"
    ]
  },
  {
    "objectID": "chapters/incomplete-block-design.html#example-analysis",
    "href": "chapters/incomplete-block-design.html#example-analysis",
    "title": "6¬† Balanced Incomplete Block Experiment",
    "section": "7.2 Example Analysis",
    "text": "7.2 Example Analysis\nhttps://kwstat.github.io/agridat/reference/weiss.incblock.html\n\n library(agridat)\n  data(weiss.incblock)\n  dat &lt;- weiss.incblock\n\n\n library(desplot)\n  desplot(dat, yield~col*row,\n          text=gen, shorten='none', cex=.6, out1=block,\n          aspect=252/96, # true aspect\n          main=\"weiss.incblock\")\n\n\n\n\n\n\n\n\n\nlme4tidymodels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.1 Data integrity checks\n\n\n7.2.2 Model Building\n\n\nRecall the model:\n\\[ \\]\nHere is the R syntax for that statistical model:\n\nlme4tidymodels\n\n\n\n\n\n\n\n\n\n\n\n7.2.3 Check Model Assumptions\n\n\n7.2.4 Inference",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Balanced Incomplete Block Experiment</span>"
    ]
  },
  {
    "objectID": "chapters/lattice-design.html",
    "href": "chapters/lattice-design.html",
    "title": "7¬† lattice_design",
    "section": "",
    "text": "https://kwstat.github.io/agridat/reference/cochran.lattice.html\n\nlibrary(dplyr) \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(nlme)\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\nlibrary(mmrm)\nlibrary(emmeans)\n\nmmrm() registered as emmeans extension\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nlibrary(performance)\nlibrary(lme4); library(lmerTest); library(emmeans)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:nlme':\n\n    lmList\n\n\n\nAttaching package: 'lmerTest'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nThe following object is masked from 'package:stats':\n\n    step\n\n\nImport data from agridat package and create columns for row and column as factor variables. This is a balanced experiment design\n\nlibrary(agridat)\ndata(burgueno.rowcol)\ndat &lt;- burgueno.rowcol\n\n\n# Two contiguous reps in 8 rows, 16 columns\nlibs(desplot)\ndesplot(dat, yield ~ col*row,\n        out1=rep, # aspect unknown\n        text=gen, shorten=\"none\", cex=.75,\n        main=\"burgueno.rowcol\")\n\n\n\n\n\n\n\n\nStatistical model for lattice design:\n\\(Yijk = \\mu + \\alpha_i + \\gamma_j + \\tau_t  + \\beta_k + \\epsilon_ijk\\)\nwhere, mu is the ¬µ is the experiment mean, ùõΩ is the row effect, ùõæ is the column effect, and ùúè is the treatment effect.\n\n#Random rep, row and col within rep\n m1 &lt;- lmer(yield ~ gen + (1|rep) + (1|rep:row) + (1|rep:col), data=dat)\nsummary(m1) \n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: yield ~ gen + (1 | rep) + (1 | rep:row) + (1 | rep:col)\n   Data: dat\n\nREML criterion at convergence: 168.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.1392 -0.4036  0.0000  0.4036  1.1392 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n rep:col  (Intercept) 0.2189   0.4679  \n rep:row  (Intercept) 0.1646   0.4057  \n rep      (Intercept) 0.1916   0.4378  \n Residual             0.1796   0.4238  \nNumber of obs: 128, groups:  rep:col, 32; rep:row, 8; rep, 2\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)   \n(Intercept)  2.325589   0.509444  4.216418   4.565   0.0091 **\ngenG02       0.349182   0.523392 38.995063   0.667   0.5086   \ngenG03       0.371260   0.531293 41.034622   0.699   0.4886   \ngenG04       0.475842   0.527614 43.470779   0.902   0.3721   \ngenG05      -0.601225   0.513762 38.892580  -1.170   0.2490   \ngenG06       0.574869   0.527284 40.643852   1.090   0.2820   \ngenG07       0.244490   0.534996 42.592433   0.457   0.6500   \ngenG08       0.606486   0.527879 43.602192   1.149   0.2569   \ngenG09       0.010630   0.525899 42.747488   0.020   0.9840   \ngenG10       0.509855   0.527357 43.301826   0.967   0.3390   \ngenG11       0.463014   0.535708 42.977451   0.864   0.3922   \ngenG12       0.340678   0.517892 43.399748   0.658   0.5141   \ngenG13      -0.041178   0.483241 34.257292  -0.085   0.9326   \ngenG14       0.132480   0.523679 39.142513   0.253   0.8016   \ngenG15       0.385104   0.526349 43.013937   0.732   0.4683   \ngenG16      -0.148379   0.483194 34.227894  -0.307   0.7606   \ngenG17      -0.016143   0.536067 42.926995  -0.030   0.9761   \ngenG18       0.358218   0.526325 42.993175   0.681   0.4998   \ngenG19       0.734743   0.533892 41.978194   1.376   0.1761   \ngenG20       0.212299   0.521319 40.753106   0.407   0.6860   \ngenG21       0.150212   0.525313 39.814746   0.286   0.7764   \ngenG22      -0.039713   0.497948 37.586406  -0.080   0.9369   \ngenG23       0.325771   0.484472 34.701705   0.672   0.5058   \ngenG24      -0.194686   0.524899 39.587776  -0.371   0.7127   \ngenG25       0.202462   0.514979 39.325398   0.393   0.6963   \ngenG26       0.089411   0.483188 34.221812   0.185   0.8543   \ngenG27       0.218244   0.536631 43.262734   0.407   0.6862   \ngenG28      -0.284235   0.524825 39.538457  -0.542   0.5911   \ngenG29       0.047110   0.515184 39.470339   0.091   0.9276   \ngenG30      -0.213561   0.484574 34.769665  -0.441   0.6621   \ngenG31      -0.034873   0.535702 42.734026  -0.065   0.9484   \ngenG32       1.000827   0.535020 42.606153   1.871   0.0683 . \ngenG33       0.252960   0.507660 40.377683   0.498   0.6210   \ngenG34       0.242054   0.537217 43.562588   0.451   0.6545   \ngenG35       0.213005   0.515262 39.472578   0.413   0.6816   \ngenG36       0.362633   0.525014 42.290855   0.691   0.4935   \ngenG37       0.282612   0.530472 40.615244   0.533   0.5971   \ngenG38      -0.125437   0.537059 43.462082  -0.234   0.8164   \ngenG39       1.261824   0.537018 43.466180   2.350   0.0234 * \ngenG40       0.346211   0.536855 43.369657   0.645   0.5224   \ngenG41      -0.255692   0.522110 41.202626  -0.490   0.6269   \ngenG42       0.744461   0.483144 34.195322   1.541   0.1326   \ngenG43       0.489907   0.535381 42.795749   0.915   0.3653   \ngenG44       0.445400   0.527076 43.156823   0.845   0.4027   \ngenG45       0.728849   0.531497 41.172558   1.371   0.1777   \ngenG46       0.008386   0.527720 43.541892   0.016   0.9874   \ngenG47      -0.173693   0.525585 42.635003  -0.330   0.7427   \ngenG48       0.364422   0.523287 41.600011   0.696   0.4900   \ngenG49       0.283642   0.535631 42.924562   0.530   0.5992   \ngenG50      -0.160189   0.534315 42.227391  -0.300   0.7658   \ngenG51       0.127042   0.526978 43.139993   0.241   0.8106   \ngenG52      -0.277455   0.534469 42.326672  -0.519   0.6064   \ngenG53      -0.401069   0.525510 42.532998  -0.763   0.4496   \ngenG54      -0.221400   0.533965 42.027349  -0.415   0.6805   \ngenG55       0.479012   0.524627 42.079587   0.913   0.3664   \ngenG56       0.232007   0.536959 43.388811   0.432   0.6678   \ngenG57      -0.153493   0.526605 42.888008  -0.291   0.7721   \ngenG58       0.545562   0.523508 41.715186   1.042   0.3034   \ngenG59       0.691577   0.536175 43.006805   1.290   0.2040   \ngenG60      -0.221321   0.517482 37.741262  -0.428   0.6713   \ngenG61       0.205307   0.514087 39.066489   0.399   0.6918   \ngenG62       0.341897   0.534904 42.530411   0.639   0.5261   \ngenG63       0.701913   0.517290 40.377937   1.357   0.1823   \ngenG64       0.066248   0.526946 40.462383   0.126   0.9006   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 64 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\nanova(m1)\n\nType III Analysis of Variance Table with Satterthwaite's method\n    Sum Sq Mean Sq NumDF  DenDF F value Pr(&gt;F)\ngen 9.5245 0.15118    63 34.322  0.8418 0.7274\n\n\n\ncheck_model(m1)\n\n\n\n\n\n\n\n\nANOVA\n\nanova(m1)\n\nType III Analysis of Variance Table with Satterthwaite's method\n    Sum Sq Mean Sq NumDF  DenDF F value Pr(&gt;F)\ngen 9.5245 0.15118    63 34.322  0.8418 0.7274\n\n\nEstimated marginal means\n\nemmeans(m1, ~ gen)\n\n gen emmean    SE   df lower.CL upper.CL\n G01   2.33 0.515 4.21    0.923     3.73\n G02   2.67 0.515 4.21    1.272     4.08\n G03   2.70 0.515 4.21    1.294     4.10\n G04   2.80 0.515 4.21    1.399     4.20\n G05   1.72 0.515 4.21    0.322     3.13\n G06   2.90 0.515 4.20    1.497     4.30\n G07   2.57 0.515 4.21    1.167     3.97\n G08   2.93 0.515 4.21    1.529     4.33\n G09   2.34 0.515 4.20    0.933     3.74\n G10   2.84 0.515 4.20    1.432     4.24\n G11   2.79 0.515 4.20    1.385     4.19\n G12   2.67 0.515 4.19    1.263     4.07\n G13   2.28 0.515 4.21    0.882     3.69\n G14   2.46 0.515 4.20    1.055     3.86\n G15   2.71 0.515 4.20    1.307     4.11\n G16   2.18 0.515 4.21    0.775     3.58\n G17   2.31 0.515 4.19    0.906     3.71\n G18   2.68 0.515 4.21    1.281     4.09\n G19   3.06 0.514 4.18    1.657     4.46\n G20   2.54 0.515 4.20    1.135     3.94\n G21   2.48 0.515 4.19    1.072     3.88\n G22   2.29 0.515 4.21    0.883     3.69\n G23   2.65 0.515 4.21    1.249     4.05\n G24   2.13 0.515 4.19    0.727     3.53\n G25   2.53 0.515 4.20    1.125     3.93\n G26   2.42 0.515 4.21    1.013     3.82\n G27   2.54 0.515 4.20    1.141     3.95\n G28   2.04 0.515 4.20    0.638     3.44\n G29   2.37 0.515 4.20    0.970     3.78\n G30   2.11 0.515 4.19    0.708     3.52\n G31   2.29 0.514 4.18    0.887     3.69\n G32   3.33 0.515 4.20    1.923     4.73\n G33   2.58 0.514 4.19    1.175     3.98\n G34   2.57 0.515 4.21    1.165     3.97\n G35   2.54 0.515 4.20    1.136     3.94\n G36   2.69 0.515 4.20    1.285     4.09\n G37   2.61 0.515 4.20    1.205     4.01\n G38   2.20 0.515 4.21    0.797     3.60\n G39   3.59 0.515 4.20    2.184     4.99\n G40   2.67 0.515 4.21    1.269     4.07\n G41   2.07 0.514 4.18    0.666     3.47\n G42   3.07 0.515 4.21    1.668     4.47\n G43   2.82 0.515 4.20    1.412     4.22\n G44   2.77 0.515 4.20    1.368     4.17\n G45   3.05 0.515 4.20    1.651     4.46\n G46   2.33 0.515 4.21    0.931     3.74\n G47   2.15 0.515 4.20    0.749     3.56\n G48   2.69 0.515 4.19    1.286     4.09\n G49   2.61 0.515 4.22    1.207     4.01\n G50   2.17 0.514 4.19    0.762     3.57\n G51   2.45 0.514 4.19    1.049     3.86\n G52   2.05 0.514 4.19    0.644     3.45\n G53   1.92 0.515 4.19    0.521     3.33\n G54   2.10 0.514 4.18    0.700     3.51\n G55   2.80 0.514 4.18    1.401     4.21\n G56   2.56 0.515 4.20    1.155     3.96\n G57   2.17 0.515 4.19    0.769     3.58\n G58   2.87 0.514 4.18    1.467     4.28\n G59   3.02 0.514 4.19    1.613     4.42\n G60   2.10 0.516 4.22    0.702     3.51\n G61   2.53 0.515 4.21    1.128     3.93\n G62   2.67 0.514 4.18    1.264     4.07\n G63   3.03 0.514 4.19    1.624     4.43\n G64   2.39 0.515 4.19    0.988     3.80\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>lattice_design</span>"
    ]
  },
  {
    "objectID": "chapters/glmm.html",
    "href": "chapters/glmm.html",
    "title": "8¬† Generalized Linear Mixed Models",
    "section": "",
    "text": "8.1 Zero-inflated & hurdle models\nWhen data have a large number of zeros, that can skew the results very dramatically and are most certainly violating standard assumptions of linear models (constant variance, normality, iid). What is a large number? That depends (of course) but I suggest 15% to 60% of the total data being zeros is high. Anything more than 60% starts to be too high - and it begs the question if statistics are really needed to understand what is going on.\nAdditionally, the occurence of zero‚Äôs does matter. If there are all occurring for a particular treatment (e.g.¬†a negative control), estimation is impossible for that treatment level and running a conditional analysis may be a better choice. This mean filtering the data set to the treatments that are not completely all zero‚Äôs and running the analysis as a condition of a limited number of treatments.\nZero-inflated models are currently best developed for count variable and less ammenable (although not impossible) for continuous variable. I find these models helpful for studies in plant pathology, entomology, etc when pathogen/disease/pest occurence is spotty.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Generalized Linear Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/glmm.html#zero-inflated-hurdle-models",
    "href": "chapters/glmm.html#zero-inflated-hurdle-models",
    "title": "8¬† Generalized Linear Mixed Models",
    "section": "",
    "text": "8.1.0.1 Zero-inflated versus hurdle models\nKeeping with this tutorial self-imposed rule, I will not go into theory, but really, you ought to read up on these models because they are complicated. The Wikipedia entries for zero-inflated and hurdle models are a good source for an introductory overview.\n\n\n8.1.1 Data import & preparation\n\ninsect_exp &lt;- read.csv(here::here(\"data\", \"insect_count_data_glmm.csv\")) %&gt;% \n  mutate(sampling_date = as.Date(sampling_date, format = \"%m/%d/%y\")) %&gt;% \n  mutate(Date = as.character(sampling_date), \n         block = as.character(block),\n         treatment = as.character(treatment))\n\n|‚Äî‚Äî‚Äî-|‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-|\n|plot | a unique number referring to each experimental unit |\n|treatment | 6 pesticide treatments (converted to a ) |\n|row | plot position for row |\n|col | plot positions for column or range |\n|block | the blocking unit (converted to character) |\n| insect_counts | response variable, number of insects counted |\n|sampling_date | dates when each experimental unit were evaluated for insect counts |\n|Date | sampling date converted to a character variable |\n\n\n8.1.2 Data integrity checks\nData types:\n\nstr(insect_exp)\n\n'data.frame':   270 obs. of  8 variables:\n $ plot         : int  101 102 103 104 201 202 203 204 301 302 ...\n $ treatment    : chr  \"2\" \"5\" \"1\" \"6\" ...\n $ row          : int  1 1 1 1 2 2 2 2 3 3 ...\n $ column       : int  1 2 3 4 1 2 3 4 1 2 ...\n $ block        : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ insect_counts: int  4 1 0 0 0 0 2 1 2 1 ...\n $ sampling_date: Date, format: \"1988-06-17\" \"1988-06-17\" ...\n $ Date         : chr  \"1988-06-17\" \"1988-06-17\" \"1988-06-17\" \"1988-06-17\" ...\n\n\nData balance:\n\ntable(insect_exp$sampling_date, insect_exp$treatment)\n\n            \n             1 2 3 4 5 6\n  1988-06-17 5 5 5 5 5 5\n  1988-06-22 5 5 5 5 5 5\n  1988-06-27 5 5 5 5 5 5\n  1988-06-29 5 5 5 5 5 5\n  1988-07-06 5 5 5 5 5 5\n  1988-07-13 5 5 5 5 5 5\n  1988-07-21 5 5 5 5 5 5\n  1988-07-27 5 5 5 5 5 5\n  1988-08-03 5 5 5 5 5 5\n\n\nMissingness:\n\napply(insect_exp, 2, function(x) sum(is.na(x)))\n\n         plot     treatment           row        column         block \n            0             0             0             0             0 \ninsect_counts sampling_date          Date \n            0             0             0 \n\n\nData visualization:\nHistograms are often not helpful for zero-inflated data since the zero‚Äôs dominate the distribution. Stem-and-leaf plots can be better. It‚Äôs also helpful to count the total number of zero‚Äôs.\n\nstem(insect_exp$insect_counts)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n   0 | 00000000000000000000000000000000000000000000000000000000000000000000+137\n   1 | 01222333455566779\n   2 | 001122234577789\n   3 | 00013568\n   4 | 48\n   5 | 13\n   6 | 0125\n   7 | 6\n   8 | 45\n   9 | 4\n  10 | \n  11 | \n  12 | \n  13 | 5\n\nsum(insect_exp$insect_counts == 0)/nrow(insect_exp)\n\n[1] 0.4185185\n\n\nRoughly 42% of the data are zero‚Äôs. The remaining non-zero data look like it might folow a Poisson or negative binomial distribution.\n\n# all data\nggplot(insect_exp, aes(x = sampling_date, y = insect_counts, color = treatment, group = plot)) +\n  geom_point(size = 2) +\n  geom_line() +\n  ggtitle(\"all data\") + \n  theme_classic()\n\n\n\n\n\n\n\n# mean of each treatment\ninsect_exp %&gt;% group_by(sampling_date, treatment) %&gt;% \n  summarise(mean_counts = mean(insect_counts)) %&gt;% \n  ggplot(., aes(x = sampling_date, y = mean_counts, color = treatment)) +\n    geom_point(size = 2) +\n    geom_line() +\n    ggtitle(\"mean data\") + \n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n8.1.3 Statistical modelling\nModel statement:\n\\[y_{ijk} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\delta_i + \\epsilon_{ijk}\\]\nwhere:\n\\(\\mu\\) = overall mean \\(\\alpha_i\\) = effect of the \\(i^{th}\\) pesticide treatment\n\\(\\beta_j\\) = effect of the \\(j^{th}\\) block \\(\\gamma_k\\) = effect of the \\(k^{th}\\) sampling date \\(\\delta_i\\) = effect of the \\(i^{th}\\) pesticide treatment on becoming non-zero\nand\n\n8.1.3.1 Model fitting\nAs mentioned, this is hard and often takes many tries.\n\nm1 = glmmTMB(\n  insect_counts ~ treatment + Date + ar1(Date + 0|plot) + (1|block),\n  ziformula = ~ treatment,\n  data = insect_exp, \n  na.action = na.exclude, \n  family = nbinom2)\n\nThis model is using the correlation structure for autoregressive correlated error terms, ar1(). There are several other specialized covariance structures implmented by glmmTMB. In general, repeated measures syntax follow this convention: (time + 0 | grouping).\nFitting glmm is hard. The glmmTMB writers have written some guidance on model fitting.\n\nm1\n\nFormula:          \ninsect_counts ~ treatment + Date + ar1(Date + 0 | plot) + (1 |      block)\nZero inflation:                 ~treatment\nData: insect_exp\n      AIC       BIC    logLik  df.resid \n1298.7328 1385.0949 -625.3664       246 \nRandom-effects (co)variances:\n\nConditional model:\n Groups Name           Std.Dev. Corr      \n plot   Date1988-06-17 0.7748   0.49 (ar1)\n block  (Intercept)    0.3333             \n\nNumber of obs: 270 / Conditional model: plot, 30; block, 5\n\nDispersion parameter for nbinom2 family (): 1.76 \n\nFixed Effects:\n\nConditional model:\n   (Intercept)      treatment2      treatment3      treatment4      treatment5  \n       2.39231        -0.04978        -1.53159        -2.75395        -2.50652  \n    treatment6  Date1988-06-22  Date1988-06-27  Date1988-06-29  Date1988-07-06  \n      -1.48975         0.24054         0.26618         0.62692         1.17067  \nDate1988-07-13  Date1988-07-21  Date1988-07-27  Date1988-08-03  \n       0.83442         0.19962        -0.96749        -1.11938  \n\nZero-inflation model:\n(Intercept)   treatment2   treatment3   treatment4   treatment5   treatment6  \n     -2.608       -1.200        1.568        2.607        1.542        2.134  \n\n\n\n\n8.1.3.2 Model diagnostics\nLook at residuals over space\n\ninsect_exp$model_resids &lt;- residuals(m1)\n\nggplot(insect_exp, aes(x = row, y = column, fill = model_resids)) +\n  geom_tile() + \n  facet_wrap(facets = vars(Date), nrow = 3, ncol = 3) + \n  scale_fill_viridis_c(direction = -1) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nUse DHARMa to conduct residual tests\n\nsimulated_resids &lt;- simulateResiduals(m1)\ntestDispersion(simulated_resids)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 0.35248, p-value = 0.408\nalternative hypothesis: two.sided\n\nplot(simulated_resids)\n\n\n\n\n\n\n\n\n\n\n8.1.3.3 Inference\nANOVA\nThe package car is needed to conduct ANOVA tests on glmmTMB object. It conducts a chi-square test rather than an F-test. These tend to be more sensitive than F-tests, resulting in lower p-values.\n\ncar::Anova(m1)\n\nWarning in printHypothesis(L, rhs, names(b)): one or more coefficients in the hypothesis include\n     arithmetic operators in their names;\n  the printed representation of the hypothesis will be omitted\n\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: insect_counts\n           Chisq Df Pr(&gt;Chisq)    \ntreatment 54.358  5  1.769e-10 ***\nDate      41.652  8  1.574e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEstimates.\nglmmTMB is compatible with emmeans and effects.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Generalized Linear Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/special-conditions.html",
    "href": "chapters/special-conditions.html",
    "title": "9¬† Combining Scenarios",
    "section": "",
    "text": "9.1 Split plot with repeated measures\nNormally-distributed data",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Combining Scenarios</span>"
    ]
  },
  {
    "objectID": "chapters/special-conditions.html#split-plot-with-repeated-measures",
    "href": "chapters/special-conditions.html#split-plot-with-repeated-measures",
    "title": "9¬† Combining Scenarios",
    "section": "",
    "text": "9.1.0.1 Load data\nThis is an alfalfa study consisting of two treatments: irrigation level and planting mix with four reps. Each plot (the experimental unit) was harvested three times and the yield was measured.\n\nalfalfa &lt;- read.csv(here::here(\"data\", \"alfalfa2021_data.csv\"))\n\n|‚Äî‚Äî‚Äî-|‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-| | cut | a cutting (harvest) of alfalfa within a single growing season. This is a temporal unit for repeated measures analysis. There were three cuttings in total for that year and field. The dates are not known, so we cannot assume they are evenly spaced apart |\n|irrigation | main plot, irrigation treatment (‚ÄúFull‚Äù or ‚ÄúDeficit‚Äù) |\n|plot | a number referring to each experimental unit |\n|block | the blocking unit |\n|yield | alfalfa yield (the response variable) |\n|row | plot position for row |\n|col | plot positions for column or range. |\nTwo new variables need to be created:\n\nblock: character version of the original ‚Äòblock‚Äô\ncut_num: integer version of ‚Äòcut‚Äô. This is required by nlme::lme for specialized correlation structures. The numeric order of this variable matches the cut order.\n\n\nalfalfa_sp &lt;- alfalfa %&gt;% \n  mutate(block = as.character(block)) %&gt;% \n  mutate(cut_num = case_when(\n    cut == \"First\" ~ 1L,\n    cut == \"Second\" ~ 2L,\n    cut == \"Third\" ~ 3L,\n    is.na(cut) ~ NA_integer_)) \n\n\n\n9.1.0.2 Data integrity checks\nData type check:\n\nstr(alfalfa_sp)\n\n'data.frame':   240 obs. of  9 variables:\n $ cut       : chr  \"First\" \"First\" \"First\" \"First\" ...\n $ irrigation: chr  \"Full\" \"Full\" \"Full\" \"Full\" ...\n $ plot      : int  1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 ...\n $ block     : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ mix       : chr  \"50A+50O\" \"75A+25O\" \"50A+50F\" \"75A+25M\" ...\n $ yield     : num  221 289 467 557 423 ...\n $ row       : int  1 1 1 1 1 2 2 2 2 2 ...\n $ col       : int  1 2 3 4 5 1 2 3 4 5 ...\n $ cut_num   : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\nData balance check:\n\ntable(alfalfa_sp$irrigation, alfalfa_sp$mix, alfalfa_sp$cut)\n\n, ,  = First\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n, ,  = Second\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n, ,  = Third\n\n         \n          100A 50A+50F 50A+50F_AR 50A+50M 50A+50M_AR 50A+50O 50A+50O_AR 75A+25F\n  Deficit    4       4          4       4          4       4          4       4\n  Full       4       4          4       4          4       4          4       4\n         \n          75A+25M 75A+25O\n  Deficit       4       4\n  Full          4       4\n\n\nCheck missingness:\n\napply(alfalfa_sp, 2, function(x) sum(is.na(x)))\n\n       cut irrigation       plot      block        mix      yield        row \n         0          0          0          0          0          0          0 \n       col    cut_num \n         0          0 \n\n\nCheck dependent data:\n\nhist(alfalfa_sp$yield)\n\n\n\n\n\n\n\n\nThere are some very high values that we should keep an eye on.\nExperimental layout:\n\nalfalfa_sp %&gt;% filter(cut == \"First\") %&gt;% \n  ggplot(aes(x = col, y = row)) +\n    geom_raster(aes(fill = irrigation)) +\n    geom_tileborder(aes(group = 1, grp = block), lwd = 1.5) + \n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n9.1.0.3 Data analysis\nModel statement:\n\\[y_{ijk} = \\mu + \\alpha_i+ \\beta_j + \\gamma_k + (\\alpha\\beta)_{ij} + (\\alpha\\gamma)_{ik} + (\\beta\\gamma)_{jk} + (\\alpha\\beta\\gamma)_{ijk} +\\epsilon_{ijk}\\]\nwhere\n\\(\\mu\\) = overall mean\n\\(\\alpha_i\\) = effect of the \\(i^{th}\\) irrigation treatment\n\\(\\beta_j\\) = effect of the \\(j^{th}\\) planting mix treatment\n\\(\\gamma_k\\) = effect of the \\(k^{th}\\) cutting\nAnd the remaining terms reflect two-way and three-way interactions.\nThe error terms are assumed to follow this distribution, \\(\\epsilon \\sim N(0, \\sigma)\\), and each plot is assumed to follow an auto-regressive correlation structure.\nThe starting model is very similar to the other split plot example in this guide where the main plot ‚Äúirrigation‚Äù is nested with ‚Äúblock‚Äù. An additional level of nesting is used for ‚Äúplot‚Äù since that is the experimental unit we are designating for the repeated measures term.\nI usually build the model in two steps: first the basic model is estimated, and next a correlation structure is added. This is not strictly needed; the model can be estimated in one step.\n\nm1 &lt;- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|block/irrigation/plot,\n          data = alfalfa_sp)\n\nSince we don‚Äôt know the temporal spacing for each cutting, a compound symmetry correlation structure will be used. This type assumes a single correlation across time. This has a starting value of 0.3 and this may chagne during the fitting process since fixed = FALSE.\n\ncorstr &lt;- corCompSymm(value = 0.3, \n                      form = ~ cut|block/irrigation/plot,\n                      fixed = FALSE)\n\nIt is required by nlme that two terms match after the ‚Äú|‚Äù in the random and form arguments match exactly. The plot term is needed because this is the unit to calculate correlations at.\n\ncorstr &lt;- corCompSymm(value = 0.3, \n                      form = ~ cut|block/irrigation/plot,\n                      fixed = FALSE)\n\nm1 &lt;- lme(yield ~ mix*irrigation*cut,\n          random = ~ 1|block/irrigation/plot,\n          data = alfalfa_sp)\n\nUpdate the model with the correlation structure:\n\nm2 &lt;- update(m1, cor = corstr)\n\n\n\n9.1.0.4 Check model assumpotion\n\nplot(m2)\n\n\n\n\n\n\n\nqqnorm(m2, ~ resid(., type = \"p\"), abline = c(0, 1))\n\n\n\n\n\n\n\n\nThere are some very large outliers at the right side of the plot.\n\n\n9.1.0.5 Run ANOVA\n\nanova(m2)\n\n                   numDF denDF   F-value p-value\n(Intercept)            1   102 1432.6369  &lt;.0001\nmix                    9   102   13.6932  &lt;.0001\nirrigation             1     3    4.8770  0.1143\ncut                    2   102    6.0434  0.0033\nmix:irrigation         9   102    0.5256  0.8530\nmix:cut               18   102    0.8029  0.6927\nirrigation:cut         2   102   14.2649  &lt;.0001\nmix:irrigation:cut    18   102    1.0226  0.4418\n\n\nAlways check the degrees of freedom (denominator and numerator) to make sure the model is specified correctly.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Combining Scenarios</span>"
    ]
  },
  {
    "objectID": "chapters/analysis-tips.html",
    "href": "chapters/analysis-tips.html",
    "title": "10¬† Tips on Analysis",
    "section": "",
    "text": "10.0.0.1 Think about your analytical goals\nThroughout this guide, I have tried to explicitly state the goals of each analysis. This helps inform us on how to approach the analysis of an experiment. It can be difficult, especially for new scientists-in-training (i.e.¬†graduate students), to understand what it is they want to estimate. You may have been handed a data set you had no role in generating and told to ‚Äúanalyze this‚Äù with no additional context. Or perhaps you may have conducted a large study that has some overall goals that are lofty, yet vague.\nIt can helpful to think about the exact results you are hoping to get. What does this look like exactly? Do you want to estimate the changes in plant diversity as the result of a herbicide spraying program? Do you want to find out if a fertilizer treatment changed protein content in a crop and by how much? Do you want to know about changes in human diet due to an intervention? What are quantifiable difference that you and/or experts in your domain would find meaningful?\nConsider what the results would look like on the best case scenario when your wildest dreams come true and null results, when you find out that your treatment or invention had no effect.\nBy ‚Äúconsider‚Äù, I mean: imagine the final plot or table, or summary sentence you want to present, either in a peer-reviewed manuscript, or some output for stakeholders. From this, you work backwards to determine the analytical approach needed to arrive at that final output. Or you may determine that your data are unsuitable to generate the desired output, in which case, it‚Äôs best to determine that as soon as possible.\nBy ‚Äúconsider‚Äù, I also mean: imagine exactly what the spreadsheet of results would say - what columns are present and what data are in the cells. If you are planning an experiment, this can help ensure you plan it properly to actually test whatever it is you want to evaluate. If the experiment is done, this enables you to evaluate if you have the information present to test your hypothesis.\nBy taking the time to reflect on what it is you exactly want to analyse, this can save time and prevent you from doing unneeded analyses that don‚Äôt serve this final goal. There is rarely (never?) one way to analyse an experiment or a data set, so use your limited time wisely and focus on what matters.\n\n\n10.0.0.2 Some reflections on p-values\n\nInformally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value. -American Statistical Association\n\nThe great majority of researched are deeply interested in p-values. This is not a bad thing per se, but sometimes the focus is so strong it comes at the expense of other valuable pieces of information, like treatment estimates!\nThe American Statistics Association recommends that ‚ÄúScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.‚Äù That articles also contain explanations regarding what p-values are telling us and how to avoid committing analytical errors and/or misinterpreting p-values. If you have time to read the full article, it will benefit your research!\nThe main problematic behavior I see is researchers using p-values as the sole criteria on whether to present results: ‚ÄúWe wanted to test if x, y and z had an effect. We ran some model and found that that only x had a significant effect, and those results indicate‚Ä¶‚Äù (results with a p-value &lt; 0.05 are ignored).\nA better option would be to discuss the the results of the analysis and how they addressed the research questions: how did the dependent variable change (or not change) as a result of the treatments/interventions/independent variables? What are the parameters or treatment predictions and what do they tell us with regard to the research goals? And to bolster those estimates, what are the confidence intervals on those estimates? What are the p-values for the statistical tests? P-values can support the results and conclusions, but the main results desired by a researcher are usually the estimates themselves - so lead with that!\n\n\n10.0.0.3 Data cleaning\nThis has and will continue to occupy the majority of researcher‚Äôs time when conducting an analysis. Truly, I am sorry for this. But, please know it is not you, it is the nature of data. I have written extensively about this elsewhere, but please prepare yourself to spend time cleaning and preparing your data for analysis. This will take way longer than the actual analysis! It is needed to ensure you can actually get correct results in an analysis, and hence worthy of the time invested.",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tips on Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/variance-components.html",
    "href": "chapters/variance-components.html",
    "title": "11¬† Variance Components",
    "section": "",
    "text": "For when there are multiple variance components and an interest in understanding them.",
    "crumbs": [
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Variance Components</span>"
    ]
  },
  {
    "objectID": "chapters/summary.html",
    "href": "chapters/summary.html",
    "title": "12¬† Summary",
    "section": "",
    "text": "In summary, mixed models are complicated.",
    "crumbs": [
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "chapters/resources.html",
    "href": "chapters/resources.html",
    "title": "13¬† Additional Resources",
    "section": "",
    "text": "13.0.1 Further Reading\n\nlme4 vignette for fitting linear mixed models\n\n\n\n13.0.2 Other Resources",
    "crumbs": [
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Additional Resources</span>"
    ]
  }
]